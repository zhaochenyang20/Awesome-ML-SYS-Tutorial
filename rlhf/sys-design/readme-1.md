# RL ç³»ç»Ÿæ·±æ€ï¼šæ·±å…¥ç†è§£æƒé‡æ›´æ–°æœºåˆ¶

å› ä¸ºå·¥ä½œéœ€è¦ï¼Œæœ€è¿‘ç»ˆäºå¾—ç©ºèƒ½å¤Ÿå†æ¬¡æ·±å…¥å»å­¦ä¹ æ€è€ƒä¸»æµ RL æ¡†æ¶çš„ç³»ç»Ÿè®¾è®¡ã€‚æˆ‘ä»¬å¸Œæœ›èƒ½å¤Ÿé€šè¿‡ä¸€ç³»åˆ—æ–‡æ¡£åˆ†äº«æˆ‘ä»¬çš„æ€è€ƒï¼Œä¹Ÿå¸Œæœ›èƒ½å¤Ÿå¾—åˆ°å¤§å®¶çš„åé¦ˆï¼Œå’Œå¿—åŒé“åˆçš„æœ‹å‹ä¸€åŒæ‰“é€ æ›´å¥½çš„å¼€æº RLHF æ¡†æ¶ã€‚æˆ‘ä»¬å°†è¿™ç³»åˆ—æ–‡ç« ç§°ä¸º RL ç³»ç»Ÿæ·±æ€ã€‚æœ¬æ–‡æ˜¯è¿™ç³»åˆ—çš„ç¬¬ä¸€ç¯‡ï¼Œé‡ç‚¹è®¨è®ºå„ç±»æƒé‡æ›´æ–°æœºåˆ¶ã€‚æœ¬æ–‡é¦–å…ˆåˆ†æ verl è¿™ç§ co-locate ç­–ç•¥ä¸‹çš„æƒé‡æ›´æ–°æ–¹å¼ï¼Œä¹Ÿæ˜¯æˆ‘è‡ªå·±ç¬¬ä¸€æ¬¡ä»å¤´åˆ°å°¾ç†è§£äº†åŸºäº handle tuple é‡å»º tensor æ¥å®ç°çš„æƒé‡æ›´æ–°ã€‚æ¥ç€ï¼Œæˆ‘ä»¬ä¼šå‰–æ slime æ¡†æ¶ä¸‹çš„æƒé‡æ›´æ–°æ¨¡å¼ï¼Œé‡ç‚¹åˆ†æå…¶ç‹¬å‡ºå¿ƒè£çš„æ¡¶æ›´æ–°ç­–ç•¥ã€‚æœ€åï¼Œæˆ‘ä»¬æ¨ªå‘å¯¹æ¯”ä¸‰ç§æƒé‡æ›´æ–°æ–¹å¼ï¼Œæµ…æµ…åˆ†äº«æˆ‘ä¸ªäººçš„ä¸€äº›æƒ³æ³•ï¼Œæ¬¢è¿å¤§å®¶æ‰¹è¯„æŒ‡æ­£ã€‚

ç…§ç†ï¼Œæ„Ÿè°¢å‚ä¸æœ¬æ–‡æ¡£è®¨è®ºå’Œæ’°å†™çš„æ‰€æœ‰æœ‹å‹ä»¬ï¼š

zhuoran yinï¼ˆCMUï¼‰ï¼Œchangyi yangï¼ˆCMUï¼‰ï¼Œji liï¼ˆèš‚èšï¼‰ï¼Œchengxi liï¼ˆCMUï¼‰ï¼Œbiao heï¼ˆLinkedinï¼‰ï¼Œjunrong linï¼ˆQwenï¼‰ï¼ŒShan Yuï¼ˆUCLAï¼‰ï¼ŒXinyuan Tongï¼ˆchenyang çš„å°å—å–½ï¼‰ï¼Œchenyang zhaoï¼ˆAmazonï¼‰

æ’åæŒ‰ç…§å¾®ä¿¡ç¾¤çš„æˆå‘˜é¡ºåº ğŸ˜‚

## verl å½“ä¸­ co-locate ç­–ç•¥çš„æƒé‡æ›´æ–°

ä»é€»è¾‘ä¸Šï¼Œåœ¨ co-locate ç­–ç•¥ä¸‹çš„æƒé‡æ›´æ–°éƒ½æ˜¯ç±»ä¼¼çš„ï¼Œæˆ‘ä»¬ä»¥ FSDP training backend ä¸ºä¾‹ï¼Œç»™å‡ºä¸€ä¸ªç®€åŒ–è€Œé€šç”¨çš„æ›´æ–°æµç¨‹ï¼Œæ ¸å¿ƒå°±æ˜¯è¿™æ ·ä¸€ä¸ª[ä»£ç ç‰‡æ®µ](https://github.com/volcengine/verl/blob/0508af25b66e839772fba8e79d97896bf0d843d3/verl/workers/sharding_manager/fsdp_sglang.py#L160)ï¼š

```python
def _preprocess_tensor_for_update_weights(tensor: torch.Tensor):
    if isinstance(tensor, DTensor):
        return tensor.full_tensor()
    return tensor

async def update_weights(self, params):
    named_tensors = [(k, v) for k, v in params.items()]
    load_format = None
    for tensor_index, (name, tensor) in enumerate(named_tensors):
        serialized_tensor = MultiprocessingSerializer.serialize(_preprocess_tensor_for_update_weights(tensor))

        if self.device_mesh["infer_tp"].get_local_rank() == 0:
            gathered_serialized_tensors = [None for _ in range(self.device_mesh["infer_tp"].mesh.size()[0])]
        else:
            gathered_serialized_tensors = None
        dist.gather_object(
            obj=serialized_tensor,
            object_gather_list=gathered_serialized_tensors,
            dst=self.device_mesh["infer_tp"].mesh.tolist()[0],
            group=self.device_mesh["infer_tp"].get_group(),
        )

        if self.device_mesh["infer_tp"].get_local_rank() == 0:
            await self.inference_engine.update_weights_from_tensor(
                named_tensors=[
                    (
                        name,
                        LocalSerializedTensor(values=gathered_serialized_tensors),
                    )
                ],
                load_format=load_format,
                flush_cache=tensor_index == len(named_tensors) - 1,
            )
```

å‚æ•°æ˜¯é€ä¸ªè¿›è¡Œèšåˆå¹¶ä¸”æ›´æ–°çš„ï¼Œæ›´æ–°å®Œä¸€ä¸ªå‚æ•°å release ä¸€ä¸ªï¼Œç„¶åç»§ç»­å¾ªç¯ã€‚æˆ‘ä»¬ä»¥å•ä¸ªå‚æ•°ä¸ºä¾‹ã€‚å‡è®¾è¿™ä¸ªå‚æ•°çš„ size æ˜¯ `[1024, 1024]`ï¼ŒFSDP çš„ TP size æ˜¯ 4ï¼Œè€Œ SGLang çš„ TP size æ˜¯ 2ã€‚å› æ­¤åœ¨æ›´æ–°å‚æ•°å¼€å§‹å‰ï¼Œ æ¯ä¸ª rank ä¸Šåœ¨ FSDP engine å†…æœ‰ `[256, 1024]` å¤§å°çš„ tensorï¼Œè€Œ SGLang engine æœ‰ `[512, 1024]` å¤§å°çš„ tensorã€‚

1. æƒé‡å¯¼å‡ºï¼šæ¯ä¸ª rank è°ƒç”¨ `_preprocess_tensor_for_update_weights()` å°†å½“å‰å‚æ•°çš„å®Œæ•´ tensor è¿›è¡Œèšåˆï¼Œå®é™…ä¸ŠæŠŠåˆ†æ•£åœ¨å„ä¸ª GPU ä¸Šçš„å‚æ•°åˆ†ç‰‡éƒ½èšåˆåˆ°äº†æ¯ä¸ª rank ä¸Šï¼Œæ¯ä¸ª rank ä¸Šéƒ½æœ‰ä¸€ä»½å½“å‰å‚æ•°çš„å®Œæ•´ tensorã€‚æ­¤æ—¶ï¼Œè¿™ä¸ª parameter ä¼šæœ‰ä¸‰ä»½ï¼Œå‰ä¸¤ä»½æ˜¯ FSDP å’Œ SGLang æœ¬èº«å°±æœ‰çš„ `[512, 1024]` å’Œ `[256, 1024]`ï¼Œç¬¬ä¸‰ä»½æ˜¯ä¸ºäº†èšåˆè€Œå•ç‹¬å¼€è¾Ÿçš„ `[1024, 1024]` å¤§å°çš„ tensorã€‚
2. tensor åºåˆ—åŒ–ï¼šè°ƒç”¨ `MultiprocessingSerializer.serialize()`ï¼Œå°†æ¯ä¸ª rank ä¸Šèšåˆåˆ°çš„å‚æ•°åºåˆ—åŒ–ï¼Œå¾—åˆ°åºåˆ—åŒ–åçš„ handle tupleï¼Œç§°ä¸º `serialized_tensor`ã€‚æ³¨æ„ï¼Œè™½ç„¶åºåˆ—åŒ–ä¼ å…¥çš„å‚æ•°æ˜¯èšåˆå¾—åˆ°çš„é‚£ä¸ª `[1024, 1024]` çš„ tensorï¼Œä½†æ˜¯å®é™…ä¸Šè¿”å›çš„åªæœ‰è¢«åºåˆ—åŒ–çš„ handle tupleã€‚handle tuple è¿‘ä¼¼äºæŒ‡å‘ tensor å®é™…å­˜å‚¨çš„æŒ‡é’ˆï¼Œå­˜æ”¾äº†è™šæ‹Ÿåœ°å€ï¼Œstripeï¼Œsize ç­‰ç­‰ä¿¡æ¯ï¼Œä»¥åŠåç»­åœ¨ SGLang engine ä¾§é‡å»º tensor éœ€è¦å…±äº«çš„ CUDA IPC handlerã€‚
3. èšåˆ handle tuple åˆ° FSDP TP 0ï¼šè™½ç„¶æ¯ä¸ª rank ä¸Šéƒ½èšåˆäº†å½“å‰å‚æ•°çš„å®Œæ•´ tensorï¼Œä½†æ˜¯åªæœ‰ tp 0 é€šè¿‡ `gather_object` æ”¶é›†äº†æ‰€æœ‰ rank çš„ handle tupleã€‚
4. è·¨è¿›ç¨‹ä¼ é€’ï¼šFSDP TP rank 0 å°†æ”¶é›†åˆ°çš„ handle tuple åˆ—è¡¨æ‰“åŒ…ä¸º `LocalSerializedTensor` å¯¹è±¡ç”¨äºåç»­é‡å»ºã€‚æ¥ç€ï¼Œé€šè¿‡è·¨è¿›ç¨‹é€šä¿¡ä¼ é€’ç»™ SGLang Engineã€‚è¿™é‡Œä¼ é€’çš„åªæœ‰åºåˆ—åŒ–åçš„ handle tupleï¼Œè€Œéå®é™…æ•°æ®ã€‚
5. SGLang Engine é‡å»º tensorï¼šSGLang çš„æ¯ä¸ª TP rank è°ƒç”¨ `_unwrap_tensor()`ï¼Œé¡ºç€ `LocalSerializedTensor.get -> MultiprocessingSerializer.deserialize` å‘ä¸‹è°ƒç”¨ï¼Œååºåˆ—åŒ–æ¢å¤äº†åœ¨ FSDP ä¾§èšåˆå¾—åˆ°çš„å®Œæ•´ tensor çš„ handle tupleã€‚æ¥ç€ï¼Œæ„é€ æ–°çš„ python tensor å¯¹è±¡ï¼Œå°†åˆšåˆšæ¢å¤çš„ handle tuple ä½œä¸ºæ–°çš„ Python tensor å¯¹è±¡çš„ handle tupleã€‚æ–°çš„ tensor å¯¹è±¡å’Œ FSDP ä¾§èšåˆå¾—åˆ°çš„å®Œæ•´ tensor å…±äº«äº† handle tupleï¼Œä¹Ÿå…±äº«äº†ä¸€åˆ‡ meta dataï¼Œå¿…ç„¶æŒ‡å‘äº†åŒä¸€å—æ˜¾å­˜ï¼Œå®Œæˆäº†æ‰€è°“çš„ tensor é‡å»ºè¿‡ç¨‹ã€‚
6. SGLang engine load weightsï¼šé‡å»ºåçš„ tensor ä¼ é€’ç»™ `ModelRunner.load_weights`ï¼Œå°†åŸæœ¬è¿™ä¸ª parameter çš„ tensor æ›´æ¢ä¸ºæ–°çš„ tensorï¼Œå®Œæˆæ•´ä¸ªå‚æ•°æ›´æ–°è¿‡ç¨‹ã€‚

ç”±æ­¤ä»¥æ¥ï¼Œå…¶å®åœ¨ä»»æ„ä¸€ä¸ª TP ä¸Šï¼Œåªæ˜¯ä¸´æ—¶åˆ›å»ºäº†ä¸€ä¸ª `[1024, 1024]` çš„ tensorï¼Œç„¶ååŸæœ¬çš„ handler è¢«æ›´æ¢åï¼Œè¿™ä¸ª `[1024, 1024]` çš„ tensor æ‰€ä¸ç”¨çš„é‚£ä¸€åŠä¼šè¢« release æ‰ï¼ŒåŸæœ¬ SGLang engine é‡Œé¢çš„ handler æŒ‡å‘çš„æ—§çš„ tensor ä¼šè¢«é‡Šæ”¾æ‰ï¼Œå¹¶æ²¡æœ‰æ˜¾å­˜æ³„éœ²ã€‚


<div style="text-align: center;">
  <img src="./pics/update_weights.jpg" alt="Update Weights Diagram" style="width:50%;">
</div>

### æƒé‡å¯¼å‡º

æƒé‡å¯¼å‡ºå’Œ handle tuple åºåˆ—åŒ–åœ¨åŒä¸€è¡Œå®Œæˆï¼š

```python
def _preprocess_tensor_for_update_weights(tensor: torch.Tensor):
    if isinstance(tensor, DTensor):
        return tensor.full_tensor()
    return tensor

serialized_tensor = MultiprocessingSerializer.serialize(_preprocess_tensor_for_update_weights(tensor))
```

åœ¨å°†è®­ç»ƒé˜¶æ®µç»“æŸåï¼Œé¦–å…ˆä½¿ç”¨ FSDP `state_dict` å¯¼å‡ºæƒé‡ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œ`state_dict` æ˜¯ä¸€ä¸ª `param name -> tensor` çš„ dictï¼Œè€Œ FSDP ä¸­çš„ `state_dict` çš„å€¼å–å†³äº `StateDictType` çš„æ¨¡å¼ã€‚FSDP å†…ç½®äº†ä¸‰ç§æ¨¡å¼ï¼š`FULL_STATE_DICT`ã€`SHARDED_STATE_DICT` ä»¥åŠ `LOCAL_STATE_DICT`ã€‚æˆ‘ä»¬åˆ†åˆ«æ¥çœ‹çœ‹è¿™ä¸‰ç§æ¨¡å¼å‡è®¾æœ‰ä¸€ä¸ª 4-rank FSDP è®­ç»ƒï¼Œå‚æ•°å½¢çŠ¶ä¸º `[1024, 1024]`ï¼Œæ¯ä¸ª rank è´Ÿè´£ 1/4 çš„å‚æ•°ï¼š

1. `FULL_STATE_DICT`

```python
# æ¯ä¸ª rank éƒ½å¾—åˆ°å®Œæ•´çš„å‚æ•°
{
    'layer1.weight': tensor([1024, 1024]),  # å®Œæ•´å¼ é‡ï¼Œæ¯ä¸ª rank éƒ½ç›¸åŒ
    'layer1.bias': tensor([1024]),          # å®Œæ•´å¼ é‡ï¼Œæ¯ä¸ª rank éƒ½ç›¸åŒ
    # ... æ‰€æœ‰å‚æ•°éƒ½æ˜¯å®Œæ•´çš„
}
```

2. `LOCAL_STATE_DICT`  

```python
# æ¯ä¸ª rank åªå¾—åˆ°è‡ªå·±è´Ÿè´£çš„åˆ†ç‰‡
{
    'layer1.weight': tensor([256, 1024]),  # å½“å‰ rank çš„åˆ†ç‰‡ (1/4)
    'layer1.bias': tensor([256]),          # å½“å‰ rank çš„åˆ†ç‰‡ (1/4)
    # ... åªæœ‰å½“å‰ rank è´Ÿè´£çš„å‚æ•°åˆ†ç‰‡
}
```

3. `SHARDED_STATE_DICT`

```python
# æ¯ä¸ª rank å¾—åˆ°åŒ…å«å…ƒä¿¡æ¯çš„åˆ†ç‰‡å¯¹è±¡
{
    'layer1.weight': ShardedTensor {
        metadata: {
            "world_size": 4,           # æ€»åˆ†ç‰‡æ•°
            "rank": 1,                 # å½“å‰åˆ†ç‰‡ç´¢å¼• (0-3)
            "shape": [1024, 1024],     # å®Œæ•´å¼ é‡çš„å½¢çŠ¶
            "dtype": torch.float16,    # æ•°æ®ç±»å‹
        },
        local_shard: tensor([256, 1024]),  # å½“å‰ rank çš„åˆ†ç‰‡æ•°æ®
    },
    'layer1.bias': ShardedTensor {
        metadata: { "world_size": 4, "rank": 1, "shape": [1024], "dtype": torch.float16 },
        local_shard: tensor([256]),    # å½“å‰ rank çš„åˆ†ç‰‡æ•°æ®
    }
}
```

å…¶ä¸­ `FULL_STATE_DICT` æ˜¯æœ€æœ´ç´ çš„å®ç°æ–¹å¼ã€‚`LOCAL_STATE_DICT` åªä¿å­˜å½“å‰ rank æ‰€å­˜å‚¨çš„éƒ¨åˆ†ï¼Œæ²¡æœ‰åˆ‡ç‰‡ä¿¡æ¯ï¼Œè€Œ `SHARDED_STATE_DICT` åœ¨ `LOCAL_STATE_DICT` åŸºç¡€ä¸Šï¼Œé¢å¤–å­˜æœ‰å½“å‰ rank è´Ÿè´£çš„å‚æ•°åˆ†ç‰‡å’Œåˆ‡ç‰‡ä¿¡æ¯ã€‚é€šè¿‡ `full_tensor()` å°±å¯ä»¥å°† `SHARDED_STATE_DICT` çŠ¶æ€ä¸‹çš„ tensor èšåˆèµ·æ¥ï¼š

```python
if isinstance(tensor, DTensor):
    return tensor.full_tensor()
```

### tensor åºåˆ—åŒ–

åºåˆ—åŒ–ç”± `MultiprocessingSerializer.serialize` å®Œæˆï¼Œå¦‚åŒå‰æ–‡æ‰€è¯´ï¼Œåºåˆ—åŒ–ä¸€ä¸ª tensor å®é™…ä¸Šå¾—åˆ°çš„è¿”å›å€¼æ˜¯åºåˆ—åŒ–åçš„ handlerï¼Œæˆ–è€…æ›´ä¸¥è°¨çš„è¯´æ³•æ˜¯ handler tupleã€‚æˆ‘ä»¬æ¥çœ‹çœ‹åºåˆ—åŒ–æœ€åå±‚å±‚å‘ä¸‹è°ƒç”¨çš„ `reduce_tensor()` å‡½æ•°çš„è¿”å›å€¼ï¼š

```python
 return (
            rebuild_cuda_tensor, # é‡å»ºå‡½æ•°
            (
                type(tensor), # tensor ç±»å‹
                tensor.size(), # tensor å¤§å°
                tensor.stride(), # tensor æ­¥é•¿
                tensor_offset,  # tensor åœ¨ storage ä¸­çš„åç§»é‡
                type(storage), # storage ç±»å‹
                tensor.dtype, # tensor æ•°æ®ç±»å‹
                device, # tensor è®¾å¤‡
                handle,  # identifier which CUDA allocation is the storage in.
                storage_size_bytes,  # storage å¤§å°
                storage_offset_bytes,  # storage åœ¨ CUDA allocation ä¸­çš„åç§»é‡
                tensor.requires_grad, # tensor æ˜¯å¦éœ€è¦æ¢¯åº¦
                ref_counter_handle, # å¼•ç”¨è®¡æ•°å™¨ handle
                ref_counter_offset, # å¼•ç”¨è®¡æ•°å™¨åç§»é‡
                event_handle, # äº‹ä»¶ handle
                event_sync_required, # äº‹ä»¶åŒæ­¥æ˜¯å¦éœ€è¦
            ),
        )
```

å¯è§ï¼Œå¯¹ä¸€ä¸ª CUDA Tensor è°ƒç”¨ `reduce_tensor`ï¼Œå®é™…ä¸Šè¿”å›çš„æ˜¯ä¸€ä¸ª Python Tupleï¼ŒåŒ…å«äº†é‡å»º Tensor æ‰€éœ€çš„ä¸€åˆ‡ï¼Œè€Œç»ä¸åŒ…å«å®é™…å­˜å‚¨çš„æ•°æ®æœ¬èº«ã€‚æ¥ç€ï¼Œè¿™ä¸ª handler tuple é€šè¿‡è¿›ç¨‹é—´é€šä¿¡ï¼ˆæ¯”å¦‚ zmqï¼‰ä¼ é€’ç»™æ¥æ”¶æ–¹ã€‚æ¥æ”¶æ–¹æ‹¿åˆ°çš„è‡ªç„¶ä¹Ÿä¸æ˜¯æ•°æ®æœ¬èº«ï¼Œè€Œæ˜¯ä¸€ç»„å¯ä»¥å¸®åŠ©é‡æ–°æ‰¾åˆ°ï¼ˆé‡å»ºï¼‰è¿™ä¸ª tensor çš„ handlerï¼Œæˆ‘ä»¬åœ¨åæ–‡ä¸­ä¼šä»¥ handler tuple æ¥æŒ‡ä»£ã€‚

### èšåˆ handler

æ³¨æ„åˆ°ï¼Œåœ¨èšåˆ tensor å¹¶ä¸”åºåˆ—åŒ–çš„è¿‡ç¨‹ä¸­ï¼Œä»æœªæŒ‡å®šä¸åŒ tp çš„åŒºåˆ«ï¼Œå¯è§å¯¹äºå½“å‰æ­£åœ¨æ›´æ–°çš„å‚æ•°ï¼Œæ¯ä¸ª tp ä¸Šéƒ½ä¼šé¢å¤–ç”³è¯·ä¸€ç‰‡æ˜¾å­˜ç©ºé—´ï¼Œèšåˆå¾—åˆ°å®Œæ•´çš„ tensorï¼Œå¹¶ä¸”åºåˆ—åŒ–å¾—åˆ°å…¶ handler tupleã€‚è€ƒè™‘åˆ°å•ä¸ªå‚æ•°å¹¶ä¸å¤§ï¼Œè¿™ç§åšæ³•ä»æ—§å®‰å…¨ã€‚æ¥ç€ï¼Œæ¯ä¸ª tp éƒ½å¾—åˆ° handle tuple åï¼Œå°† handle tuple ä¹Ÿè¿›è¡Œèšåˆï¼š

```python
if self.device_mesh["infer_tp"].get_local_rank() == 0:
    gathered_serialized_tensors = [None for _ in range(self.device_mesh["infer_tp"].mesh.size()[0])]
else:
    gathered_serialized_tensors = None
dist.gather_object(
    obj=serialized_tensor,
    object_gather_list=gathered_serialized_tensors,
    dst=self.device_mesh["infer_tp"].mesh.tolist()[0],
    group=self.device_mesh["infer_tp"].get_group(),
)
```

è¿™é‡Œä½¿ç”¨ `dist.gather_object` æ¥èšåˆæ‰€æœ‰ TP rank çš„ handler tupleã€‚ä¸ `all_gather` ä¸åŒï¼Œ`gather_object` æ˜¯ä¸€ä¸ªå•å‘èšåˆæ“ä½œï¼š

- æ‰€æœ‰ TP rank éƒ½å‚ä¸å‘é€ï¼šæ¯ä¸ª rank éƒ½è°ƒç”¨ `dist.gather_object` å‘é€è‡ªå·±çš„ `serialized_tensor`
- åªæœ‰ç›®æ ‡ rank æ¥æ”¶ï¼šåªæœ‰ `dst` æŒ‡å®šçš„ rankï¼ˆè¿™é‡Œæ˜¯ TP rank 0ï¼‰ä¼šæ¥æ”¶åˆ°å®Œæ•´çš„ handler tuple åˆ—è¡¨
- å…¶ä»– rank ä¸æ¥æ”¶ï¼šéç›®æ ‡ rank çš„ `gathered_serialized_tensors` ä¿æŒä¸º `None`

è¿™æ ·è®¾è®¡çš„å¥½å¤„æ˜¯ï¼šåç»­åªéœ€è¦ TP rank 0 å°†æ”¶é›†åˆ°çš„æ‰€æœ‰ handler tuple ä¼ é€’ç»™ SGLang Engineï¼Œé¿å…äº†æ¯ä¸ª rank éƒ½æŒæœ‰å®Œæ•´ handler tuple åˆ—è¡¨çš„å†…å­˜æµªè´¹ã€‚

### SGLang å®Œæˆ tensor é‡å»º

ä¸‹ä¸€æ­¥ï¼Œå°†èšåˆå¥½çš„ handler tuple  list ä¼ é€’ç»™ SGLang Engineï¼Œå¹¶ä¸”è°ƒç”¨ `update_weights_from_tensor` æ¥å£ã€‚

```python
if self.device_mesh["infer_tp"].get_local_rank() == 0:
    await self.inference_engine.update_weights_from_tensor(
        named_tensors=[
            (
                name,
                LocalSerializedTensor(values=gathered_serialized_tensors),
            )
        ],
        load_format=load_format, # å®é™…ä¸Šä¼ å…¥çš„æ˜¯ None
        flush_cache=tensor_index == len(named_tensors) - 1,
    )
```

æ¥ç€ï¼Œä»£ç æ¥åˆ° SGLang ä¸€ä¾§ï¼Œæˆ‘ä»¬æŸ¥çœ‹ [ModelRunner.update_weights_from_tensor](https://github.com/sgl-project/sglang/blob/392e441ad17c78b68638f2d959fcf592d19b4834/python/sglang/srt/model_executor/model_runner.py#L774) çš„æºç ã€‚æ³¨æ„åˆ°ï¼Œå¯¹äº SGLang è€Œè¨€ï¼Œ`ModelRunner` æ˜¯ä¸€ä¸ªéå¸¸åº•å±‚çš„ç±»äº†ï¼Œå†å¾€ä¸Šæ˜¯æœ‰ TpModelManger çš„ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™ä¸ª `update_weights_from_tensor` å®é™…ä¸Šæ˜¯ SGLang çš„æ¯ä¸ª TP rank éƒ½ä¼šè°ƒç”¨ã€‚å…·ä½“çš„ SGLang æ¶æ„å¯ä»¥å‚è€ƒæ­¤å›¾ï¼š

<div style="text-align: center;">
  <img src="../../../../sglang/code-walk-through/sglang-architecture.svg" alt="SGLang Architecture" style="width:50%;">
</div>

æˆ‘ä»¬è¿˜æ˜¯å›åˆ°ä¸»çº¿ä¸Šï¼Œç ”ç©¶ä¸‹ SGLang åº•å±‚åœ¨æ¯ä¸ª TP rank ä¸Šæ‰§è¡Œçš„ `update_weights_from_tensor` æ¥å£ï¼š

```python
def update_weights_from_tensor(
    self,
    named_tensors: List[Tuple[str, Union[torch.Tensor, "LocalSerializedTensor"]]],
    load_format: Optional[str] = None,
):
    named_tensors = [
        (name, _unwrap_tensor(tensor, tp_rank=self.tp_rank))
        for name, tensor in named_tensors
    ]
    if load_format == "direct":
        _model_load_weights_direct(self.model, named_tensors)
    elif load_format in self.server_args.custom_weight_loader:
        custom_loader = dynamic_import(load_format)
        custom_loader(self.model, named_tensors)
    elif load_format is None:
        self.model.load_weights(named_tensors)
    else:
        raise NotImplementedError(f"Unknown load_format={load_format}")
    return True, "Success"


def _unwrap_tensor(tensor, tp_rank):
    if isinstance(tensor, LocalSerializedTensor):
        monkey_patch_torch_reductions()
        tensor = tensor.get(tp_rank)
    return tensor.to(torch.cuda.current_device())


@dataclass
class LocalSerializedTensor:
    """torch.Tensor that gets serialized by MultiprocessingSerializer (which only serializes a pointer and not the data).
    The i-th element in the list corresponds to i-th rank's GPU."""

    values: List[bytes]

    def get(self, rank: int):
        return MultiprocessingSerializer.deserialize(self.values[rank])
```

æ¯ä¸ª tp rank è°ƒç”¨ `_unwrap_tensor` æ¥å£ï¼Œåœ¨ `tensor.get(tp_rank)` ä¸€æ­¥ä¸­ï¼Œé¡ºç€ `LocalSerializedTensor.get -> MultiprocessingSerializer.deserialize` å‘ä¸‹è°ƒç”¨ï¼Œååºåˆ—åŒ–æ¢å¤äº†åœ¨ FSDP ä¾§èšåˆå¾—åˆ°çš„å®Œæ•´ tensor çš„ handler tupleã€‚æ¥ç€ï¼Œæ„é€ æ–°çš„ python tensor å¯¹è±¡ï¼Œå°†åˆšåˆšæ¢å¤çš„ handler tuple ä½œä¸ºæ–°çš„ Python tensor å¯¹è±¡çš„ handle tupleã€‚è¿™æ ·ä¸€æ¥ï¼Œé€šè¿‡å…±äº« handle çš„æœºåˆ¶ï¼Œæ–°çš„ tensor å¯¹è±¡å’Œ FSDP ä¾§èšåˆå¾—åˆ°çš„å®Œæ•´ tensor å…±äº«äº†ä¸€åˆ‡ meta dataï¼Œè‡ªç„¶ä¹ŸæŒ‡å‘äº†åŒä¸€å—æ˜¾å­˜ï¼Œå®Œæˆäº†æ‰€è°“çš„ tensor é‡å»ºè¿‡ç¨‹ã€‚é‡å»ºç»“æŸåï¼Œè¿™ä¸ªæ–°çš„ tensor å¯¹è±¡è¢«ä¼ é€’ç»™ `ModelRunner.load_weights`ï¼Œåœ¨ SGLang åº•å±‚æŠŠåŸæœ¬çš„ tensor æ›´æ¢æ‰å³å¯ã€‚

## slime ä¸­çš„æƒé‡åŒæ­¥ç­–ç•¥

æœ‰äº†å‰æ–‡å¯¹ `update_weights_from_tensor` çš„ç†è§£ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥åˆ†æ slime åœ¨ co-locate ç­–ç•¥ä¸‹çš„æƒé‡åŒæ­¥ç­–ç•¥ã€‚slime æ˜¯ä¸€å¥—åŒæ—¶æ”¯æŒ dis-aggregate å’Œ co-locate ç­–ç•¥çš„è½»é‡çº§æ¡†æ¶ã€‚åœ¨æŠ€æœ¯é€‰å‹ä¸Šï¼Œslime é€‰æ‹©äº† Ray ä½œä¸ºé€šä¿¡æ¡†æ¶ï¼ŒTraining Backend é€‰æ‹© Megatronï¼ŒRollout Backend é€‰æ‹© SGLangã€‚å‡ºäºè®¾è®¡å’ŒæŠ€æœ¯é€‰å‹çš„ç²¾ç®€ï¼Œæ•´ä¸ª slime çš„ä»£ç éå¸¸æ¸…çˆ½ã€‚æˆ‘ä»¬åç»­ä¼šæœ‰æ›´å¤šåˆ†äº«ã€‚è¿™é‡Œå…ˆé¡ºç€ä¸Šæ–‡ç»§ç»­åˆ†äº« slime åœ¨ co-locate ç­–ç•¥ä¸‹çš„æƒé‡åŒæ­¥ç­–ç•¥ã€‚

åœ¨ co-locate ç­–ç•¥ä¸‹ï¼Œrollout engine å’Œ training engine éœ€è¦ä¸æ–­ offload ä¸ uploadï¼Œæ¥äº’ç›¸è®©å‡ºæ˜¾å­˜ã€‚SGLang é€šè¿‡ torch memory savor è¿›è¡Œ offload ç®¡ç†ï¼Œè€Œ Megatron é€šè¿‡ CuMemAllocator è¿›è¡Œ offload ç®¡ç†ã€‚ä»é€»è¾‘ä¸Šï¼ŒRollout ç»“æŸåï¼Œé€šè¿‡ mem savor ç›´æ¥ release æ‰ç‰©ç†å ç”¨ï¼Œç„¶åå¯åŠ¨ megatron è¿›è¡Œè®­ç»ƒã€‚è®­ç»ƒç»“æŸåï¼Œå°† megatron çš„ model weights å’Œ optimizer å…¨éƒ½ offload åˆ° CPU ä¸Šï¼Œç„¶åå°† SGLang çš„ model weights è¿˜æœ‰ KV cache upload åˆ° GPU ä¸Šã€‚

è¿™æ—¶å€™å°±å¾ˆæœ‰æ„æ€äº†ã€‚ä¸ºäº†æ¥ä¸‹æ¥çš„å‚æ•°æ›´æ–°ï¼Œslime ä¼šåˆ†æ¡¶å°† megatron çš„ model weights upload åˆ° GPU ä¸Šï¼Œç„¶åå’Œ verl ä¸­çš„æ“ä½œç±»ä¼¼ï¼Œèšåˆå¾—åˆ°å®Œæ•´çš„ tensorï¼Œç„¶ååºåˆ—åŒ–å¾—åˆ° handle tupleï¼Œç„¶åä¼ é€’ handle tuple ç»™ rollout engineï¼Œè°ƒç”¨ `update_weights_from_tensor` æ¥å£å®Œæˆå‚æ•°æ›´æ–°ã€‚

æœ‰ä¸€ä¸ªé—®é¢˜éå¸¸å€¼å¾—åˆ†äº«ï¼šä¸ºä»€ä¹ˆ slime éœ€è¦å…ˆå°† megatron çš„ model weights offload æ‰å† upload ä¸Šæ¥ï¼Œç›´æ¥ä¿ç•™åœ¨ GPU ä¸Šä¸è¡Œå—ï¼Ÿ

ç­”æ¡ˆåœ¨äº slime å¯¹æƒé‡æ›´æ–°çš„å¤„ç†æ›´ä¸ºç²¾ç»†ã€‚å…·ä½“æ¥è¯´ï¼Œä¸ºäº†é¿å…è¶…å¤§è§„æ¨¡ MOE model ç›´æ¥æ•´ä¸ª model weights upload åˆ° GPU ä¸Šå’Œ SGLang å¹¶å­˜å¯¼è‡´ OOMï¼Œslime å¯¹ params è¿›è¡Œäº†åˆ†æ¡¶æ›´æ–°ã€‚æ¯æ¬¡åªæ›´æ–°æ¡¶å†…çš„ä¸€å°éƒ¨åˆ†å‚æ•°ã€‚å¦‚æœé‡‡ç”¨å’Œ verl ç±»ä¼¼çš„æ–¹æ³•ï¼Œå°†æ•´ä¸ª FSDP çš„å‚æ•°ä¿ç•™åœ¨ GPU ä¸Šï¼Œå¯¹äºéå¸¸å¤§çš„æ¨¡å‹ï¼Œé™¤é tp å¼€çš„å¾ˆå¤§ï¼Œè¿˜æ˜¯å¾ˆå®¹æ˜“ OOM çš„ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å¯ä»¥å‘ç°ï¼Œslime çš„ update weights é˜¶æ®µå…¶å®æ˜¾å­˜å ç”¨å‡ ä¹åªæœ‰ SGLang çš„ CUDA Graphï¼Œmodel weights å’Œ KV cacheï¼Œmegatron upload ä¸Šæ¥çš„å‚æ•°å ç”¨æ˜¾å­˜å¾ˆå°‘ã€‚æ‰€ä»¥ç†è®ºä¸Š slime ä¸éœ€è¦æˆ‘ä»¬åœ¨ verl é‡Œé¢åšçš„é‚£å¥—å¤æ‚çš„ [mutli-stage wake up](https://hebiao064.github.io/rl-memory-management) æœºåˆ¶ï¼Œä¹Ÿå¯ä»¥è®¾ç½® SGLang çš„ mem static fraction åœ¨ä¸€ä¸ªå¾ˆé«˜çš„æ°´å¹³ã€‚ä¸è¿‡å¯æƒœï¼Œç”±äº megatron çš„ offload æ²¡æœ‰é‚£ä¹ˆå®Œç¾ï¼Œç›®å‰çš„ mem static è¿˜æœ‰æ”¹è¿›ç©ºé—´ã€‚æˆ‘ä»¬ LMSYS ä¹Ÿåœ¨å’Œ slime å›¢é˜Ÿé€šåŠ›åˆä½œï¼Œå±•å¼€ä¼˜åŒ–ã€‚

å¥½äº†ï¼Œæœ‰äº†è¿™äº›åŸºç¡€ï¼Œæˆ‘ä»¬æ¥é€Ÿè§ˆ slime åœ¨ co-locate ç­–ç•¥ä¸‹å…·ä½“çš„æƒé‡æ›´æ–°ï¼š

1. å»ºç«‹é€šè®¯ç»„ï¼šä¸ºäº†åœ¨æ›´æ–°æƒé‡æ—¶èƒ½å¤Ÿèšåˆ handle tupleï¼Œåœ¨å¯åŠ¨ slime æ—¶å°±ä¼šå»ºç«‹ä¸€ä¸ªåŒ…å«æ‰€æœ‰ rollout engine å’Œ training engine çš„ process groupï¼Œä¹Ÿå³ `_ipc_gather_group`ï¼Œå¹¶è®¾å®šé€šä¿¡åç«¯ä¸º `nccl`ã€‚
2. æ¸…ç©º kv cache: rollout engine æ›´æ–°å‚æ•°åï¼Œæ‰€æœ‰å…ˆå‰çš„ kv cache æ— æ³•ç»§ç»­ä½¿ç”¨ã€‚æ•…è€Œåœ¨ rollout engine æ›´æ–°å‚æ•°å‰ï¼Œå…ˆå‘æ‰€æœ‰ rollout engine å‘é€ flush cache æ¥æ¸…é™¤ radix treeï¼Œç¡®ä¿æ—§çš„ kv cache ä¸å½±å“æ–°ä¸€è½®çš„ rolloutã€‚
3. æƒé‡èšåˆ: æ„é€ åˆ†æ¡¶ï¼Œç„¶åå°†æ¡¶å†…çš„ megatron model weights ä» CPU upload åˆ° GPUã€‚æ¥ç€ï¼Œå…ˆåœ¨ PP/EP ç»„å†…åš `broadcast`ï¼Œåœ¨ PP/EP ç»´åº¦ä¿è¯æ¯ä¸ª rank æ‹¥æœ‰å®Œæ•´å‚æ•°ï¼Œå†é€šè¿‡ `dist.all_gather` + `torch.cat` å®Œæˆ TP å±‚é¢çš„èšåˆï¼Œå¾—åˆ°å®Œæ•´çš„ tensorã€‚verl ä¸»è¦æ˜¯ç»´æŠ¤åªæœ‰ TP å±‚é¢çš„å‚æ•°ï¼Œå¯ä»¥é€šè¿‡ `full_tensor` ç›´æ¥å°†è¿™ä¸€ç»´åº¦çš„ `DTensor` èšåˆæˆ tensorã€‚åœ¨ slime ä¸­ï¼Œå­˜åœ¨ä¸åŒåˆ‡åˆ†æ–¹å¼çš„å¤šç»´åº¦å¹¶è¡Œï¼Œæ‰€ä»¥ä¸èƒ½ç®€å•åœ°ç”¨ `full_tensor`ï¼Œéœ€è¦æ‰‹åŠ¨èšåˆã€‚
4. tensor åºåˆ—åŒ–å¹¶èšåˆ handle tuple: ä¸ verl ä¸€æ ·ï¼Œä½¿ç”¨ `MultiprocessingSerializer.serialize` è¿›è¡Œåºåˆ—åŒ–ï¼Œå¾—åˆ° handle tupleï¼›æ¥ç€ï¼Œé€šè¿‡ `dist.gather()` å®Œæˆ handle tuple çš„èšåˆã€‚
5. ä¼ é€’ handler tuples å¹¶é‡å»ºå‚æ•°å®Œæˆæ›´æ–°: è¿™é‡Œå’Œå‰æ–‡éå¸¸ç±»ä¼¼äº†ï¼Œå°†èšåˆçš„ handler tuple ä¼ é€’ç»™ SGLang Enginesï¼Œç„¶ååœ¨ SGLang ä¾§ååºåˆ—åŒ–ï¼Œé‡å»ºå‚æ•°ï¼Œç„¶åè°ƒç”¨ `ModelRunner.load_weights` å®Œæˆå‚æ•°æ›´æ–°ã€‚

ä»¥ä¸‹åˆ—ä¸¾ä¸€äº›ç›¸å…³ä»£ç ä¾¿äºç†è§£ï¼š

<details>
<summary>slime æƒé‡æ›´æ–°ä»£ç </summary>

```python
def update_weights_from_tensor(self):
    pp_size = mpu.get_pipeline_model_parallel_world_size()
    ep_size = mpu.get_expert_model_parallel_world_size()
    rank = dist.get_rank()
    if rank == 0:
        ray.get([engine.reset_prefix_cache.remote() for engine in self.rollout_engines])
    dist.barrier()
    for param_infos in self.param_info_buckets:
        # init params:
        params = []
        for info in param_infos:
            if dist.get_rank() == info.src_rank:
                params.append(
                    torch.nn.Parameter(self.params_dict[info.name].to(device=torch.cuda.current_device()))
                )
            else:
                params.append(torch.empty(info.shape, dtype=info.dtype, device=torch.cuda.current_device()))

        # broadcast params across pp ranks
        if pp_size > 1:
            handles = []
            for info, param in zip(param_infos, params):
                if info.src_rank in dist.get_process_group_ranks(mpu.get_pipeline_model_parallel_group()):
                    handles.append(
                        torch.distributed.broadcast(
                            param, src=info.src_rank, group=mpu.get_pipeline_model_parallel_group(), async_op=True
                        )
                    )
            for handle in handles:
                handle.wait()

        # broadcast params across ep ranks
        if ep_size > 1:
            handles = []
            for info, param in zip(param_infos, params):
                if ".experts." in info.name:
                    src_rank = (
                        info.src_rank
                        if info.src_rank in dist.get_process_group_ranks(mpu.get_expert_model_parallel_group())
                        else rank
                    )
                    handles.append(
                        torch.distributed.broadcast(
                            param, src=src_rank, group=mpu.get_expert_model_parallel_group(), async_op=True
                        )
                    )
            for handle in handles:
                handle.wait()

        converted_named_tensors = []
        for info, param in zip(param_infos, params):
            # set tp attrs
            for key, value in info.attrs.items():
                setattr(param, key, value)
            # gather param
            param = update_weight_utils.all_gather_param(info.name, param)
            param = update_weight_utils.remove_padding(info.name, param, self.vocab_size)
            converted_named_tensors.extend(
                update_weight_utils.convert_to_hf(
                    self.args, self.model_name, info.name, param, self.quantization_config
                )
            )
        self._update_converted_params_from_tensor(converted_named_tensors)
        
def all_gather_param(name, param):
    if "expert_bias" in name:
        return param

    assert hasattr(param, "tensor_model_parallel"), f"{name} does not have tensor_model_parallel attribute"
    if not param.tensor_model_parallel:
        # if mpu.get_tensor_model_parallel_world_size() == 1:
        return param.data

    if ".experts." in name:
        tp_size = mpu.get_expert_tensor_parallel_world_size()
        tp_group = mpu.get_expert_tensor_parallel_group()
    else:
        tp_size = mpu.get_tensor_model_parallel_world_size()
        tp_group = mpu.get_tensor_model_parallel_group()

    param_partitions = [torch.empty_like(param.data) for _ in range(tp_size)]
    dist.all_gather(param_partitions, param.data, group=tp_group)
    partition_dim = param.partition_dim
    assert param.partition_stride == 1, "partition_stride != 1 is not supported"
    # TODO: here we did an extra copy during concat, maybe merge this with convert_to_hf is better?
    # TODO: check only GLU is used.
    if "linear_fc1.weight" in name:
        param_partitions = [p.chunk(2, dim=0) for p in param_partitions]
        param_partitions = [p[0] for p in param_partitions] + [p[1] for p in param_partitions]
    # this is bug in megatron's grouped moe.
    if "linear_fc2.weight" in name:
        if partition_dim == 0:
            partition_dim = 1
    param = torch.cat(param_partitions, dim=partition_dim)
    return param

def _update_converted_params_from_tensor(self, converted_named_tensors):
    ipc_handle = MultiprocessingSerializer.serialize(converted_named_tensors, output_str=True)
    ipc_handles = (
        [None] * dist.get_world_size(self._ipc_gather_group) if self._ipc_gather_src == dist.get_rank() else None
    )
    dist.gather_object(
        ipc_handle,
        object_gather_list=ipc_handles,
        dst=self._ipc_gather_src,
        group=self._ipc_gather_group,
    )

    if dist.get_rank() == self._ipc_gather_src:
        ref = self._ipc_engine.update_weights_from_tensor.remote(
            ipc_handles=ipc_handles,
        )
        ray.get(ref)

    converted_named_tensors.clear()
    torch.cuda.empty_cache()
```

</details>

## ä¸‰ç§æƒé‡æ›´æ–°æ–¹å¼çš„å¯¹æ¯”

æœ€åï¼Œæˆ‘ä»¬å¯¹æ¯”ä¸‰ç§æƒé‡æ›´æ–°æ–¹å¼ã€‚çŸ¥æ˜“è¡Œéš¾ï¼Œæˆ‘ä¸ªäººçš„ RL ç³»ç»Ÿå¼€å‘å°±æ˜¯ä»æƒé‡æ›´æ–°æ¥å£å¼€å§‹çš„ã€‚RL ç³»ç»Ÿæ— éå°±æ˜¯éœ€è¦æŠŠ inference engine æ¥è¿›å»ï¼Œæ¯æ¬¡åšä¸€ç³»åˆ—æ¨ç†ï¼Œç„¶åè®­ç»ƒå®Œäº†æ›´æ–°æƒé‡å°±è¡Œäº†ï¼›å¯æ˜¯å…¶ä¸­çš„å¿ƒé…¸æ»‹å‘³ï¼Œè‡ªç„¶åªæœ‰çœŸçš„æ‰“ç£¨è¿‡ï¼Œæ‰èƒ½ä½“ä¼šã€‚æˆ‘åœ¨è¿™é‡Œæ¢³ç†ä¸‰ç§æƒé‡æ›´æ–°çš„æ¥å£ï¼Œæœ¬è´¨ä¸Šä¹Ÿæ˜¯åœ¨æ¢³ç†ä¸¤ç§ï¼š

1. `update_weights_from_disk`ï¼šè¿™æ˜¯æœ€ç®€å•çš„æ¥å£ï¼Œåœ¨ä¿è¯ engine è¿è¡Œçš„æƒ…å†µä¸‹ï¼Œç›´æ¥ä»ç£ç›˜è¯»å–æƒé‡ï¼Œç„¶åå±‚å±‚å‘ä¸‹è°ƒç”¨ `ModelRunner.load_weights` æ¥å£æ›´æ–°æƒé‡ã€‚å®é™…ä½¿ç”¨ä¸Šï¼Œåœ¨ RL è¿‡ç¨‹ä¸­æ¯æ¬¡å®Œæˆ target policy çš„æ›´æ–°ï¼Œå°† target policy å­˜ä¸‹æ¥ï¼Œç„¶åå†è°ƒç”¨ `update_weights_from_disk` æ¥å£æ›´æ–°å³å¯ã€‚å¬ä¸Šå»æ•ˆç‡ä¸é«˜ï¼Œæ¯•ç«Ÿè¦å°†æƒé‡å†™å…¥ä¸‹å±‚å­˜å‚¨ï¼Œç„¶åå†è¯»å–ä¸Šæ¥ï¼Œæ•´ä½“é€Ÿåº¦ç”±ä¸‹å±‚å­˜å‚¨çš„ I/O æ•ˆç‡å†³å®šã€‚ç„¶è€Œï¼Œå€˜è‹¥ä¸‹å±‚å­˜å‚¨çš„è¯»å†™é€Ÿåº¦è¶³å¤Ÿå¿«ï¼Œæˆ–è€… SGLang Engine èƒ½å¤Ÿé«˜æ•ˆå¹¶è¡Œåœ°å»è¯»å–ç£ç›˜ï¼Œæœªå¿…è¿™æ˜¯ä¸ªä¸èƒ½é‡‡ç”¨çš„æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œåœ¨å†™å…¥ä¸‹å±‚å­˜å‚¨çš„æ—¶å€™ï¼Œé¡ºå¸¦ä¹Ÿå®Œæˆäº† checkpoint çš„å†™å…¥ã€‚ç”¨å…¶ä»–çš„æ¥å£æ¥æ›´æ–°æƒé‡ï¼Œcheckpoint çš„ç®¡ç†è¿˜éœ€è¦æœ‰å¦ä¸€å¥—å¼‚æ­¥é€»è¾‘ã€‚æœ€åï¼Œæˆ‘è®¤ä¸º `update_weights_from_disk` æ˜¯æœ€èƒ½å¤Ÿæ»¡è¶³ rollout åŠ¨æ€æ‰©ç¼©å®¹éœ€æ±‚çš„æ¥å£ã€‚å€˜è‹¥åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå‘ç° Rollout æ…¢çš„å‡ºå¥‡ï¼Œä½¿ç”¨ `update_weights_from_distributed` æ–¹æ¡ˆçš„è¯ï¼Œä¸ºäº†è¿›è¡Œæ‰©ç¼©å®¹ï¼Œå¾—å…ˆå°†å·²æœ‰çš„é€šè®¯ç»„æš‚åœï¼Œç„¶ååŠ å…¥æ–°çš„ Rollout Engineï¼Œé‡æ–°å»ºç«‹é€šè®¯ç»„ï¼Œè¿™ä¸ªè¿‡ç¨‹çš„å·¥ç¨‹å¤æ‚ç¨‹åº¦å¯æƒ³è€ŒçŸ¥ã€‚å¦‚æœä½¿ç”¨ `update_weights_from_disk` æ¥å£ï¼Œç›´æ¥åœ¨ Rollout Engine ä¸Šå±‚çš„ DP router ä¸ŠåŠ å…¥ä¸€ä¸ªæ–°çš„ Rollout Engineï¼Œç„¶åæ‰€æœ‰ Rollout Engine ä»åŒä¸€ä¸ª checkpoint ä¸Šè¯»å–æƒé‡ç”¨äºæ›´æ–°å³å¯ã€‚`update_weights_from_disk` åœ¨ co-locate å’Œ disaggregate ç­–ç•¥ä¸‹éƒ½èƒ½ä½¿ç”¨ï¼Œä½†æ˜¯æ”¯æŒ co-locate ç­–ç•¥çš„æ¡†æ¶åŸºæœ¬éƒ½é‡‡ç”¨äº† `update_weights_from_tensor`ã€‚åœ¨ä¸»æµæ¡†æ¶ä¸­ï¼ŒAReaL é€‰æ‹©äº† `update_weights_from_disk`ã€‚


2. `update_weights_from_distributed`ï¼šè¿™æ˜¯æˆ‘å®ç°çš„æ¥å£ï¼Œåœ¨é€»è¾‘ä¸Šå’Œ `update_weights_from_tensor` ç±»ä¼¼ï¼Œä½†æ˜¯ from distributed æ˜¯é€šè¿‡ nccl æˆ–è€… IB åœ¨ä¸åŒèµ„æºç»„ä¹‹é—´é€šè®¯ï¼Œåªèƒ½ç”¨äº disaggregated ç­–ç•¥ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨ Training Engine å’Œ Rollout Engine åˆ†ç¦»æ”¾ç½®åœ¨ä¸¤ä¸ªä¸åŒçš„èµ„æºç»„çš„æ—¶ï¼Œå°†äºŒè€…å»ºç«‹ä¸€ä¸ªç»Ÿä¸€çš„é€šè®¯ç»„ã€‚æ¯æ¬¡ training engine æ›´æ–°å®Œæƒé‡åï¼Œå°†åˆ†ç¦»çš„æƒé‡é€ä¸ª parameter èšåˆåœ¨ Training Engine çš„ TP 0 ä¸Šï¼Œç„¶åä» Training Engine çš„ TP 0 ä¼ é€’åˆ° Rollout Engine çš„æ¯ä¸ª TP ä¸Šã€‚Rollout Engine çš„æ¯ä¸ª TP å†è‡ªå·± shard å–å‡ºéœ€è¦çš„éƒ¨åˆ†ï¼Œç„¶åå‚æ•° load äº†å³å¯ã€‚

3. `update_weights_from_tensor`ï¼šå…¶å®å’Œ `update_weights_from_distributed` ç±»ä¼¼ï¼Œé€»è¾‘ä¸Šéƒ½è¦èµ°ä¸€æ¬¡èšåˆï¼Œä½†æ˜¯å¦‚åŒæˆ‘ä»¬å‰æ–‡çš„åˆ†æï¼Œ`update_weights_from_tensor` æ˜¯åªåš handle tuple åºåˆ—åŒ–ä¼ é€’ï¼Œä¸ä¼ é€’å®é™…æ•°æ®çš„ã€‚from tensor ä¸»è¦çš„éº»çƒ¦æ˜¯ co-locate ç­–ç•¥å¸¸å¸¸ä¸ºäº† rollout engine çš„ä¸¥è‹› SPMDï¼Œå¯¹ rollout engine çš„ä¾µå…¥æ€§å¾ˆå¼ºã€‚åœ¨ MOE ä¸Šçš„å¾ˆå¤šä¼˜åŒ–éƒ½æ²¡æ³•å¯ç”¨ï¼Œæ¯”å¦‚ç»å…¸çš„ DeepSeek DP Attentionï¼Œè€Œè¿™åœ¨ dis-aggregate ç­–ç•¥ä¸‹æ˜¯å¤©ç„¶æ”¯æŒçš„ã€‚
