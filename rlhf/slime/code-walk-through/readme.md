# A Brief Code Walkthrough of slime

åœ¨æˆ‘å¿ƒä¸­ï¼Œslime æ˜¯æåº¦ä¼˜é›…ç®€æ´çš„ RL æ¡†æ¶ï¼Œåœ¨æ˜“ç”¨æ€§å’Œæ€§èƒ½ä¸Šéƒ½åšå‡ºäº†å·¨å¤§çš„ä¼˜åŒ–ã€‚slime é€‰æ‹©äº†ä»¥ SGLang å’Œ Megatron LM ä½œä¸ºå”¯ä¸€åç«¯ï¼Œå¼ºåŠ›æ”¯æŒäº† MOE æ¨¡å‹çš„è®­ç»ƒå’Œæä¸ºè‡ªç”±çš„é‡‡æ ·é€»è¾‘ã€‚

æ­£å€¼ slime å‘å¸ƒ 0.1.0 ç‰ˆæœ¬ä¹‹é™…ï¼Œæˆ‘ä»¬åœ¨è¿™ç¯‡æ–‡æ¡£ä¸­å¿«é€Ÿå­¦ä¹ ä»¥ partial rollout ä¸ºä»£è¡¨çš„ slime æ ¸å¿ƒä»£ç ï¼Œå…·ä½“åŸºäº commit [261ecee](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7)ã€‚

Acknowlegment: 

Mao Cheng @ Meta, Zhuoran Yin @ CMU, Ji Li @ Ant Group, Yixuan Zhang @ UoA, Yusheng Su @ AMD, Zhuohao Li @ Alibaba, Yuzhen Zhou @ CMU, Jiajun Li @ CMU, Biao He @ LinkedIn, Huapeng Zhou @ UW, Chenyang Zhao @ LMSYS

## æ ¸å¿ƒæ¶æ„

slime é‡‡ç”¨åˆ†ç¦»å¼æ¶æ„ï¼Œå°† RLHF è®­ç»ƒæµç¨‹åˆ†è§£ä¸ºä¸‰ä¸ªç‹¬ç«‹åä½œçš„æ¨¡å—ï¼š

- Training (Megatron): è´Ÿè´£ä¸»è®­ç»ƒæµç¨‹ï¼Œæ”¯æŒå¤šç§å¹¶è¡Œç­–ç•¥ï¼›å…·ä½“å®ç°åœ¨[`slime/backends/megatron_utils/`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/backends/megatron_utils/)ã€‚
  
- Rollout (SGLang): ç”Ÿæˆæ–°æ•°æ®ï¼ˆå« reward/verifierï¼‰ï¼ŒåŸºäº SGLang çš„é‡‡æ ·é€»è¾‘ï¼›å…·ä½“å®ç°åœ¨[`slime/ray/rollout.py`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout.py)ã€‚
  
- Data Buffer: ç®¡ç†æ•°æ®æµå’Œè‡ªå®šä¹‰ç”Ÿæˆé€»è¾‘ï¼Œå¯ä»¥è¯´æ˜¯ slime æœ€åŒ å¿ƒç‹¬è¿çš„æ¨¡å—ï¼›å…·ä½“å®ç°åœ¨[`slime/ray/buffer.py`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/buffer.py)ã€‚

<div style="text-align: center;">
  <img src="./overall_workflow.jpg" alt="Overall Workflow" style="width:50%;">
</div>

åŸºäºå‰å«çš„è®¾è®¡ï¼Œslime çš„è‡ªç”±çµæ´»è®©äººéå¸¸æ¸…çˆ½ï¼š

1. èµ„æºè°ƒåº¦è‡ªç”±ï¼šæ”¯æŒ co-locate ä¸ dis-aggregate ä¸¤ç§éƒ¨ç½²ç­–ç•¥ï¼›åœ¨ rollout å’Œ training ä¸Šå„è‡ªæ”¯æŒ DP/TP/PP/EPï¼›å…·ä½“å®ç°è§ [`slime/ray/placement_group.py`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/placement_group.py)

2. è®­ç»ƒæ–¹å¼è‡ªç”±ï¼šæ”¯æŒåŒæ­¥è®­ç»ƒå’Œå¼‚æ­¥è®­ç»ƒä¸¤ç§æ¨¡å¼ï¼›å…·ä½“å®ç°è§ [`slime/train.py`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/train.py) å’Œ [`slime/train_async.py`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/train_async.py)ï¼›æ³¨æ„ï¼Œåè€…éœ€è¦åœ¨ dis-aggregate æ¶æ„ä¸‹ï¼Œä½¿ç”¨ `rollout_manager.async_generate` å’Œ `actor_model.async_train` è¿›è¡Œè®­æ¨åˆ†ç¦»çš„å¼‚æ­¥è®­ç»ƒï¼Œrollout å§‹ç»ˆé¢†å…ˆ train ä¸€ä¸ª stepï¼Œä¹Ÿå³ one-step off-policyï¼›

3. é‡‡æ ·æ–¹å¼è‡ªç”±ï¼šæ”¯æŒç”¨æˆ·è‡ªå®šä¹‰å¤æ‚çš„é‡‡æ ·æµç¨‹ï¼ŒåŒ…æ‹¬[å¤šè½®å·¥å…·è°ƒç”¨](https://github.com/THUDM/slime/tree/main/examples/search-r1)ã€å¥–åŠ±æ¨¡å‹é›†æˆã€è‡ªå®šä¹‰éªŒè¯å™¨ç­‰ï¼›å…·ä½“å®ç°è§ [`slime_plugins/rollout_buffer/`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime_plugins/rollout_buffer/)ã€‚

4. æ¨¡å‹æ”¯æŒè‡ªç”±ï¼šæ”¯æŒ Dense å’Œ MoE æ¨¡å‹ï¼›å…·ä½“è„šæœ¬å¯å‚è€ƒ [`slime/scripts/run-qwen3-4B.sh`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/scripts/run-qwen3-4B.sh) å’Œ [`slime/scripts/run-deepseek-r1.sh`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/scripts/run-deepseek-r1.sh)ã€‚


## ä»£ç ç»“æ„

```bash
slime/
â”œâ”€â”€ slime/                          # æ ¸å¿ƒæ¡†æ¶ä»£ç 
â”‚   â”œâ”€â”€ ray/                        # Ray åˆ†å¸ƒå¼ç»„ä»¶
â”‚   â”‚   â”œâ”€â”€ actor_group.py          # è®­ç»ƒ Actor ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ rollout.py              # æ¨ç† Actor ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ buffer.py               # æ•°æ®ç¼“å†²åŒº
â”‚   â”‚   â””â”€â”€ placement_group.py      # èµ„æºåˆ†é…
â”‚   â”œâ”€â”€ backends/                   # åç«¯å¼•æ“é›†æˆ
â”‚   â”‚   â”œâ”€â”€ megatron_utils/         # Megatron è®­ç»ƒåç«¯
â”‚   â”‚   â””â”€â”€ sglang_utils/           # SGLang æ¨ç†åç«¯
â”‚   â””â”€â”€ utils/                      # å·¥å…·å‡½æ•°
â”œâ”€â”€ slime_plugins/                  # æ’ä»¶å’Œæ‰©å±•
â”‚   â”œâ”€â”€ rollout_buffer/             # è‡ªå®šä¹‰ç”Ÿæˆæ’ä»¶
â”‚   â””â”€â”€ models/                     # æ¨¡å‹é€‚é…
â”œâ”€â”€ scripts/                        # å‚è€ƒå¯åŠ¨è„šæœ¬
â”‚   â””â”€â”€ models/                     # å„æ¨¡å‹é…ç½®
â”œâ”€â”€ examples/                       # å‚è€ƒä½¿ç”¨ç¤ºä¾‹
â”œâ”€â”€ docs/                           # è¯¦ç»†æ–‡æ¡£
â”œâ”€â”€ train.py                        # åŒæ­¥è®­ç»ƒå…¥å£
â””â”€â”€ train_async.py                  # å¼‚æ­¥è®­ç»ƒå…¥å£
```

å…·ä½“æ¥è¯´ï¼š

- `scripts/`ï¼šç”¨äºå¯åŠ¨ Ray é›†ç¾¤ä¸æäº¤è®­ç»ƒä½œä¸šï¼›ç¤ºä¾‹è„šæœ¬ä¼šé€‰æ‹© `train.py` æˆ– `train_async.py`ï¼Œæ¯”å¦‚ï¼š`slime/scripts/run-qwen3-4B.sh`ã€`slime/scripts/run-deepseek-r1.sh`ã€‚
- `train.py` / `train_async.py`ï¼šè®­ç»ƒå…¥å£ï¼Œåˆ›å»º `PlacementGroup` åˆ†é… GPU â†’ åˆ›å»º `actor_group`ï¼ˆè®­ç»ƒï¼‰ä¸ `rollout_manager`ï¼ˆæ¨ç†ï¼‰â†’ è¿›å…¥è®­ç»ƒå¾ªç¯ï¼ŒåŒæ­¥æ¨¡å¼é€æ­¥æ‰§è¡Œï¼›å¼‚æ­¥æ¨¡å¼é€šè¿‡ `rollout_manager.async_generate()` ä¸ `ray.get()` äº¤é”™ä»¥å¹¶è¡ŒåŒ–ã€‚
- `slime/ray/`ï¼šåˆ†å¸ƒå¼ç¼–æ’ä¸èµ„æºç®¡ç†ï¼Œå…·ä½“åŒ…æ‹¬ï¼š`placement_group.py`ï¼šåŸºäº Ray Placement Group çš„ GPU èµ„æºåˆ†é…ä¸æ‰“åŒ…ï¼Œ`actor_group.py`ï¼šè®­ç»ƒ Actor ç»„ç®¡ç†ï¼Œæš´éœ² `async_init/async_train/async_update_weights` ç­‰æ¥å£ï¼Œ`rollout.py`ï¼šRollout Actorï¼ˆSGLang å¼•æ“å®¹å™¨ï¼‰ã€æ¨ç†æœåŠ¡è·¯ç”±ã€æƒé‡æ¥æ”¶ï¼Œ`buffer.py`ï¼šæ•°æ®ç¼“å†²ã€æ ·æœ¬æ‰¹æ¬¡ç»„ç»‡ã€ä¸ Rollout/Training çš„ä¸­é—´æ¡¥æ¢ã€‚
- `slime/backends/`ï¼šåç«¯å¼•æ“é€‚é…ï¼Œå…·ä½“åŒ…æ‹¬ï¼š`megatron_utils/`ï¼šè®­ç»ƒåç«¯ï¼ˆä¼˜åŒ–å™¨ã€æƒé‡æ›´æ–°ã€ä¸åˆ†å¸ƒå¼é€šä¿¡é›†æˆï¼‰ï¼Œ`sglang_utils/`ï¼šæ¨ç†åç«¯ï¼ˆåŒ…è£… SGLangã€æ‰¹å¤„ç†ç”Ÿæˆã€å¼•æ“ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼‰ã€‚
- `slime_plugins/`ï¼šå¯æ’æ‹”æ‰©å±•ï¼Œå…·ä½“åŒ…æ‹¬ï¼š`rollout_buffer/`ï¼šé€šè¿‡ HTTP/OpenAI æ¥å£ç­‰å¤–éƒ¨è”åŠ¨çš„è‡ªå®šä¹‰è½¨è¿¹ç”Ÿæˆå™¨ä½“ç³»ï¼›`models/`ï¼šä¸åŒæ¨¡å‹æ—çš„å°é€‚é…å±‚ã€‚
- `examples/`ï¼šä¸€äº›å¤ç°å…¶ä»–å·¥ä½œçš„ä¾‹å­ï¼Œæ¯”å¦‚ `examples/search-r1/` å±•ç¤ºå¤šè½®å¯¹è¯ + å·¥å…·è°ƒç”¨çš„ç”Ÿæˆä¸è®­ç»ƒä¸²è”æ–¹å¼ã€‚
- `docs/`ï¼šè¯´æ˜æ–‡æ¡£ä¸ç”¨æ³•æŒ‡å—ï¼ŒåŒ…å«æ¨¡å‹ä½¿ç”¨ã€SFTã€AMD ç­‰å¹³å°é€‚é…ä¸è°ƒä¼˜æ‰‹å†Œã€‚

### ä¸²è”å…³ç³»

1. è„šæœ¬å±‚ï¼ˆ`scripts/`ï¼‰ï¼šå¯åŠ¨ Ray â†’ æäº¤job â†’ é€‰æ‹© `train.py` æˆ– `train_async.py` å¹¶ä¼ å…¥å‚æ•°

2. å…¥å£å±‚ï¼ˆ`train*.py`ï¼‰ï¼š`create_placement_groups(args)` åˆ†é…/æ˜ å°„ GPUï¼›`create_actor_group(args, pgs["actor"])` æ„å»ºè®­ç»ƒ Actor ç»„ï¼›`create_rollout_manager(args, pgs["rollout"])` æ„å»ºæ¨ç†ä¸æ•°æ®ç”Ÿæˆç®¡ç†å™¨

3. æ‰§è¡Œå±‚ï¼ˆ`ray/` + `backends/`ï¼‰ï¼šè®­ç»ƒï¼š`actor_group.async_train(...)` â†’ Megatron ä¼˜åŒ–/æ¢¯åº¦è®¡ç®—ï¼›ç”Ÿæˆï¼š`rollout_manager.async_generate(...)` â†’ SGLang æ‰¹é‡æ¨ç†ï¼›åŒæ­¥ï¼š`actor_group.async_update_weights()` â†’ å°†è®­ç»ƒæƒé‡æ¨é€åˆ°æ¨ç†å¼•æ“

4. æ•°æ®æµï¼ˆ`buffer.py` + æ’ä»¶ï¼‰ï¼š`Buffer` è´Ÿè´£æŠ½æ ·/æ‹¼æ‰¹/è°ƒç”¨è‡ªå®šä¹‰ç”Ÿæˆï¼ˆ`slime_plugins/rollout_buffer/`ï¼‰â†’ è¿”å›è®­ç»ƒå¯ç”¨æ ·æœ¬

æ³¨æ„ï¼Œè™½ç„¶æ‰§è¡Œå±‚çš„å‡½æ•°éƒ½å¸¦æœ‰ `async` ä¿®é¥°ï¼Œä½†æ˜¯åŒæ­¥è®­ç»ƒå’Œå¼‚æ­¥è®­ç»ƒéƒ½ä½¿ç”¨äº†åŒä¸€å¥— `async_train, async_generate` å’Œ `async_update_weights` æ¥å£ã€‚åŒæ­¥å’Œå¼‚æ­¥è®­ç»ƒçš„åŒºåˆ«åœ¨äº `ray.get()` çš„è°ƒç”¨æ—¶æœºã€‚é€šè¿‡ä»¥ä¸Šé“¾è·¯ï¼Œslime å°†è„šæœ¬ â†’ å…¥å£ â†’ åˆ†å¸ƒå¼æ‰§è¡Œ â†’ æ•°æ®/æƒé‡æµè‡ªç„¶åœ°ä¸²èµ·æ¥ï¼Œå®ç°é«˜æ•ˆå¯æ‰©å±•çš„ RL åè®­ç»ƒã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è¿›å…¥æ¯éƒ¨åˆ†çš„å…·ä½“ä»£ç ï¼Œå¯¹äºæ¶æ„å›¾ä¸­çš„é‡è¦å‡½æ•°è¿›è¡Œé€ä¸€è§£æã€‚

## Ray Placement Group

æœ¬èŠ‚è¯¦ç»†è¯´æ˜ slime åœ¨ Ray ä¸Šå¦‚ä½•è¿›è¡Œ GPU èµ„æºç¼–æ’ï¼šå¦‚ä½•åˆ›å»ºå¹¶é‡æ’ Placement Groupï¼ˆPGï¼‰ä»¥å®ç°ç¨³å®šçš„ GPU æ’åºï¼Œè®­ç»ƒ Actor ä¸ Rollout Engine å¦‚ä½•åœ¨ PG ä¸Šè°ƒåº¦ï¼Œä»¥åŠä¸¤ç§éƒ¨ç½²å½¢æ€ï¼šcolocate ä¸ dis-aggregateã€‚ä¸ºäº†æ–¹ä¾¿å™è¿°ï¼Œä»‹ç»ä¸€äº›æ ¸å¿ƒæ¦‚å¿µï¼š

1. [`Ray Placement Group`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/placement_group.py)ï¼šåœ¨é›†ç¾¤ä¸­é¢„ç•™ä¸€ç»„ bundleï¼ˆæ¯ä¸ªåŒ…å« 1 GPU + 1 CPUï¼‰ï¼Œå¹¶å°†åç»­ actor å›ºå®šç»‘å®šåˆ°è¿™äº› bundle ä¸Šï¼Œå®ç°å¯æ§ã€ç¨³å®šçš„èµ„æºæ”¾ç½®ã€‚

2. [`RayTrainGroup`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/actor_group.py)ï¼šè®­ç»ƒä¾§ actor çš„ç®¡ç†å™¨ï¼›é€šè¿‡ [`_allocate_gpus_for_actor`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/actor_group.py#L50) æ¥ä¸ºæ¯ä¸ª rank åˆ›å»ºè®­ç»ƒ actor handlerï¼Œå¾—åˆ° `self._actor_handlers`ï¼Œéšåå¹¶å‘åœ¨æ¯ä¸ª rank ä¸Šè¿›è¡Œ init / train / eval / save / update / offloadã€‚

3. [`RolloutManager`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout.py)ï¼šæ¨ç†/æ•°æ®ç¼–æ’å™¨ï¼Œè´Ÿè´£åˆ›å»º Rollout Engine, Data Bufferã€Lock and Routerï¼›è¿™éƒ¨åˆ†å†…å®¹è§åç»­è§£æï¼›


### å…¥å£å‡½æ•°

å…¥å£ä½äº [`Ray Placement Group`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/placement_group.py) çš„ [`create_placement_groups`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/placement_group.py#L71)ï¼š


- è®¡ç®—æœ¬æ¬¡è®­ç»ƒæ‰€éœ€çš„æ€» GPU æ•° `num_gpus`ã€‚
- åˆ›å»ºä¸€ä¸ªåŒ…å« `num_gpus` ä¸ª bundle çš„ PGï¼Œæ¯ä¸ª bundle éœ€è¦ `{"GPU": 1, "CPU": 1}`ã€‚
- è·å¾—é‡æ’åçš„ bundle ç´¢å¼•åˆ—è¡¨ï¼Œç”¨äºç¡®ä¿ç¨³å®šçš„è·¨èŠ‚ç‚¹ / GPU é¡ºåºã€‚
- æ ¹æ® `rollout_offset` å°† PG çš„ç´¢å¼•åˆ’åˆ†ç»™è®­ç»ƒ Actor ä¸ Rolloutã€‚

<details> <summary> create_placement_groups å…·ä½“å®ç° </summary>

```python
def create_placement_groups(args):
    """Create placement groups for actor and rollout engines."""

    num_gpus = 0
    if args.debug_train_only:
        num_gpus = args.actor_num_nodes * args.actor_num_gpus_per_node
        rollout_offset = 0
    elif args.debug_rollout_only:
        num_gpus = args.rollout_num_gpus
        rollout_offset = 0
    elif args.colocate:
        num_gpus = args.actor_num_nodes * args.actor_num_gpus_per_node
        rollout_offset = 0
    else:
        num_gpus = args.actor_num_nodes * args.actor_num_gpus_per_node + args.rollout_num_gpus
        rollout_offset = args.actor_num_nodes * args.actor_num_gpus_per_node

    print(f"Creating placement group with {num_gpus} GPUs...")
    pg, actor_pg_reordered_bundle_indices = _create_placement_group(num_gpus)

    rollout_pg_reordered_bundle_indices = actor_pg_reordered_bundle_indices[rollout_offset:]

    return {
        "actor": (pg, actor_pg_reordered_bundle_indices),
        "rollout": (pg, rollout_pg_reordered_bundle_indices),
    }
```
</details>

### Bundle é‡æ’

åˆ›å»º PG åï¼Œslime ç”¨ä¸€ä¸ªä¸´æ—¶ `InfoActor` åœ¨æ¯ä¸ª bundle ä¸Šè·å–è¯¥ bundle å®é™…åˆ†é…åˆ°çš„ `(Node IP, GPU ID)`ï¼ŒéšåæŒ‰ node IP ä¸ GPU ID è¿›è¡Œé‡æ’ï¼š

1. ä¼˜å…ˆå°è¯•å°† `node_identifier` è§£ææˆ IPv4 åœ°å€ï¼Œè½¬æˆ 4 ä¸ªæ•´å‹å¹¶æ®æ­¤æ’åºï¼›
2. è‹¥ä¸æ˜¯ IPï¼Œåˆ™å°è¯• DNS è§£æï¼›è¿˜ä¸è¡Œåˆ™é€€åŒ–ä¸ºæŒ‰ä¸»æœºåå­—ç¬¦çš„ ASCII åºåˆ—æ’åºï¼›
3. åŒèŠ‚ç‚¹å†…å†æŒ‰ `gpu_id` å‡åºæ’åºã€‚

è¿™æ ·å¯ä»¥è·å¾—è·¨å¤šæœºçš„ç¨³å®š bundle é¡ºåºï¼Œé¿å…ç”±äºæ˜ å°„ä¸ç¨³å®šé€ æˆçš„è°ƒåº¦é”™é…ã€‚

<details> <summary> InfoActor and sort_key å…·ä½“å®ç°</summary>

```python
@ray.remote(num_gpus=1)
class InfoActor:
    def get_ip_and_gpu_id(self):
        return ray.util.get_node_ip_address(), ray.get_gpu_ids()[0]

def sort_key(x):
    index, node_identifier, gpu_id = x
    # Sort by node IP number and then by GPU ID
    try:
        # try to parse it as an IP address.
        ip_address = node_identifier
        node_ip_parts = list(map(int, ip_address.split(".")))
    except ValueError:
        # Try to resolve the hostname to an IP address.
        try:
            ip_address = socket.gethostbyname(node_identifier)
            node_ip_parts = list(map(int, ip_address.split(".")))
        except (socket.gaierror, TypeError):
            # Instead, we convert each character of the original identifier string
            # to its ASCII value. This provides a stable and consistent numerical
            # representation that allows for sorting.
            node_ip_parts = [ord(c) for c in node_identifier]

    return (node_ip_parts, gpu_id)
```
</details>

### Colocate vs Dis-aggregate

å†ç†Ÿæ‚‰ä¸è¿‡çš„å†…å®¹äº†ã€‚

colocate ä¸‹ï¼Œè®­ç»ƒ Actor ä¸ Rollout å¼•æ“äº¤æ›¿å…±ç”¨åŒä¸€æ‰¹ GPU èµ„æºï¼Œæ­¤æ—¶ `num_gpus = actor_num_nodes * actor_num_gpus_per_node`ï¼Œ`rollout_offset = 0`ã€‚Rollout å’Œ Actor å®Œå…¨å…±ç”¨ bundleï¼›é€‚ç”¨äºå°è§„æ¨¡è®­ç»ƒã€‚

dis-aggregate ä¸‹ï¼Œè®­ç»ƒ Actor ä¸ Rollout å¼•æ“ä½¿ç”¨å„è‡ªç‹¬ç«‹çš„ GPU æ± ï¼ˆä¾‹å¦‚è®­ç»ƒå  6 å¡ï¼Œrollout å  2 å¡ï¼‰ï¼Œæ­¤æ—¶ `num_gpus = actor_num_nodes * actor_num_gpus_per_node + rollout_num_gpus`ï¼Œ`rollout_offset = actor_num_nodes * actor_num_gpus_per_node`ã€‚Rollout å’Œ Actor ä½¿ç”¨ä¸åŒçš„ bundleï¼›é€‚ç”¨äºå¤§è§„æ¨¡è®­ç»ƒï¼›åœ¨è¿™ç§æƒ…å†µä¸‹å¯ä»¥è¿›è¡Œ async-trainã€‚

### ç«¯å£åˆ†é…ä¸å¤šæœºä¸€è‡´æ€§

åœ¨å¤šèŠ‚ç‚¹/å¤šå¡ä¸‹ï¼Œ`create_rollout_engines` ä¼šé€šè¿‡ `RayActor._get_current_node_ip_and_free_port` åœ¨ç›®æ ‡èŠ‚ç‚¹ä¸Šå¯»æ‰¾ä¸€æ®µè¿ç»­å¯ç”¨ç«¯å£ï¼Œå¹¶å°† Node 0 çš„ `dist_init_addr` æ‰©æ•£åˆ°åŒä¸€å¼•æ“çš„å…¶ä»–èŠ‚ç‚¹ï¼Œä»¥ä¿è¯è·¨æœºçš„è¿›ç¨‹ç»„ä¸€è‡´æ€§ã€‚

<details> <summary> RayActor._get_current_node_ip_and_free_port å…·ä½“å®ç°</summary>

```python
def _get_current_node_ip_and_free_port(start_port=10000, consecutive=1):
    address = ray._private.services.get_node_ip_address()
    address = address.strip("[]")
    port = start_port
    while not all(is_port_available(port + i) for i in range(consecutive)):
        port += 1
    return address, port
```
</details>

## Data Source with/without Buffer

è¿™ä¸€éƒ¨åˆ†åº”è¯¥æ˜¯æœ€å–œé—»ä¹è§çš„ï¼Œå› ä¸ºå¤§å¤šæ•°ç®—æ³•ä»ä¸šè€…ç†åº”æ”¹å¥½ data bufferï¼Œå°±å¯ä»¥è‡ªç”±ä½¿ç”¨ slimeã€‚[`slime/ray/rollout_data_source.py`](https://github.com/THUDM/slime/tree/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout_data_source.py) æ˜¯ rollout ç³»ç»Ÿçš„æ•°æ®æºç®¡ç†æ¨¡å—ï¼Œè´Ÿè´£ä¸º rollout engine æä¾›è®­ç»ƒæ•°æ®ã€‚è¯¥æ–‡ä»¶å®šä¹‰äº†ä¸¤ä¸ªæ ¸å¿ƒç±»ï¼š`RolloutDataSource` å’Œ `RolloutDataSourceWithBuffer`ã€‚

ä¸‹å›¾åšçš„æ— æ¯”æ¸…æ™°ï¼Œä»‹ç»äº†æ•´ä¸ªæ•°æ®çš„è·å–æµç¨‹ï¼ŒData Source å¯ä»¥æ˜¯ `RolloutDataSource` æˆ– `RolloutDataSourceWithBuffer`ã€‚

<div style="text-align: center;">
  <img src="./datasource.svg" alt="DataSource" style="width:50%;">
</div>

### RolloutDataSource

1. åˆå§‹åŒ–ï¼š

```python
class RolloutDataSource:
    def __init__(self, args):
        self.args = args
        self.epoch_id = 0          # å½“å‰epoch ID
        self.sample_index = 0      # å…¨å±€æ ·æœ¬ç´¢å¼•
        self.sample_offset = 0     # åœ¨å½“å‰ epoch ä¸­çš„åç§»é‡
        self.metadata = {}         # å…ƒæ•°æ®å­˜å‚¨
        self.dataset = None        # æ•°æ®é›†å¯¹è±¡
```

æˆ‘ä»¬æ¥çœ‹çœ‹å…·ä½“çš„åˆå§‹åŒ–é€»è¾‘ï¼Œæ³¨æ„åˆ°ï¼Œé»˜è®¤æƒ…å†µä¸‹ï¼Œ`rollout_global_dataset=True`ï¼Œæ­¤æ—¶åŸºäºå¯åŠ¨å‚æ•°ä¸­çš„ `--prompt-data` åŠ è½½çœŸå®æ•°æ®é›†ï¼Œå¦åˆ™ `dataset=None`ï¼Œå¯ä»¥è‡ªè¡Œç»´æŠ¤ datasetã€‚

<details>
<summary>åˆå§‹åŒ–é€»è¾‘</summary>

```python
class RolloutDataSource:
    def __init__(self, args):
        self.args = args

        self.epoch_id = 0
        self.sample_index = 0
        self.sample_offset = 0
        self.metadata = {}

        if args.rollout_global_dataset:
            tokenizer = AutoTokenizer.from_pretrained(args.hf_checkpoint, trust_remote_code=True)

            if (d := args.dump_details) is not None:
                tokenizer.save_pretrained(Path(d) / "tokenizer")

            self.dataset = Dataset(
                args.prompt_data,
                tokenizer=tokenizer,
                max_length=args.rollout_max_prompt_len,
                prompt_key=args.input_key,
                label_key=args.label_key,
                metadata_key=args.metadata_key,
                tool_key=args.tool_key,
                apply_chat_template=args.apply_chat_template,
                seed=args.rollout_seed,
            )
            if self.args.rollout_shuffle:
                self.dataset.shuffle(self.epoch_id)
        else:
            self.dataset = None
```
</details>

2. [`get_samples()`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout_data_source.py#L46) ä¸ [`Sample`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/utils/types.py#L9)ï¼š

ä»æ•°æ®é›†ä¸­è·å–æŒ‡å®šæ•°é‡çš„æ ·æœ¬ï¼š

1. è‡ªåŠ¨å¤„ç† epoch è¾¹ç•Œï¼Œæ”¯æŒæ•°æ®é›† shuffleï¼›
2. æ¯ä¸ª prompt ç”Ÿæˆ `n_samples_per_prompt` ä¸ªæ ·æœ¬ï¼Œç”¨äº GRPOï¼›
3. ç»´æŠ¤ `sample_offset, epoch_id, sample_index`ï¼›
4. ä½¿ç”¨æ·±æ‹·è´é¿å…æ•°æ®æ±¡æŸ“ï¼›
5. å–å‡ºçš„ samples æ ¼å¼ä¸º `list[list[Sample]]`ï¼›

<details>
<summary>Sample ç±»å®ç°ä¸ get_samples æ–¹æ³•</summary>

```python
class Sample:
    """The sample generated"""

    index: Optional[int] = None
    # prompt
    prompt: Union[str, list[dict[str, str]]] = ""
    tokens: list[int] = field(default_factory=list)
    # response
    response: str = ""
    response_length: int = 0
    label: Optional[str] = None
    reward: Optional[Union[float, dict[str, Any]]] = None
    loss_mask: Optional[list[int]] = None

    class Status(Enum):
        PENDING = "pending"
        COMPLETED = "completed"
        TRUNCATED = "truncated"
        ABORTED = "aborted"

    status: Status = Status.PENDING
    metadata: dict = field(default_factory=dict)

    def to_dict(self):
        value = self.__dict__.copy()
        value["status"] = self.status.value
        return value

    @staticmethod
    def from_dict(data: dict):
        data["status"] = Sample.Status(data["status"])
        return Sample(**data)

    def get_reward_value(self, args) -> float:
        return self.reward if not args.reward_key else self.reward[args.reward_key]
```

```python
def get_samples(self, num_samples):
    samples = []
    
    if self.dataset is not None:
        # åˆ†æ”¯1ï¼šä½¿ç”¨çœŸå®æ•°æ®é›†
        if self.sample_offset + num_samples <= len(self.dataset):
            # æƒ…å†µ 1ï¼šå½“å‰ epoch è¿˜æœ‰è¶³å¤Ÿæ•°æ®
            prompt_samples = self.dataset.samples[self.sample_offset : self.sample_offset + num_samples]
            self.sample_offset += num_samples
        else:
            # æƒ…å†µ 2ï¼šå½“å‰ epoch æ•°æ®ä¸è¶³ï¼Œéœ€è¦è¿›å…¥ä¸‹ä¸€ä¸ª epoch
            prompt_samples = self.dataset.samples[self.sample_offset :]  # å–å®Œå½“å‰ epoch å‰©ä½™æ•°æ®
            num_samples -= len(prompt_samples)
            self.epoch_id += 1  # è¿›å…¥ä¸‹ä¸€ä¸ª epoch
            
            # é‡æ–° shuffle æ•°æ®é›†
            if self.args.rollout_shuffle:
                self.dataset.shuffle(self.epoch_id)
            
            # ä»æ–° epoch å–å‰©ä½™æ‰€éœ€æ•°æ®
            prompt_samples += self.dataset.samples[:num_samples]
            self.sample_offset = num_samples
        
        # ä¸ºæ¯ä¸ª prompt åˆ›å»ºå¤šä¸ªæ ·æœ¬ï¼ˆn_samples_per_promptï¼‰
        for prompt_sample in prompt_samples:
            group = []
            for _ in range(self.args.n_samples_per_prompt):
                sample = copy.deepcopy(prompt_sample)  # æ·±æ‹·è´é¿å…ä¿®æ”¹åŸå§‹æ•°æ®ï¼Œå¹¶ç»´æŠ¤ index
                sample.index = self.sample_index
                self.sample_index += 1
                group.append(sample)
            samples.append(group)
    else:
        # åˆ†æ”¯2ï¼šä¸ä½¿ç”¨çœŸå®æ•°æ®é›†ï¼Œåˆ›å»ºç©ºæ ·æœ¬
        for _ in range(num_samples):
            group = []
            for _ in range(self.args.n_samples_per_prompt):
                sample = Sample(index=self.sample_index)
                self.sample_index += 1
                group.append(sample)
            samples.append(group)
    
    return samples
```
</details>

3. [`save()`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout_data_source.py#L86) å’Œ [`load()`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout_data_source.py#L100)ï¼š

ä¿å­˜ `RolloutDataSource` çŠ¶æ€åˆ°æ–‡ä»¶ï¼›load åˆ™ç”¨äºè®­ç»ƒä¸­æ–­åï¼Œä»æ–‡ä»¶åŠ è½½çŠ¶æ€ï¼Œç¡®ä¿æ•°æ®é¡ºåºä¸€è‡´æ€§ã€‚

<details>
<summary>save å’Œ load æ–¹æ³•</summary>

```python
def save(self, rollout_id):
    if not self.args.rollout_global_dataset:
        return  # ä¸ä½¿ç”¨çœŸå®æ•°æ®é›†æ—¶ä¸éœ€è¦ä¿å­˜
    
    state_dict = {
        "sample_offset": self.sample_offset,  # å½“å‰ epoch ä¸­çš„åç§»é‡
        "epoch_id": self.epoch_id,            # å½“å‰ epoch ID
        "sample_index": self.sample_index,    # å…¨å±€æ ·æœ¬ç´¢å¼•
        "metadata": self.metadata,            # å…ƒæ•°æ®
    }
    
    # ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
    path = os.path.join(self.args.save, f"rollout/global_dataset_state_dict_{rollout_id}.pt")
    os.makedirs(os.path.dirname(path), exist_ok=True)
    torch.save(state_dict, path)
```

```python
def load(self, rollout_id=None):
    if not self.args.rollout_global_dataset:
        return  # ä¸ä½¿ç”¨çœŸå®æ•°æ®é›†æ—¶ä¸éœ€è¦åŠ è½½
    
    if self.args.load is None:
        return  # æ²¡æœ‰æŒ‡å®šåŠ è½½è·¯å¾„æ—¶ä¸éœ€è¦åŠ è½½
    
    path = os.path.join(self.args.load, f"rollout/global_dataset_state_dict_{rollout_id}.pt")
    if not os.path.exists(path):
        print(f"Checkpoint {path} does not exist.")
        return
    
    # åŠ è½½çŠ¶æ€
    state_dict = torch.load(path)
    self.sample_offset = state_dict.get("sample_offset", 0)
    self.epoch_id = state_dict.get("epoch_id", 0)
    self.sample_index = state_dict.get("sample_index", 0)
    self.metadata = state_dict.get("metadata", {})
    
    # é‡æ–° shuffle æ•°æ®é›†
    if self.args.rollout_global_dataset and self.args.rollout_shuffle:
        self.dataset.shuffle(self.epoch_id)
```
</details>


### [`RolloutDataSourceWithBuffer`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout_data_source.py#L124)

å¸¦ç¼“å†²çš„æ•°æ®ç±»ï¼Œç»§æ‰¿è‡ª `RolloutDataSource`ï¼Œå¢åŠ äº†æ•°æ®ç¼“å†²åŠŸèƒ½ï¼Œæ”¯æŒä¸ºäº† partial rollout è€Œè®¾è®¡çš„æ•°æ®é‡ç”¨ç­–ç•¥ã€‚

1. åˆå§‹åŒ–ï¼šå®Œå…¨ç»§æ‰¿äº† `RolloutDataSource` çš„åˆå§‹åŒ–é€»è¾‘ï¼Œå¹¶é¢å¤–åˆå§‹åŒ–äº† `buffer_filter` æ–¹æ³•å’Œç©ºçš„ `buffer` åˆ—è¡¨ã€‚

<details>
<summary>RolloutDataSourceWithBufferåˆå§‹åŒ–</summary>

```python
class RolloutDataSourceWithBuffer(RolloutDataSource):
    def __init__(self, args):
        super().__init__(args)
        self.buffer = []  # æ•°æ®ç¼“å†²åŒº
        
        # è®¾ç½® buffer è¿‡æ»¤å™¨
        if self.args.buffer_filter_path is None:
            self.buffer_filter = pop_first  # é»˜è®¤ï¼šå…ˆè¿›å…ˆå‡º
        else:
            self.buffer_filter = load_function(self.args.buffer_filter_path)  # è‡ªå®šä¹‰è¿‡æ»¤å™¨
```
</details>

2. [`get_samples()`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout_data_source.py#L133C9-L133C20)

å†™çš„å®åœ¨å¤ªæ¸…æ¥šäº†ï¼Œä¼˜å…ˆä» buffer è·å–æ•°æ®ï¼Œbuffer ä¸è¶³æ—¶ä»åŸå§‹æ•°æ®é›†è¡¥å……ã€‚

<details>
<summary>get_samples æ–¹æ³•</summary>

```python
def get_samples(self, num_samples: int) -> list[list[Sample]]:
    # 1. é¦–å…ˆä» buffer ä¸­è·å–æ ·æœ¬ç»„
    samples = self._get_samples_from_buffer(num_samples)
    num_samples -= len(samples)
    
    # 2. å¦‚æœ buffer ä¸å¤Ÿï¼Œä»åŸå§‹æ•°æ®é›†è·å–å‰©ä½™æ ·æœ¬ç»„
    if num_samples > 0:
        samples += super().get_samples(num_samples=num_samples)
    
    return samples
```

```python
def _get_samples_from_buffer(self, num_samples: int) -> list[list[Sample]]:
    if len(self.buffer) == 0 or num_samples == 0:
        return []  # buffer ä¸ºç©ºæˆ–ä¸éœ€è¦æ ·æœ¬
    
    # ä½¿ç”¨ buffer è¿‡æ»¤å™¨è·å–æ ·æœ¬ç»„
    samples = self.buffer_filter(self.args, None, self.buffer, num_samples)
    return samples
```

</details>

3. [`add_samples()`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout_data_source.py#L154C9-L154C20)

å‘ buffer æ·»åŠ æ ·æœ¬ç»„ã€‚æ³¨æ„ï¼Œ`RolloutDataSource` æ˜¯ä¸æ”¯æŒæ·»åŠ æ ·æœ¬çš„ï¼›æ­¤å¤„æ·»åŠ çš„æ˜¯æ ·æœ¬ç»„ï¼Œä¹Ÿå³ partial rollout æ˜¯ä¸€æ•´ä¸ª prompt çš„æ‰€æœ‰ requests åŒæ—¶å†™å…¥ bufferï¼Œä¸ä¼šå‡ºç° prompt çš„ä¸åŒ requests åœ¨ä¸åŒçš„ step è¢«ç”¨äºè®­ç»ƒçš„æƒ…å†µã€‚

<details>
<summary>add_samples æ–¹æ³•</summary>

```python
def add_samples(self, samples: list[list[Sample]]):
    if not samples:
        return
    
    # éªŒè¯è¾“å…¥æ ¼å¼ï¼Œç¡®ä¿è¾“å…¥æ˜¯ list[list[Sample]] æ ¼å¼
    assert isinstance(samples, list), f"samples must be a list, got {type(samples)}"
    assert isinstance(samples[0], list), f"the elements of samples must be list, got {type(samples[0])}"
    
    # éªŒè¯æ¯ä¸ª group çš„å¤§å°
    for i in range(0, len(samples)):
        assert (
            len(samples[i]) == self.args.n_samples_per_prompt
        ), f"the length of the elements of samples must be equal to n_samples_per_prompt, got {len(samples[i])} != {self.args.n_samples_per_prompt}"
        group = samples[i]
        self.buffer.append(group)  # æ·»åŠ åˆ° buffer
```
</details>

3. [`pop_first()`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout_data_source.py#L181)

é»˜è®¤çš„ buffer è¿‡æ»¤å™¨ï¼Œå®ç°å…ˆè¿›å…ˆå‡ºï¼ˆFIFOï¼‰çš„æ•°æ®è·å–ç­–ç•¥ã€‚

<details>
<summary>pop_first æ–¹æ³•</summary>

```python
def pop_first(args, rollout_id, buffer: list[list[Sample]], num_samples: int) -> list[list[Sample]]:
    num_to_pop = min(len(buffer), num_samples)  # å– buffer é•¿åº¦å’Œéœ€æ±‚é‡çš„è¾ƒå°å€¼
    samples = buffer[:num_to_pop]               # è·å–å‰ num_to_pop ä¸ªæ ·æœ¬
    del buffer[:num_to_pop]                     # ä» buffer ä¸­åˆ é™¤è¿™äº›æ ·æœ¬
    return samples
```
</details>

4. æœ€ç»ˆçš„æ•°æ®è°ƒç”¨é“¾ï¼š

```bash
RolloutController.generate()
    â†“
RolloutDataSourceWithBuffer.get_samples()
    â†“
_get_samples_from_buffer() + super().get_samples()
    â†“
è¿”å› list[list[Sample]]
```

5. è‡ªå®šä¹‰ Buffer è¿‡æ»¤å™¨ï¼š

<details>
<summary>è‡ªå®šä¹‰ Buffer è¿‡æ»¤å™¨ç¤ºä¾‹</summary>

```python
# å®šä¹‰è‡ªå®šä¹‰è¿‡æ»¤å™¨
def custom_buffer_filter(args, rollout_id, buffer, num_samples):
    # æŒ‰rewardæ’åºï¼Œå–rewardæœ€é«˜çš„æ ·æœ¬
    sorted_buffer = sorted(buffer, key=lambda x: x[0].reward, reverse=True)
    return sorted_buffer[:num_samples]

# åœ¨argsä¸­è®¾ç½®
args.buffer_filter_path = "path.to.custom_buffer_filter"
```
</details>

å†™çš„çœŸæ¸…æ¥šï¼Œéå¸¸å¥½æ‰©å±•ã€‚

## Rollout Control

rollout ä¸»è¦ç”±ä¸¤ä¸ª class controlï¼š

- `slime/ray/rollout.py`ï¼š`class RolloutManager` ç®¡ç† rollout å¼•æ“å’Œ router çš„ç”Ÿå‘½å‘¨æœŸ;
- `slime/ray/buffer.py`ï¼š`class RolloutController` å¤„ç† rollout ç”Ÿæˆçš„æ•°æ®å¹¶è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®ï¼›

<div style="text-align: center;">
  <img src="./rollout_parts.svg" alt="Rollout Parts" style="width:50%;">
</div>


### [`RolloutManager`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout.py#L149)

RolloutManager æ˜¯ rollout ç³»ç»Ÿçš„ä¸»æ§åˆ¶å™¨ï¼Œè´Ÿè´£åè°ƒ Routerï¼ŒController å’Œ Engines ä¹‹é—´çš„äº¤äº’ã€‚

1. åˆå§‹åŒ–ï¼šåˆå§‹åŒ– Routerï¼ŒControllerï¼ŒEngines æ± ï¼Œå¹¶åˆ›å»ºé”ï¼›

<details>
<summary>RolloutManager åˆå§‹åŒ–</summary>

```python
class RolloutManager:
    def __init__(self, args, pg, wandb_run_id):
        self.args = args
        
        # 1. å¯åŠ¨ Router
        _start_router(args)
        
        # 2. åˆ›å»º Controller
        self.controller = RolloutController.options(
            num_cpus=1,
            num_gpus=0,
        ).remote(args, wandb_run_id=wandb_run_id)

        # 3. åˆ›å»º Engines æ± 
        self.all_rollout_engines = create_rollout_engines(args, pg)
        
        # 4. å¤šèŠ‚ç‚¹é…ç½®ï¼šå¦‚æœ sglang engine éœ€è¦è·¨è¶Šå¤šä¸ª nodeï¼Œåˆ™åªå‘ç€æ¯ä¸ª engine çš„ node-0 å‘é€è¯·æ±‚
        nodes_per_engine = max(1, args.rollout_num_gpus_per_engine // args.rollout_num_gpus_per_node)
        self.rollout_engines = self.all_rollout_engines[::nodes_per_engine]
        
        # 5. åˆ›å»ºé”
        # è®­ç»ƒè¿›ç¨‹éœ€è¦å‘æ‰€æœ‰ rollout engines å¹¿æ’­æ–°çš„æƒé‡
        # åŒæ—¶ rollout engines å¯èƒ½æ­£åœ¨å¤„ç†æ¨ç†è¯·æ±‚
        # å¦‚æœå¹¿æ’­å’Œæ¨ç†åŒæ—¶è¿›è¡Œï¼Œå¯èƒ½å¯¼è‡´é€šä¿¡æ­»é”
        self.rollout_engine_lock = Lock.options(
            num_cpus=1,
            num_gpus=0,
        ).remote()
```
</details>

2. `async_generate(), async_eval(), async_offload(), async_onload()`ï¼š

è¿™å››ä¸ªå‡½æ•°éƒ½æ˜¯ç›´æ¥å‘ä¸‹è°ƒç”¨ Controller æˆ–è€… Engines çš„å¯¹åº”å‡½æ•°ï¼Œä¹‹åå†è§£æã€‚

3. [`create_rollout_engines`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout.py#L15)

åˆ›å»º SGLang enginesï¼š

<details>
<summary>create_rollout_engines å®ç°</summary>

```python
def create_rollout_engines(args, pg):
    if args.debug_train_only:
        return []

    # è®¡ç®—å¼•æ“é…ç½®
    num_gpu_per_engine = min(args.rollout_num_gpus_per_engine, args.rollout_num_gpus_per_node)
    num_engines = args.rollout_num_gpus // num_gpu_per_engine

    # åˆ›å»º Ray Actor
    RolloutRayActor = ray.remote(SGLangEngine)
    
    rollout_engines = []
    for i in range(num_engines):
        num_gpus = 0.2
        num_cpus = num_gpus

        # è®¾ç½®è°ƒåº¦ç­–ç•¥
        scheduling_strategy = PlacementGroupSchedulingStrategy(
            placement_group=pg,
            placement_group_capture_child_tasks=True,
            placement_group_bundle_index=reordered_bundle_indices[i * num_gpu_per_engine],
        )

        # åˆ›å»ºå¼•æ“
        rollout_engines.append(
            RolloutRayActor.options(
                num_cpus=num_cpus,
                num_gpus=num_gpus,
                scheduling_strategy=scheduling_strategy,
                runtime_env={"env_vars": {name: "1" for name in NOSET_VISIBLE_DEVICES_ENV_VARS_LIST}},
            ).remote(args, rank=i)
        )

    # ç«¯å£åˆ†é…å’Œåˆå§‹åŒ–
    # ... ç«¯å£åˆ†é…é€»è¾‘ ...
    
    # åˆå§‹åŒ–æ‰€æœ‰å¼•æ“
    init_handles = [engine.init.remote(**ports) for engine, ports in zip(rollout_engines, addr_and_ports)]
    # ç­‰å¾…æ‰€æœ‰å¼•æ“åˆå§‹åŒ–å®Œæˆ
    ray.get(init_handles)

    return rollout_engines
```
</details>

4. [`_start_router`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/rollout.py#L114)

å¯åŠ¨ SGLang routerï¼Œæä¾›è´Ÿè½½å‡è¡¡æœåŠ¡ï¼š

<details>
<summary>_start_router å®ç°</summary>

```python
def _start_router(args):
    if args.sglang_router_ip is not None:
        return  # å·²ç»æœ‰äº†å¤–éƒ¨ Router

    from sglang_router.launch_router import RouterArgs

    # è‡ªåŠ¨åˆ†é… IP å’Œç«¯å£
    args.sglang_router_ip = get_host_info()[1]
    args.sglang_router_port = find_available_port(random.randint(3000, 4000))

    # é…ç½® Router å‚æ•°
    router_args = RouterArgs(
        host=args.sglang_router_ip,
        port=args.sglang_router_port,
        balance_abs_threshold=0,
    )

    # è®¾ç½®æ—¥å¿—çº§åˆ«å’Œè¶…æ—¶
    if hasattr(router_args, "log_level"):
        router_args.log_level = "warn"
    if hasattr(router_args, "request_timeout_secs"):
        router_args.request_timeout_secs = args.sglang_router_request_timeout_secs

    # å¯åŠ¨ Router è¿›ç¨‹
    process = multiprocessing.Process(
        target=run_router,
        args=(router_args,),
    )
    process.daemon = True
    process.start()
    
    # ç­‰å¾…å¯åŠ¨å®Œæˆ
    time.sleep(3)
    assert process.is_alive()
```
</details>

æ³¨æ„ï¼Œå¯¹äº sgl router è€Œè¨€ï¼Œæˆ‘ä»¬æœ¬èº«å¯ä»¥åŒæ—¶å¯åŠ¨ router å’Œ engineï¼Œè€Œ slime ä¸­æ˜¯å…ˆåˆ†å¼€å¯åŠ¨äº† engine å’Œ routerï¼Œä¹‹åå†è®© engine é€šè¿‡ `add_worker` å‘ router æ³¨å†Œã€‚

### [`RolloutController`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/buffer.py#L21)

RolloutController æ˜¯ rollout ç³»ç»Ÿçš„çœŸæ­£æ‰§è¡Œè€…ï¼Œè´Ÿè´£æ•°æ®ç”Ÿæˆã€è½¬æ¢å’Œç®¡ç†ã€‚

1. åˆå§‹åŒ–ï¼šåˆ›å»ºæ•°æ®æºï¼ŒåŠ¨æ€åŠ è½½ rollout å‡½æ•°ã€‚

<details>
<summary>RolloutController åˆå§‹åŒ–</summary>

```python
@ray.remote
class RolloutController:
    def __init__(self, args, wandb_run_id):
        self.args = args
        init_wandb_secondary(args, wandb_run_id)

        # åˆ›å»ºæ•°æ®æº
        self.data_source = RolloutDataSourceWithBuffer(args)

        # åŠ¨æ€åŠ è½½ rollout å‡½æ•°
        self.generate_rollout = load_function(self.args.rollout_function_path)
        self.eval_generate_rollout = load_function(self.args.eval_function_path)
        
        print(f"import {self.args.rollout_function_path} as generate_rollout function.")
        print(f"import {self.args.eval_function_path} as eval_generate_rollout function.")
```
</details>

2. [`generate()`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/buffer.py#L42)


è°ƒç”¨ rollout å‡½æ•°è¿›è¡Œé‡‡æ ·éšåè½¬æ¢ä¸ºè®­ç»ƒæ•°æ®æ ¼å¼ï¼š

<details>
<summary>generate æ–¹æ³•å®ç°</summary>

```python
def generate(self, rollout_id):
    self.rollout_id = rollout_id

    # 1. è°ƒè¯•æ¨¡å¼ï¼šä»ç£ç›˜åŠ è½½æ•°æ®
    if self.args.load_debug_rollout_data:
        data = torch.load(
            open(self.args.load_debug_rollout_data.format(rollout_id=rollout_id), "rb"),
        )["samples"]
        data = [Sample.from_dict(sample) for sample in data]
    else:
        # 2. æ­£å¸¸æ¨¡å¼ï¼šè°ƒç”¨ rollout å‡½æ•°ç”Ÿæˆæ•°æ®
        data = self.generate_rollout(self.args, rollout_id, self.data_source, evaluation=False)
        
        # 3. æ‰å¹³åŒ–æ•°æ®ï¼ˆå¦‚æœæ˜¯åµŒå¥—åˆ—è¡¨ï¼‰
        if isinstance(data[0], list):
            data = sum(data, [])

    # 4. å¯é€‰ï¼šä¿å­˜è°ƒè¯•æ•°æ®
    if (path_template := self.args.save_debug_rollout_data) is not None:
        path = Path(path_template.format(rollout_id=self.rollout_id))
        print(f"Save debug rollout data to {path}")
        path.parent.mkdir(parents=True, exist_ok=True)
        torch.save(
            dict(
                rollout_id=self.rollout_id,
                samples=[sample.to_dict() for sample in data],
            ),
            path,
        )
    
    # 5. è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®æ ¼å¼
    data = self._convert_samples_to_train_data(data)
    
    # 6. åŒ…è£…å¹¶è¿”å›
    return Box(ray.put(data))
```
</details>

3. [`eval()`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/buffer.py#L74)

è°ƒç”¨ eval rollout å‡½æ•°è¿›è¡Œé‡‡æ ·éšåè¿›è¡Œè¯„åˆ†ï¼š

<details>
<summary>eval æ–¹æ³•å®ç°</summary>

```python
def eval(self, rollout_id):
    if self.args.debug_train_only:
        return  # è°ƒè¯•æ¨¡å¼ä¸ç”Ÿæˆè¯„ä¼°æ•°æ®

    # è°ƒç”¨è¯„ä¼°rolloutå‡½æ•°
    data = self.eval_generate_rollout(self.args, rollout_id, self.data_source, evaluation=True)
    
    # è®°å½•è¯„ä¼°æ•°æ®
    log_eval_data(rollout_id, self.args, data)
```
</details>

4. [`_convert_samples_to_train_data`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/buffer.py#L105)

å°†ç”Ÿæˆçš„ Sample å¯¹è±¡è½¬æ¢ä¸ºè®­ç»ƒæ‰€éœ€çš„å­—å…¸æ ¼å¼ï¼š

<details>
<summary>_convert_samples_to_train_data å®ç°</summary>

```python
def _convert_samples_to_train_data(self, samples: Union[list[Sample], list[list[Sample]]]):
    """
    Convert inference generated samples to training data.
    """
    # åŸºç¡€è®­ç»ƒæ•°æ®
    train_data = {
        "tokens": [sample.tokens for sample in samples], # prompt + response çš„ token ids
        "response_lengths": [sample.response_length for sample in samples], # response çš„ token é•¿åº¦
        "rewards": [sample.get_reward_value(self.args) for sample in samples], # å¥–åŠ±å€¼
        "truncated": [1 if sample.status == Sample.Status.TRUNCATED else 0 for sample in samples], # æ˜¯å¦è¢«æˆªæ–­çš„æ ‡å¿—
        "sample_indices": [sample.index for sample in samples], # æ ·æœ¬ç´¢å¼•
    }

    # å¤„ç† loss mask
    loss_masks = []
    for sample in samples:
        # å¦‚æœæ²¡æœ‰æä¾› loss_maskï¼Œåˆ›å»ºé»˜è®¤çš„
        if sample.loss_mask is None:
            sample.loss_mask = [1] * sample.response_length
        
        # éªŒè¯ loss_mask é•¿åº¦
        assert (
            len(sample.loss_mask) == sample.response_length
        ), f"loss mask length {len(sample.loss_mask)} != response length {sample.response_length}"
        loss_masks.append(sample.loss_mask)
    train_data["loss_masks"] = loss_masks

    # å¤„ç† raw reward
    if samples[0].metadata and "raw_reward" in samples[0].metadata:
        train_data["raw_reward"] = [sample.metadata["raw_reward"] for sample in samples]

    # å¤„ç† round_numberï¼ˆç”¨äº rollout bufferï¼‰
    if samples[0].metadata and "round_number" in samples[0].metadata:
        train_data["round_number"] = [sample.metadata["round_number"] for sample in samples]
    
    return train_data
```
</details>

### [`log_eval_data`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/ray/buffer.py#L163)

è®°å½•è¯„ä¼°æ•°æ®åˆ° wandb å’Œæ§åˆ¶å°ï¼š

<details>
<summary>log_eval_data å®ç°</summary>

```python
def log_eval_data(rollout_id, args, data):
    log_dict = {}
    for key in data.keys():
        rewards = data[key]["rewards"]
        log_dict[f"eval/{key}"] = sum(rewards) / len(rewards)
        
        if "truncated" in data[key]:
            truncated = data[key]["truncated"]
            log_dict[f"eval/{key}-truncated_ratio"] = sum(truncated) / len(truncated)

    print(f"eval {rollout_id}: {log_dict}")
    
    if args.use_wandb:
        log_dict["eval/step"] = (
            rollout_id
            if not args.wandb_always_use_train_step
            else rollout_id * args.rollout_batch_size * args.n_samples_per_prompt // args.global_batch_size
        )
        wandb.log(log_dict)
```
</details>

### é»˜è®¤çš„ rollout å‡½æ•°

æ³¨æ„ï¼Œåˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬è¿˜æ˜¯æ²¡æœ‰è§£æè¿‡é»˜è®¤çš„ rollout funciton å’Œ eval funcitonã€‚æˆ‘ä»¬åœ¨è¿™é‡Œçœ‹çœ‹é»˜è®¤çš„ rollout å‡½æ•°ï¼š

<details>
<summary>é»˜è®¤çš„ rollout å‡½æ•°</summary>

```python
def generate_rollout(args, rollout_id, data_buffer, evaluation=False):
    """An example to implement the generate_rollout function for an rule based rm rollout generation.

    Args:
        args: the whole args
        rollout_id: int, the id of the rollout, used for deterministic data generation
        data_buffer: the data buffer to store the generated samples
        evaluation: bool, whether the rollout is for evaluation or not

    Returns:
        list[list[Sample]]: a list of list of samples generated by the rollout
    """
    completed_samples, aborted_samples = generate_abortable_samples(
        args, rollout_id, data_buffer.get_samples, evaluation=evaluation
    )
    data_buffer.add_samples(aborted_samples)
    return completed_samples


def generate_abortable_samples(args, rollout_id, data_source, evaluation=False):
    assert args.rollout_global_dataset
    if evaluation:
        return run(eval_rollout(args, rollout_id))
    return run(generate_rollout_async(args, rollout_id, data_source))
```
</details>

å†™çš„è¿˜æ˜¯ä¸€å¦‚æ—¢å¾€çš„ç®€æ´ï¼Œæˆ‘ä»¬ç»§ç»­é¡ºç€ `run` å‡½æ•°å‘ä¸‹è§‚å¯Ÿï¼š

<details>
<summary>run å‡½æ•°å…·ä½“å®ç°</summary>

```python
def run(coro):
    """Run a coroutine in the background event loop."""
    return get_async_loop().run(coro)
```
</details>

ç®€æ´åˆ°è®©æˆ‘æƒŠè®¶çš„ç¨‹åº¦ï¼Œå®é™…ä¸Šä¼ å…¥ç»™ `run` çš„ `coro` æ˜¯ä¸€ä¸ª `coroutine`ï¼ˆåç¨‹ï¼‰å¯¹è±¡ã€‚ åœ¨ä¸Šæ–‡ä¸­ï¼Œä¼ å…¥çš„ `coro` æ˜¯ `generate_rollout_async(args, rollout_id, data_source)`ã€‚å½“æ‰§è¡Œ `run(generate_rollout_async(args, rollout_id, data_source))` æ—¶ï¼š

1. `run()` å‡½æ•°æ¥æ”¶ `generate_rollout_async(args, rollout_id, data_source)` åç¨‹å¯¹è±¡ï¼›
2. `get_async_loop()` è·å–æˆ–åˆ›å»ºåå°äº‹ä»¶å¾ªç¯çº¿ç¨‹ï¼›
3. `async_loop.run(coro)` è°ƒç”¨ `AsyncLoopThread.run()` æ–¹æ³•ï¼›
4. `asyncio.run_coroutine_threadsafe(coro, self.loop)` å°†åç¨‹æäº¤åˆ°åå°çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯ä¸­ï¼›
5. `.result()` é˜»å¡ç­‰å¾…åç¨‹æ‰§è¡Œå®Œæˆå¹¶è¿”å›ç»“æœï¼›

ç›¸å…³çš„ä»£ç å¦‚ä¸‹ï¼š

<details>
<summary>åç¨‹æäº¤çš„ç›¸å…³é€»è¾‘</summary>

1. `run(coro)` å‡½æ•°æœ¬èº«

```python
def run(coro):
    """Run a coroutine in the background event loop."""
    return get_async_loop().run(coro)
```

2. `get_async_loop()` åˆ›å»ºåå°äº‹ä»¶å¾ªç¯

```python
def get_async_loop():
    global async_loop
    if async_loop is None:
        async_loop = AsyncLoopThread()  # åˆ›å»ºä¸€ä¸ªåå°çº¿ç¨‹è¿è¡Œäº‹ä»¶å¾ªç¯
    return async_loop
```

3. `AsyncLoopThread` ç±»

```python
class AsyncLoopThread:
    def __init__(self):
        self.loop = asyncio.new_event_loop()  # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
        self._thread = threading.Thread(target=self._start_loop, daemon=True)  # åˆ›å»ºåå°çº¿ç¨‹
        self._thread.start()  # å¯åŠ¨çº¿ç¨‹

    def _start_loop(self):
        asyncio.set_event_loop(self.loop)  # åœ¨æ–°çº¿ç¨‹ä¸­è®¾ç½®äº‹ä»¶å¾ªç¯
        self.loop.run_forever()  # è®©äº‹ä»¶å¾ªç¯ä¸€ç›´è¿è¡Œ

    def run(self, coro):
        # å°†åç¨‹æäº¤åˆ°åå°äº‹ä»¶å¾ªç¯å¹¶ç­‰å¾…ç»“æœ
        return asyncio.run_coroutine_threadsafe(coro, self.loop).result()
```

</details>

## SGLang Rollout

æˆ‘ä»¬ç»§ç»­å‘ä¸‹ç ”ç©¶ï¼Œé»˜è®¤çš„ [`generate_rollout_async`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/rollout/sglang_rollout.py#L235) æ˜¯ç›´æ¥å®šä¹‰åœ¨ [`sglang_rollout.py`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/rollout/sglang_rollout.py) ä¸­ã€‚

```
Router â†’ SGLang Server 1/2 â†’ TP0/TP1/TP2/TP3 â†’ æ ·æœ¬ç”Ÿæˆ â†’ å¥–åŠ±è¯„ä¼°
```

æ¨¡å—ç»“æ„ï¼š

```
slime/rollout/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ sglang_rollout.py      # åŸºäº SGLang çš„å¼‚æ­¥æ ·æœ¬ç”Ÿæˆ
â”œâ”€â”€ sft_rollout.py         # SFT è®­ç»ƒæ ·æœ¬å¤„ç†
â”œâ”€â”€ filter_hub/            # æ ·æœ¬è¿‡æ»¤å™¨
â”‚   â”œâ”€â”€ dynamic_sampling_filters.py
â”‚   â””â”€â”€ over_sampling_filters.py
â””â”€â”€ rm_hub/                # å¥–åŠ±æ¨¡å‹é›†åˆ
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ deepscaler.py
    â”œâ”€â”€ f1.py
    â”œâ”€â”€ math_utils.py
    â””â”€â”€ math_dapo_utils.py
```

æ ¸å¿ƒç»„ä»¶è¯¦è§£ï¼š

### RL Rollout

[SGLang Rollout](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/rollout/sglang_rollout.py) è´Ÿè´£ä¸º RL è®­ç»ƒé‡‡é›†å®é™…æ ·æœ¬ã€‚ä½¿ç”¨ `asyncio` å®ç°å¹¶å‘æ ·æœ¬ç”Ÿæˆï¼›`GenerateState` å•ä¾‹ç±»ç®¡ç†å…¨å±€ç”ŸæˆçŠ¶æ€ï¼›æ”¯æŒåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ä¸­æ–­å’Œæ¢å¤ï¼›æ”¯æŒæ‰¹é‡ç”Ÿæˆå’Œå¥–åŠ±æ¨¡å‹è¯„ä¼°ã€‚

**[`GenerateState`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/rollout/sglang_rollout.py#L18)**

`GenerateState` æ˜¯å…¨å±€ç”ŸæˆçŠ¶æ€ç®¡ç†å™¨ï¼šç®¡ç† `Group: List[Sample]` çš„ç”ŸæˆçŠ¶æ€ï¼›æ§åˆ¶ `generate_and_rm_group` ä»»åŠ¡çš„æäº¤ï¼›ç»´æŠ¤ `semaphore`, `sampling_params`, `args` ç­‰ã€‚

ã€TODOã€‘ï¼šè¿™ä¸ª State çš„åå­—å¾ˆå¥‡æ€ªï¼Œstate åº”è¯¥å°±æ˜¯çŠ¶æ€ï¼Œå¾ˆç®€å•ä¸€ä¸ªç±»ï¼Œæ€ä¹ˆè¿˜ç®¡ç€ submit task ğŸ˜‚

<details>
<summary>GenerateState å…·ä½“å®ç°</summary>

```python
class GenerateState(metaclass=SingletonMeta):
    def __init__(self, args):
        self.args = args
        self.tokenizer = AutoTokenizer.from_pretrained(args.hf_checkpoint, trust_remote_code=True)
        # è¿™ä¸ª semaphore æ§åˆ¶çš„æ˜¯ router ä¸Šçš„æœ€å¤§æµé‡ï¼Œé˜²æ­¢ router å´©æºƒ
        self.semaphore = asyncio.Semaphore(args.sglang_server_concurrency * args.rollout_num_gpus // args.rollout_num_gpus_per_engine)
        self.sampling_params = dict(
            temperature=args.rollout_temperature,
            top_p=args.rollout_top_p,
            top_k=args.rollout_top_k,
            max_new_tokens=args.rollout_max_response_len,
            stop=args.rollout_stop,
            stop_token_ids=args.rollout_stop_token_ids,
            skip_special_tokens=args.rollout_skip_special_tokens,
            no_stop_trim=True,
            spaces_between_special_tokens=False,
        )
        self.reset()

    def reset(self):
        self.remaining_batch_size = 0
        self.pendings = set()
        self.aborted = False

    def submit_generate_tasks(self, samples: list[list[Sample]]):
        for group in samples:
            self.pendings.add(
                asyncio.create_task(
                    # generate_and_rm_group æ˜¯ä¸€ä¸ª GRPO ç»„ï¼Œç»„å†…æ˜¯ä¸€ä¸ª prompt çš„å¤šä¸ª requests
                    generate_and_rm_group(
                        self.args,
                        group,
                        sampling_params=self.sampling_params.copy(),
                        evaluation=False,
                    )
                )
            )
        self.remaining_batch_size += len(samples)
```

</details>

**[`generate_rollout_async`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/rollout/sglang_rollout.py#L235)**

`generate_rollout_async` è¿™æ˜¯å¼‚æ­¥æ ·æœ¬ç”Ÿæˆçš„ä¸»å‡½æ•°ï¼Œåœ¨å‰æ–‡ä¹Ÿæœ‰æåˆ°ï¼Œè¢«ä½œä¸ºåç¨‹å¯¹è±¡ä¼ å…¥åˆ° `run` å‡½æ•°ä¸­ã€‚è¿™ä¸ªå‡½æ•°å¦è¯šè¯´å†™çš„è¿˜æœ‰æå‡ç©ºé—´ï¼š

1. åˆå§‹åŒ– `dynamic_filter` å’Œ `over_sampling_filter`ï¼Œ`dynamic_filter` å°±æ˜¯ DAPO ä¸­æåˆ°çš„ç­–ç•¥ï¼Œå°† reward std ä¸º 0 çš„æ•´ä¸ªç»„ä» data ä¸­ä¸¢å¼ƒï¼›ä½†æ˜¯ï¼Œ`over_sampling_filter` å…¶å®åœ¨ slime ä¸­æ˜¯ä¸ä¼šé»˜è®¤ç”¨åˆ°çš„ï¼›slime è™½ç„¶ä¼šé»˜è®¤å¼€å¯ over sampleï¼ˆè®¾ç½® `over_sample_batch_size` å¤§äº `rollout_batch_size`ï¼‰ï¼Œä½†æ˜¯ä¸ä¼šé»˜è®¤æ‰“å¼€ `over_sampling_filter`ï¼›æˆ‘ä»¬å…ˆä¸çœ‹å¼€å¯ `over_sampling_filter` çš„æƒ…å†µï¼Œæ­¤æ—¶ `target_data_size` å°±ç­‰äº `rollout_batch_size` è€Œå°äº `over_sample_batch_size`ï¼›
2. è¿›å…¥ while ä¸»å¾ªç¯ï¼Œç­‰å¾… `data` ä¸­å¾—åˆ° `target_data_size`(`rollout_batch_size`) ä¸ª group æ‰é€€å‡ºï¼›
3. è¿›å…¥æäº¤ group ç»™ router çš„å¾ªç¯ï¼Œæ£€æµ‹å½“å‰çš„ `remaining_batch_size` æ˜¯å¦å°äº `target_data_size`ï¼Œå¦‚æœå°äºï¼Œåˆ™æäº¤ `over_sample_batch_size` ä¸ª group ç»™ routerï¼›æ³¨æ„ï¼Œç¬¬ä¸€æ¬¡è¿›å…¥è¿™ä¸ªå¾ªç¯æ—¶ï¼Œ`remaining_batch_size` æ˜¯ 0ï¼Œå› ä¸ºè¿˜æ²¡å¼€å§‹æäº¤ groupï¼›æ‰€ä»¥ä¸€å®šä¼š submit `over_sample_batch_size` ä¸ª group ç»™ routerï¼›ç„¶å `remaining_batch_size` ä¼šåŠ ä¸Š `over_sample_batch_size`ï¼›
4. æäº¤å®Œ group åï¼Œç­‰å¾…ä»»æ„ä¸€ä¸ª group ç»“æŸï¼Œä¹Ÿå³æ•´ä¸ª group çš„æ‰€æœ‰ requests éƒ½ rollout ç»“æŸäº†ï¼›
5. å¦‚æœå¼€å¯äº† `dynamic_filter`ï¼Œåˆ™å¯¹å®Œæˆçš„ group åº”ç”¨ `dynamic_filter`ï¼›å¦‚æœ `dynamic_filter` è¿”å› Falseï¼Œåˆ™å‡æ‰ä¸€ä¸ª `remaining_batch_size`ï¼Œä¸ä¼šåŠ å…¥ `data` ä¸­ï¼›
6. å¦‚æ­¤ä»¥æ¥ï¼Œä¸æ–­å¾€ `data` ä¸­æ·»åŠ  groupï¼Œç›´åˆ° `data` ä¸­å¾—åˆ° `target_data_size` ä¸ª group ä¸ºæ­¢ï¼›æˆ–è€…ï¼Œè¢« filter æ‰çš„ group å¤ªå¤šäº†ï¼Œ`remaining_batch_size` å°äºäº† `target_data_size`ï¼Œåˆ™è¿˜è¦å†æäº¤ `over_sample_batch_size` ä¸ª group ç»™ routerï¼›
7. ç›´åˆ°é‡‡æ ·åˆ° `data` ä¸­å¾—åˆ° `target_data_size` ä¸ª group ä¸ºæ­¢ï¼Œé€€å‡º while ä¸»å¾ªç¯ï¼›
8. æ³¨æ„åˆ°ï¼Œæˆ‘ä»¬æäº¤çš„ groups çš„æ•°ç›®è‡³å°‘æ˜¯ä¸€ä¸ª `over_sample_batch_size`ï¼Œè€Œ `target_data_size` å¯èƒ½å°äº `over_sample_batch_size`ï¼Œæ‰€ä»¥éœ€è¦ abort æ‰æœªå®Œæˆ groups å‰©ä¸‹çš„ requestsï¼›

å¦‚æœæˆ‘ä»¬å¼€å¯ `over_sampling_filter`ï¼Œåˆ™ `target_data_size` å°±ç­‰äº `over_sample_batch_size`ï¼Œç­‰å¾… `over_sample_batch_size` ä¸ª group å®Œæˆ rollout æ‰é€€å‡ºå¾ªç¯ï¼Œä¸­é—´å¯èƒ½è¿˜ä¼šè¢« `dynamic_filter` è¿‡æ»¤æ‰ä¸€äº› groupï¼Œè¿˜å¾—ç»§ç»­æäº¤æ›´å¤šç»„ group ç»™ routerï¼›å¾ªç¯é€€å‡ºåï¼Œæˆ‘ä»¬æ‹¿åˆ°äº† `over_sample_batch_size` ä¸ª groupï¼Œç„¶ååº”ç”¨ `over_sampling_filter` è¿‡æ»¤æ‰ä¸€äº› groupï¼ˆæ¯”å¦‚æŠŠ reward std æ’åå€’æ•°çš„ group ä¸¢å¼ƒï¼‰ï¼Œç„¶åæ‹¿å»è®­ç»ƒã€‚

å¦‚æœæ‚¨çœ‹æ‡‚äº†ä¸Šæ–¹çš„é€»è¾‘ï¼Œå¯ä»¥æ¥çœ‹çœ‹è¿™ä¸ªä¾‹å­ã€‚æˆ‘ä»¬è®¾ç½® `over_sample_batch_size` ä¸º 6ï¼Œ`rollout_batch_size` ä¸º 4ï¼Œå¼€å¯ `dynamic_filter` å’Œ `over_sampling_filter`ã€‚

å›¾ç‰‡ä¸­é—´çš„ä¸Šéƒ¨åˆ†æ˜¯ç¬¬ä¸€æ¬¡æäº¤çš„ `over_sample_batch_size` ä¸ª group ç»™ routerï¼Œ6 ä¸ª group çš„æ‰€æœ‰ requests åŒæ—¶å¼€å§‹ rolloutã€‚éšåæˆ‘ä»¬å‘ç°ä¸­é—´ä¸‰ç»„çš„ reward std ä¸º 0ï¼Œè¢« `dynamic_filter` è¿‡æ»¤æ‰äº†ï¼Œæ­¤æ—¶ `remaining_batch_size` å˜ä¸º 3ï¼Œå°äºäº† `target_data_size`ï¼ˆæ­¤æ—¶ç­‰äº `over_sample_batch_size = 6`ï¼‰ï¼Œæ‰€ä»¥éœ€è¦å†æäº¤ä¸€ç»„ `over_sample_batch_size` ä¸ª group ç»™ routerã€‚

æ­¤æ—¶ï¼Œæ³¨æ„åˆ°å›¾ç‰‡ä¸­é—´ä¸‹æ–¹çš„ 6 ä¸ª groupï¼Œå½“å‰ 4 ä¸ª group é‡‡æ ·ç»“æŸä¸”æ²¡æœ‰è¢« dynamic filter è¿‡æ»¤æ‰ï¼Œ`data` é‡Œé¢è¿å¸¦ç€ä¸Šæ–¹çš„ 2 ä¸ª groupsï¼Œä¸€å…±å°±æœ‰äº† 6 ä¸ª groupï¼Œè¾¾åˆ°äº† `target_data_size`ï¼Œæ‰€ä»¥é€€å‡ºå¾ªç¯ï¼ŒæŠŠå›¾ä¸­æ©™è‰²çš„ 3 ç»„è¿˜æ²¡æœ‰ rollout ç»“æŸçš„ abort æ‰ã€‚éšåè¿›å…¥å›¾ç‰‡çš„æœ€å·¦è¾¹ï¼Œ`data` ä¸­çš„ 6 ä¸ª groups åº”ç”¨ `over_sampling_filter` è¿‡æ»¤æ‰ 2 ä¸ª groupï¼Œæœ€åå¾—åˆ° 4 ä¸ª group æ‹¿å»è®­ç»ƒã€‚

<div style="text-align: center;">
  <img src="./sampling_flow.jpg" alt="Sampling Flow" style="width:50%;">
</div>


<details>
<summary>generate_rollout_async å‡½æ•°</summary>

```python
async def generate_rollout_async(args, rollout_id: int, data_source) -> list[list[Sample]]:
    """An example to implement the generate_rollout function for an rule based rm rollout generation.

    Args:
        args: the whole args
        rollout_id: int, the id of the rollout, used for deterministic data generation
        data_source: the data source to fetch

    Returns:
        list[list[Sample]]: a list of samples generated by the rollout, the length of the list is exactly the same as the `rollout_batch_size`
    """
    assert args.rollout_global_dataset

    state = GenerateState(args)

    # instantiate data filters
    # dynamic filter å°±æ˜¯ DAPO çš„ç­–ç•¥ï¼Œä¸€ä¸ªç»„å†… reward çš„ std æ˜¯ 0 å°±å…¨åˆ äº†
    dynamic_filter = (
        load_function(args.dynamic_sampling_filter_path) if args.dynamic_sampling_filter_path is not None else None
    )
    over_sampling_filter = (
        load_function(args.over_sampling_filter_path) if args.over_sampling_filter_path is not None else None
    )

    # target_data_size is the total number of valid samples to get
    # é»˜è®¤æƒ…å†µä¸‹ï¼Œover sample filter æ˜¯ä¸å¼€çš„ï¼Œä½†æ˜¯ over_sample_batch_size ä¼šæ¯” rollout_batch_size å¤§
    # ä¸€æ¬¡æ€§å‘é€ over_sample_batch_size ä¸ª requestsï¼Œç­‰åˆ° rollout_batch_size(target_data_size) ä¸ª group
    # è¿”å›äº†å°±é€€å‡ºå¾ªç¯ï¼Œå‰©ä¸‹çš„ requests ä¼š abort æ‰
    target_data_size = args.over_sampling_batch_size if over_sampling_filter is not None else args.rollout_batch_size

    data = []
    do_print = True
    pbar = tqdm(total=target_data_size * args.n_samples_per_prompt, desc="Rollout generation")
    while len(data) < target_data_size:
        while state.remaining_batch_size < target_data_size:
            # get samples from the buffer and submit the generation requests.
            samples = data_source(args.over_sampling_batch_size)
            state.submit_generate_tasks(samples)

        # wait for the generation to finish
        # æ•´ä¸ª group çš„æ‰€æœ‰ requests éƒ½ rollout ç»“æŸäº†ï¼Œæ‰è¿”å›
        done, state.pendings = await asyncio.wait(state.pendings, return_when=asyncio.FIRST_COMPLETED)
        for task in done:
            group: list[Sample] = task.result()

            if do_print:
                print(
                    f"First rollout sample: {[group[0].prompt + group[0].response]}, label: {group[0].label}, reward: {group[0].reward}",
                    flush=True,
                )
                do_print = False

            assert len(group) == args.n_samples_per_prompt
            if dynamic_filter is not None and not dynamic_filter(args, group):
                # å¦‚æœè¢« dynamic_filter è¿‡æ»¤æ‰äº†ï¼Œå°±å‡æ‰ä¸€ä¸ª remaining_batch_sizeï¼Œä¸ä¼šåŠ å…¥ data ä¸­
                state.remaining_batch_size -= 1
                continue

            # add the samples to the data
            # NOTE: here we have not stored all the unused samples back to the data buffer.
            if len(data) < target_data_size:
                data.append(group)
                pbar.update(args.n_samples_per_prompt)

    pbar.close()
    print(
        f"Finish rollout: {[data[-1][0].prompt + data[-1][0].response]}, label: {data[-1][0].label}, reward: {data[-1][0].reward}",
        flush=True,
    )

    # å› ä¸º over_sampling_batch_size ä¸€å®šæ˜¯å¤§äº rollout_batch_size 
    #å¦‚æœç­‰å¾… rollout_batch_size ä¸ª groups å°±é€€å‡ºå¾ªç¯
    # åˆ™éœ€è¦ abort æ‰æœªå®Œæˆ groups å‰©ä¸‹çš„ requests
    aborted_samples = await abort(args, rollout_id)

    if over_sampling_filter is not None:
        data = over_sampling_filter(args, data)[: args.rollout_batch_size]

    assert len(data) == args.rollout_batch_size, f"Got {len(data)} samples, expected {args.rollout_batch_size}"
    data = sorted(data, key=lambda group: group[0].index)

    # reset the global state to prevent effects on the next rollout or eval.
    state.reset()
    return data, aborted_samples
```
</details>


**[`generate_and_rm_group`](https://github.com/THUDM/slime/blob/261ecee700b30429ba2cf4d4c27e3fc7ae0a12c7/slime/rollout/sglang_rollout.py#L178)**

å¯¹æ ·æœ¬ç»„çš„æ¯ä¸ª request æ‰§è¡Œ `generate_and_rm` æ“ä½œã€‚

<details>
<summary>generate_and_rm_group ç›¸å…³å®ç°</summary>

1. `generate_and_rm_group` å‡½æ•°

```python
async def generate_and_rm_group(args, group: list[Sample], sampling_params: dict, evaluation=False) -> list[Sample]:
    """å¯¹æ ·æœ¬ç»„è¿›è¡Œç”Ÿæˆå’Œå¥–åŠ±æ¨¡å‹è¯„ä¼°"""
    state = GenerateState(args)

    if state.aborted:
        return group

    # å¹¶å‘ç”Ÿæˆæ‰€æœ‰æ ·æœ¬
    group = await asyncio.gather(
        *[generate_and_rm(args, sample, sampling_params.copy(), evaluation=evaluation) for sample in group]
    )

    # å¯¹äºéœ€è¦æ•´ä¸ªç»„çš„å¥–åŠ±æ¨¡å‹ï¼Œåœ¨è¿™é‡Œè¿›è¡Œè¯„ä¼°
    if not state.aborted and args.group_rm:
        rewards = await batched_async_rm(args, group)
        for sample, reward in zip(group, rewards):
            sample.reward = reward

    return group
```

2. `generate_and_rm` å‡½æ•°

```python
async def generate_and_rm(args, sample: Sample, sampling_params: dict, evaluation=False) -> Sample:
    """å•ä¸ªæ ·æœ¬çš„ç”Ÿæˆå’Œå¥–åŠ±æ¨¡å‹è¯„ä¼°"""
    # å¯¹äºå·²æœ‰å“åº”çš„æ ·æœ¬ï¼Œæ£€æŸ¥æ˜¯å¦å®Œæˆ
    if sample.status == Sample.Status.COMPLETED or sample.status == Sample.Status.TRUNCATED:
        if not args.group_rm:
            assert sample.reward is not None
        return sample

    state = GenerateState(args)

    # ç”Ÿæˆ
    async with state.semaphore:
        if state.aborted:
            sample.status = Sample.Status.ABORTED
            return sample

        if args.custom_generate_function_path is not None:
            custom_generate_func = load_function(args.custom_generate_function_path)
            sample = await custom_generate_func(args, sample, sampling_params)
        else:
            sample = await generate(args, sample, sampling_params)

    if sample.status == Sample.Status.ABORTED:
        return sample

    # å¯¹äºéœ€è¦æ•´ä¸ªç»„çš„å¥–åŠ±æ¨¡å‹ï¼Œä¸åœ¨è¿™é‡Œè¯„ä¼°
    if args.group_rm:
        return sample

    # è¯„ä¼°å¥–åŠ±
    sample.reward = await async_rm(args, sample)
    return sample
```

3. `abort` å‡½æ•°

```python
async def abort(args, rollout_id: int):
    """ä¸­æ–­ç”Ÿæˆè¿‡ç¨‹"""
    aborted_samples = []
    state = GenerateState(args)
    state.aborted = True
    
    # ä¸­æ–­æ‰€æœ‰è¯·æ±‚
    response = await get(f"http://{args.sglang_router_ip}:{args.sglang_router_port}/list_workers")
    for url in response["urls"]:
        await post(f"{url}/abort_request", {"abort_all": True})

    # æ”¶é›†éƒ¨åˆ†å®Œæˆçš„æ ·æœ¬
    while state.pendings:
        done, state.pendings = await asyncio.wait(state.pendings, return_when=asyncio.FIRST_COMPLETED)
        for task in done:
            group = task.result()
            aborted_samples.append(group)

    return aborted_samples
```
</details>

### SFT Rollout (`sft_rollout.py`)

ä¸“é—¨ç”¨äºç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰çš„æ ·æœ¬å¤„ç†æ¨¡å—ï¼šä½¿ç”¨ tokenizer å¯¹æ ·æœ¬è¿›è¡Œåˆ†è¯ï¼Œç”Ÿæˆç”¨äºè®­ç»ƒçš„æŸå¤±æ©ç ï¼Œè®¡ç®—å“åº”éƒ¨åˆ†çš„é•¿åº¦ã€‚

<details>

```python
def generate_rollout(args, rollout_id, data_buffer, evaluation=False):
    # è·å–æ ·æœ¬
    samples = data_buffer.get_samples(args.rollout_batch_size)
    
    for sample in samples:
        # ç”ŸæˆæŸå¤±æ©ç 
        token_ids, loss_mask = MASK_GENERATOR.get_loss_mask(messages)
        response_length = MASK_GENERATOR.get_response_lengths([loss_mask])[0]
        
        # è®¾ç½®æ ·æœ¬å±æ€§
        sample.tokens = token_ids
        sample.response_length = response_length
        sample.reward = 0
        sample.loss_mask = loss_mask[-response_length:]
    
    return samples
```
</details>

### `filter_hub/`

ç”¨äºå®ç°åŠ¨æ€è¿‡æ»¤ï¼ˆdynamic sampling filterï¼‰å’Œè¿‡é‡‡æ ·è¿‡æ»¤ï¼ˆover sampling filterï¼‰æœºåˆ¶ï¼Œç¡®ä¿æ ·æœ¬è´¨é‡ã€‚

1. dynamic sampling filters

è¿‡æ»¤æ‰ reward std ä¸º 0 çš„æ ·æœ¬ç»„ï¼ˆåˆ é™¤å…¨ 0/1 æ ·æœ¬ç»„ï¼‰

<details>
<summary>dynamic sampling filters å®ç°</summary>

```python
def check_reward_nonzero_std(args, samples: list[Sample], **kwargs):
    """
    æ£€æŸ¥æ ·æœ¬ç»„çš„å¥–åŠ±æ ‡å‡†å·®æ˜¯å¦å¤§äº0
    
    Args:
        args: å…¨å±€å‚æ•°
        samples: æ ·æœ¬åˆ—è¡¨
        **kwargs: é¢å¤–å‚æ•°
    
    Returns:
        bool: å¦‚æœæ ‡å‡†å·®å¤§äº0è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    rewards = [sample.get_reward_value(args) for sample in samples]
    return torch.tensor(rewards, dtype=torch.float).std() > 0.0
```


2. over sampling filters

æŒ‰å¥–åŠ±æ ‡å‡†å·®å¯¹æ ·æœ¬ç»„è¿›è¡Œæ’åºï¼Œä¼˜å…ˆé€‰æ‹©æ–¹å·®å¤§çš„æ ·æœ¬ç»„ï¼Œé»˜è®¤ä¸æ‰“å¼€

<details>
<summary>over sampling filters å®ç°</summary>

```python
def sort_by_reward_std(args, samples: list[list[Sample]], **kwargs) -> list[list[Sample]]:
    """
    æŒ‰å¥–åŠ±æ ‡å‡†å·®å¯¹æ ·æœ¬ç»„è¿›è¡Œæ’åº
    
    Args:
        args: å…¨å±€å‚æ•°
        samples: æ ·æœ¬ç»„åˆ—è¡¨
        **kwargs: é¢å¤–å‚æ•°
    
    Returns:
        list[list[Sample]]: æŒ‰æ ‡å‡†å·®é™åºæ’åºçš„æ ·æœ¬ç»„
    """
    samples_with_std = []
    for group in samples:
        rewards = [item.reward for item in group]
        std = torch.tensor(rewards, dtype=torch.float).std()
        samples_with_std.append((group, std))
    
    # æŒ‰æ ‡å‡†å·®é™åºæ’åºï¼ˆpython sortæ˜¯ç¨³å®šçš„ï¼‰
    samples_with_std.sort(key=lambda x: x[1], reverse=True)
    return [item[0] for item in samples_with_std]
```
</details>

### å¥–åŠ±æ¨¡å‹é›†åˆ (`rm_hub/`)

å¯¹ç”Ÿæˆæ ·æœ¬çš„è¯„ä¼°æœºåˆ¶ï¼Œæ”¯æŒå¤šç§è¯„ä¼°æ–¹å¼ï¼š

- DeepScaler: åŸºäºè§„åˆ™çš„å¥–åŠ±æ¨¡å‹
- DAPO/Math: æ•°å­¦é—®é¢˜è¯„ä¼°æ¨¡å‹
- F1: F1åˆ†æ•°è®¡ç®—æ¨¡å‹
- Remote RM: è¿œç¨‹å¥–åŠ±æ¨¡å‹æ¥å£

1. `async_rm`

æ ¹æ®é…ç½®çš„å¥–åŠ±æ¨¡å‹ç±»å‹è¯„ä¼°å•ä¸ªæ ·æœ¬ã€‚

<details>
<summary>async_rm å®ç°</summary>

```python
async def async_rm(args, sample: Sample, **kwargs):
    """
    å¼‚æ­¥è¯„ä¼°å•ä¸ªæ ·æœ¬çš„å¥–åŠ±
    
    Args:
        args: å…¨å±€å‚æ•°
        sample: å¾…è¯„ä¼°çš„æ ·æœ¬
        **kwargs: é¢å¤–å‚æ•°
    
    Returns:
        float: å¥–åŠ±å€¼
    """
    if args.custom_rm_path is not None:
        rm_function = load_function(args.custom_rm_path)
        return await rm_function(args, sample, **kwargs)

    rm_type = args.rm_type
    response = sample.response
    label = sample.label
    
    # å¤„ç†ç‰¹æ®Šå‰ç¼€
    if rm_type.startswith("boxed_"):
        response = extract_boxed_answer(response) or ""
        rm_type = rm_type[len("boxed_"):]

    # æ ¹æ®ç±»å‹é€‰æ‹©å¥–åŠ±æ¨¡å‹
    if rm_type == "remote_rm":
        return await remote_rm(args, sample)
    elif rm_type == "deepscaler":
        return get_deepscaler_rule_based_reward(response, label)
    elif rm_type == "dapo":
        return compute_score_dapo(response, label)
    elif rm_type == "math":
        return 1 if grade_answer_verl(response, label) else 0
    elif rm_type == "f1":
        return f1_score(response, label)[0]
    else:
        raise NotImplementedError(f"Rule-based RM for {rm_type} is not implemented.")
```
</details>

2. `batched_async_rm`

æ‰¹é‡è¯„ä¼°å¤šä¸ªæ ·æœ¬çš„å¥–åŠ±ï¼Œæé«˜è¯„ä¼°æ•ˆç‡ã€‚

<details>
<summary>batched_async_rm å®ç°</summary>


```python
async def batched_async_rm(args, samples: list[Sample], **kwargs) -> list[Union[int, float]]:
    """
    æ‰¹é‡å¼‚æ­¥è¯„ä¼°å¤šä¸ªæ ·æœ¬çš„å¥–åŠ±
    
    Args:
        args: å…¨å±€å‚æ•°
        samples: æ ·æœ¬åˆ—è¡¨
        **kwargs: é¢å¤–å‚æ•°
    
    Returns:
        list[Union[int, float]]: å¥–åŠ±å€¼åˆ—è¡¨
    """
    if args.custom_rm_path is not None:
        rm_function = load_function(args.custom_rm_path)
        return await rm_function(args, samples, **kwargs)
    
    tasks = [async_rm(args, sample, **kwargs) for sample in samples]
    rewards = await asyncio.gather(*tasks)
    return rewards
```