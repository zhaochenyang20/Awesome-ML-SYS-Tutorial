# é€šè¿‡ Torch Memory Snapshot åˆ†æ VLM RL è®­ç»ƒä¸­çš„æ˜¾å­˜æ³„éœ²é—®é¢˜

å‰ä¸€æ®µæ—¶é—´æˆ‘ä»¬åœ¨ RL è®­ç»ƒå’Œ SGLang æœ¬èº«çš„æ¨ç†å½“ä¸­éƒ½é‡åˆ°äº†ä¸€å®šçš„æ˜¾å­˜æ³„éœ²é—®é¢˜ã€‚æ˜¨å¤©ç»ˆäºæƒ³æ˜ç™½äº†å…·ä½“æ³„éœ²çš„åŸå› ï¼Œè¿™ç¯‡æ–‡ç« åˆ†äº«æˆ‘ä»¬åŸºäº Torch Memory Snapshot çš„æ’æŸ¥è¿‡ç¨‹ï¼Œä»¥åŠåˆ†äº«æˆ‘ä»¬å¯¹æ˜¾å­˜æ³„éœ²é—®é¢˜çš„è§£å†³æ–¹æ¡ˆã€‚

ç‰¹åˆ«è‡´è°¢ï¼šHongyu Lu (TikTok), Xinpeng Wei (Amazon), Rohan Bavishi (Amazon), Vint Lee (Amazon), Daisy Lin (Amazon), Deniz Birlikci (Amazon), Shahil Patel (Amazon), XJ Wang (Amazon), Huapeng Zhou (UW), Changyi Yang (CMU), Xinyuan Tong (USC), Yuhao Yang (HKU), Biao He (LinkedIn), Zhuoran Yin (CMU), Chenyang Zhao (LMSYS)
## èƒŒæ™¯

å¾ˆæœ‰æ„æ€çš„æ˜¯ï¼Œæˆ‘ä»¬å¹¶ä¸æ˜¯ä¸ºäº†æ”¯æŒåˆ†ææ˜¾å­˜æ³„éœ²æ‰ç°åœºå­¦ä¹ çš„ Torch Memory Snapshotï¼Œè€Œæ˜¯å¤§æ¦‚ä¸€ä¸ªæœˆå‰ï¼Œåœ¨è§£å†³ FSDP2 é—®é¢˜çš„æ—¶å€™å°±åœ¨é€æ­¥ä½¿ç”¨äº†ã€‚å›åˆ°æˆ‘ä»¬å…ˆå‰çš„æ–‡ç« ï¼Œ[FSDP è®­ç»ƒåç«¯](../../rlhf/sys-design/readme-2.md#fsdp-in-verl)ï¼Œæˆ‘ä»¬æåˆ°è¿‡ï¼Œç›´è§‰ä¸Šä» FSDP1 åˆ‡æ¢åˆ° FSDP2 å¹¶ä¸éº»çƒ¦ï¼Œåªéœ€è¦ä¿®æ”¹å››è¡Œé…ç½®ï¼š

```bash
actor_rollout_ref.ref.strategy=fsdp2
actor_rollout_ref.actor.strategy=fsdp2
critic.strategy=fsdp2
reward_model.strategy=fsdp2
```

ç„¶è€Œå¾ˆä¸å¹¸ï¼Œæˆ‘ä»¬æƒŠå¥‡çš„å‘ç°ï¼ŒFSDP1 çš„è„šæœ¬å¹³ç§»åˆ° FSDP2 ä¸Šåï¼Œç¨³å®šä¼š OOMã€‚æ›´ç¥å¥‡çš„æ˜¯ï¼Œæˆ‘ä»¬æŠŠè‡ªå·± OOM çš„è„šæœ¬äº¤ç»™ verl å›¢é˜Ÿå’Œ Pytorch è´Ÿè´£ FSDP2 çš„å·¥ç¨‹å¸ˆï¼Œä»–ä»¬å‘è§‰ 8B æ¨¡å‹ä¸ä¼š OOMï¼Œä½†æ˜¯ 3B æ¨¡å‹ç¨³å®š OOMã€‚æŠ˜è…¾äº†å¾ˆä¹…ï¼Œæœ€åé€šè¿‡ `set_expandable_segments(True)` è§£å†³äº†é—®é¢˜ï¼Œç›¸å…³ PR è§[3020](https://github.com/volcengine/verl/pull/3020)ã€‚

<details>
<summary>Expandable Segments æœºåˆ¶</summary>

`set_expandable_segments(True)` é€šè¿‡å¼€å¯ CUDA çš„å¯æ‰©å±•å†…å­˜æ®µåŠŸèƒ½ï¼Œä½¿å¾— PyTorch èƒ½å¤Ÿæ›´çµæ´»åœ°ç®¡ç† GPU å†…å­˜ã€‚PyTorch åœ¨ CUDA åç«¯ä¸Šçš„å†…å­˜åˆ†é…ä¸»è¦ç”± CUDA caching allocator ç®¡ç†ã€‚allocator ä¸ä¼šç«‹å³å°†é‡Šæ”¾çš„å†…å­˜è¿”å›ç»™æ“ä½œç³»ç»Ÿï¼Œè€Œæ˜¯å°†å…¶ä¿å­˜åœ¨ä¸€ä¸ªå†…éƒ¨çš„å†…å­˜æ± ä¸­ï¼Œä»¥ä¾¿åç»­çš„å†…å­˜è¯·æ±‚å¯ä»¥å¿«é€Ÿå¾—åˆ°æ»¡è¶³ã€‚è¿™ç§æœºåˆ¶é€šè¿‡å‡å°‘ä¸ CUDA API çš„äº¤äº’æ¥æé«˜æ€§èƒ½ã€‚å†…å­˜æ± å®è´¨ä¸Šç”± segment å’Œ block ä¸¤ä¸ªæ¦‚å¿µæ¥æè¿°ã€‚

1. Segments (å†…å­˜æ®µ)ï¼šå†…å­˜æ®µæ˜¯ PyTorch ä» CUDA é©±åŠ¨ç¨‹åºè¯·æ±‚çš„å¤§å—è¿ç»­å†…å­˜ã€‚è¿™äº›æ®µæ˜¯å†…å­˜åˆ†é…çš„æœ€å°å•ä½ï¼Œæ‰€æœ‰çš„ PyTorch å¼ é‡å’Œæ•°æ®éƒ½å­˜å‚¨åœ¨è¿™äº›æ®µä¸­ã€‚æ‰€æœ‰åˆ†é…çš„ segment æ€»å’Œå°±æ˜¯ Reserved Memoryã€‚
2. Blocks (å†…å­˜å—)ï¼šæ¯ä¸ªå†…å­˜æ®µéƒ½åŒ…å«è®¸å¤šå°å—å†…å­˜ï¼ˆblocksï¼‰ã€‚å½“ PyTorch éœ€è¦åˆ†é…å†…å­˜æ—¶ï¼Œå®ƒä¼šåœ¨ä¸€ä¸ªç°æœ‰çš„æ®µä¸­å¯»æ‰¾ä¸€ä¸ªåˆé€‚çš„ç©ºé—²å—ã€‚å¦‚æœæ‰¾ä¸åˆ°ï¼Œå®ƒä¼šå°è¯•ä» CUDA é©±åŠ¨ç¨‹åºä¸­ç”³è¯·ä¸€ä¸ªæ–°çš„æ®µã€‚æ‰€æœ‰åˆ†é…çš„ block æ€»å’Œå°±æ˜¯ Allocated Memoryã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œå½“ PyTorch çš„ caching allocator æ— æ³•åœ¨ç°æœ‰å†…å­˜æ®µä¸­æ‰¾åˆ°è¶³å¤Ÿå¤§çš„ç©ºé—²å—æ—¶ï¼Œå®ƒä¼šå‘ CUDA é©±åŠ¨ç¨‹åºè¯·æ±‚ä¸€ä¸ªæ–°çš„å†…å­˜æ®µã€‚è¿™ä¸ªæ–°æ®µçš„å¤§å°æ˜¯æ ¹æ®å½“å‰çš„å†…å­˜éœ€æ±‚åŠ¨æ€å†³å®šçš„ã€‚ä½†æ˜¯ï¼Œè¿™ç§åŠ¨æ€æ‰©å±•æœºåˆ¶å¯èƒ½å¯¼è‡´å†…å­˜ç¢ç‰‡åŒ–ï¼Œå…ˆå‰åˆ†é…çš„ segment ç•™ä¸‹çš„ block è¿Ÿè¿Ÿæ— æ³•è¢«åˆ©ç”¨ï¼Œå°¤å…¶æ˜¯åœ¨ PyTorch å†…å­˜åˆ†é…å™¨é¢‘ç¹åœ°é‡Šæ”¾å’Œç”³è¯·å¤§å—å†…å­˜çš„æƒ…å†µä¸‹ã€‚

å›åˆ° FSDP ä¸Šï¼ŒFSDP é»˜è®¤é‡‡ç”¨ zero3 çš„ç­–ç•¥ï¼Œåœ¨ forward å’Œ backward éƒ½éœ€è¦ all gatherï¼Œæ¯ä¸ª GPU èŠ‚ç‚¹ä¼šä¸´æ—¶èšåˆå…¶ä»–èŠ‚ç‚¹çš„ parameter shardï¼Œè¿™ä¼šåˆ›å»ºä¸´æ—¶çš„å¤§é‡å¼ é‡ï¼Œå¯¼è‡´å¯¹è¿ç»­å†…å­˜çš„éœ€æ±‚æ¿€å¢ã€‚åœ¨ä¼ ç»Ÿçš„å†…å­˜ç®¡ç†æ¨¡å¼ä¸‹ï¼Œå¦‚æœ caching allocator æ— æ³•æ‰¾åˆ°ä¸€ä¸ªè¶³å¤Ÿå¤§çš„è¿ç»­å†…å­˜å—æ¥å®¹çº³è¿™äº›ä¸´æ—¶çš„å¤§å¼ é‡ï¼Œå°±ä¼šç›´æ¥ OOMã€‚å³ä½¿ GPU ä»æœ‰å¯ç”¨å†…å­˜ï¼Œä½†ç”±äºå†…å­˜ç¢ç‰‡åŒ–ï¼Œæ²¡æœ‰è¶³å¤Ÿçš„è¿ç»­ç©ºé—´æ¥å®¹çº³æ‰€éœ€çš„æ–°å¼ é‡ã€‚

`torch.cuda.memory._set_allocator_settings("expandable_segments:True")` å°† PyTorch çš„å†…å­˜ç®¡ç†æ¨¡å¼åˆ‡æ¢ä¸ºä¸€ç§æ›´çµæ´»çš„æ¨¡å¼ã€‚å¼€å¯è¯¥åŠŸèƒ½åï¼Œå½“ caching allocator éœ€è¦æ›´å¤§çš„è¿ç»­å†…å­˜æ—¶ï¼Œå®ƒä¸å†ä»…ä»…å°è¯•ä» CUDA é©±åŠ¨ç¨‹åºä¸­è¯·æ±‚ä¸€ä¸ªå…¨æ–°çš„æ®µï¼Œè€Œæ˜¯å°è¯•æ‰©å±•å·²æœ‰çš„å†…å­˜æ®µã€‚è¿™ç§æ‰©å±•æœºåˆ¶å…è®¸ PyTorch é‡æ–°è°ƒæ•´å…¶å†…å­˜å¸ƒå±€ï¼Œå°†åˆ†æ•£çš„ç©ºé—²å†…å­˜å—æ‰©å±•æˆ–è€…åˆå¹¶ä¸ºæ›´å¤§çš„è¿ç»­å—ï¼Œä»è€Œæ»¡è¶³é‚£äº›å¯¹å¤§å—å†…å­˜æœ‰éœ€æ±‚çš„ä¸´æ—¶å¼ é‡çš„åˆ†é…ã€‚
</details>

æ€»ä¹‹ï¼Œå¯¹ torch memory snapshot çš„åˆ†æï¼Œå…¶å®æ˜¯æˆ‘ä»¬ä» FSDP2 çš„ OOM é—®é¢˜ä¸­å­¦ä¹ åˆ°çš„ï¼Œä¸ºæˆ‘ä»¬å»è§£å†³ RL è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ˜¾å­˜æ³„éœ²åŸ‹ä¸‹äº†ä¼ç¬”ã€‚

## å¦‚ä½•è§‚å¯Ÿæ˜¾å­˜å ç”¨

ç»è¿‡å‰æ–‡çš„é“ºå«ï¼Œæˆ‘ä»¬ç»ˆäºå¯ä»¥å¼€å§‹ä»‹ç»å¦‚ä½•ä½¿ç”¨ Torch Memory Snapshot æ¥åˆ†ææ˜¾å­˜æ³„éœ²é—®é¢˜äº†ã€‚

### torch.cuda.memory_summary

åœ¨ä»‹ç» mem snapshot ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹æœ€ç®€å•çš„æ˜¾å­˜æŸ¥è¯¢æ–¹æ³•ï¼š

<details>
<summary>æœ€ç®€å•çš„æ˜¾å­˜æŸ¥è¯¢æ–¹æ³•</summary>

```python
    @DynamicGradMode()
    def event_loop_overlap(self):
        """A scheduler loop that overlaps the CPU processing and GPU computation."""
        self.result_queue = deque()

        # åˆå§‹åŒ–å†…å­˜æ—¥å¿—æ–‡ä»¶
        if not hasattr(self, "_memory_log_file"):
            import datetime

            start_time = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            self._memory_log_filename = f"{start_time}_memory_log.txt"
            self._memory_log_file = open(self._memory_log_filename, "w")
            self._memory_log_file.write(
                "timestamp,memory_summary,memory_allocated,memory_reserved\n"
            )
            self._memory_log_file.flush()

        while True:
            current_time = time.time()
            if (
                not hasattr(self, "_last_memory_log_time")
                or current_time - self._last_memory_log_time >= 1.0
            ):
                gc.collect()
                torch.cuda.empty_cache()

                # è·å–å†…å­˜ä¿¡æ¯
                memory_summary = torch.cuda.memory_summary(
                    device=self.gpu_id, abbreviated=True
                )
                memory_allocated = torch.cuda.memory_allocated()
                memory_reserved = torch.cuda.memory_reserved()

                # è½¬æ¢ä¸ºMB
                memory_allocated_mb = memory_allocated / (1024 * 1024)
                memory_reserved_mb = memory_reserved / (1024 * 1024)

                # è®°å½•æ—¶é—´æˆ³
                timestamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())

                # å†™å…¥æ—¥å¿—æ–‡ä»¶
                self._memory_log_file.write(
                    f"{timestamp},\"{memory_summary.replace(',', ';')}\",{memory_allocated_mb:.2f},{memory_reserved_mb:.2f}\n"
                )
                self._memory_log_file.flush()

                # æ›´æ–°æ—¶é—´è®°å½•
                self._last_memory_log_time = current_time

                # åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°ï¼ˆå¯é€‰ï¼‰
                print(f"[{timestamp}] Memory allocated: {memory_allocated_mb:.2f} MB")
                print(f"[{timestamp}] Memory reserved: {memory_reserved_mb:.2f} MB")
```

</details>

è¿™æ˜¯æˆ‘ä»¬åœ¨æ’æŸ¥ SGLang æ˜¾å­˜æ³„éœ²åŸå› è¿‡ç¨‹ä¸­ï¼Œåœ¨è¿™ä¸ª [commit](https://github.com/sgl-project/sglang/pull/9071/files#diff-c3b8cc39d10c245933a25aa9c2fd6397f6b31ed8d85c0ecbb926c1f42afdd178) é‡Œé¢ä½¿ç”¨çš„ä¸€å¥—å›æ”¶ + æ‰“å°æ˜¾å­˜æ—¥å¿—çš„ä»£ç ã€‚ç®€å•æ¥è¯´ï¼Œè¿™ä¸ªä»£ç çš„é€»è¾‘æ˜¯ï¼š

1. æ¯ 1s é€šè¿‡ `torch.cuda.memory_summary, torch.cuda.memory_allocated, torch.cuda.memory_reserved` æ‰“å°æ˜¾å­˜å ç”¨æƒ…å†µ
2. æ¯ 1s é€šè¿‡ `gc.collect, torch.cuda.empty_cache` å›æ”¶æ˜¾å­˜

æˆ‘ä»¬å…ˆæŒ‰ä¸‹ `gc.collect, torch.cuda.empty_cache` ä¸è¡¨ï¼Œçœ‹çœ‹ `torch.cuda.memory_summary, torch.cuda.memory_allocated, torch.cuda.memory_reserved` çš„è¾“å‡º:

<details>
<summary>torch.cuda.memory_summary çš„è¾“å‡º</summary>

```bash
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      | 184648 KiB | 192833 KiB | 258378 KiB |  73729 KiB |
|       from large pool | 184576 KiB | 192768 KiB | 254208 KiB |  69632 KiB |
|       from small pool |     72 KiB |   1060 KiB |   4170 KiB |   4097 KiB |
|---------------------------------------------------------------------------|
| Active memory         | 184648 KiB | 192833 KiB | 258378 KiB |  73729 KiB |
|       from large pool | 184576 KiB | 192768 KiB | 254208 KiB |  69632 KiB |
|       from small pool |     72 KiB |   1060 KiB |   4170 KiB |   4097 KiB |
|---------------------------------------------------------------------------|
| Requested memory      | 184648 KiB | 192832 KiB | 258376 KiB |  73728 KiB |
|       from large pool | 184576 KiB | 192768 KiB | 254208 KiB |  69632 KiB |
|       from small pool |     72 KiB |   1060 KiB |   4168 KiB |   4096 KiB |
|---------------------------------------------------------------------------|
| GPU reserved memory   | 235520 KiB | 235520 KiB | 235520 KiB |      0 B   |
|       from large pool | 233472 KiB | 233472 KiB | 233472 KiB |      0 B   |
|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |
|---------------------------------------------------------------------------|
| Non-releasable memory |  30391 KiB |  38607 KiB | 132985 KiB | 102594 KiB |
|       from large pool |  28416 KiB |  36608 KiB | 126848 KiB |  98432 KiB |
|       from small pool |   1975 KiB |   2040 KiB |   6137 KiB |   4162 KiB |
|---------------------------------------------------------------------------|
| Allocations           |      21    |      23    |      42    |      21    |
|       from large pool |      12    |      14    |      26    |      14    |
|       from small pool |       9    |      10    |      16    |       7    |
|---------------------------------------------------------------------------|
| Active allocs         |      21    |      23    |      42    |      21    |
|       from large pool |      12    |      14    |      26    |      14    |
|       from small pool |       9    |      10    |      16    |       7    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      10    |      10    |      10    |       0    |
|       from large pool |       9    |       9    |       9    |       0    |
|       from small pool |       1    |       1    |       1    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |       6    |       6    |      13    |       7    |
|       from large pool |       4    |       5    |      11    |       7    |
|       from small pool |       2    |       2    |       2    |       0    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|
```

</details>

çœ‹ä¸Šå»è¾“å‡ºçš„å†…å®¹éå¸¸å¤šï¼Œä½†æ˜¯ä»”ç»†è¯»è¯»ï¼Œå…¶å®å†…å®¹éå¸¸ç®€å•ï¼Œç›´æ¥å¾—åˆ°äº†å¯¹åº”æ˜¾å¡ï¼ˆrankï¼‰ä¸Šçš„æ‰€æœ‰è¿›ç¨‹çš„æ˜¾å­˜å ç”¨æƒ…å†µã€‚æˆ‘ä¼šåœ¨è¿™éƒ¨åˆ†åå¤å¼ºè°ƒè¿›ç¨‹çš„æ¦‚å¿µï¼Œåç»­è¯»è€…ä¼šé€æ¸ä½“ä¼šåˆ°è·å¾—æ˜¾å­˜å ç”¨çš„æ–¹æ³•å…¶å®é«˜åº¦å—åˆ°è¿›ç¨‹çš„å½±å“ã€‚

æ­¤å¤–ï¼Œæˆ‘ä»¬æ¥å›é¡¾ä¸‹ï¼Œå¯¹äº SGLang è€Œè¨€ï¼Œå¦‚æœæŸä¸ªä¸»è¿›ç¨‹ç›´æ¥ init äº†ä¸€ä¸ª SGLang Engineï¼Œå®é™…ä¸Šä¼šå¾—åˆ°ä¸‰ä¸ªè¿›ç¨‹ã€‚åˆå§‹åŒ– Engine çš„ä¸»è¿›ç¨‹ä¼šå¾—åˆ°ä¸€ä¸ª Engine å®ä¾‹å’Œ Tokenizer Mangerï¼›ç¬¬äºŒä¸ªè¿›ç¨‹ä¼šåˆå§‹åŒ– SGLang Schedulerï¼Œè¿™ä¸ªè¿›ç¨‹æ‰æ˜¯å®é™…ä¸Šå æ®ç»å¤§å¤šæ•°ç°å­˜çš„æ ¸å¿ƒè¿›ç¨‹ï¼›æœ€åä¸€ä¸ªè¿›ç¨‹ä¼šåˆå§‹åŒ– SGLang Detokenizer Managerã€‚

æ³¨æ„ï¼Œæˆ‘ä»¬ä¸Šæ–¹çš„ä»£ç è™½ç„¶æ˜¯ç›´æ¥åœ¨ SGLang scheduler ä¸€å±‚åŠ å…¥çš„æ˜¾å­˜ç›‘æ§ï¼Œä½†æ˜¯ `torch.cuda.memory_summary` å®é™…ä¸Šç›‘æ§çš„æ˜¯æ•´ä¸ª rank ä¸Šçš„æ˜¾å­˜å ç”¨æƒ…å†µã€‚`torch.cuda.memory_summary` æ˜¯ä¸åŒºåˆ†è¿›ç¨‹çš„ï¼Œè€Œ `torch.cuda.memory._dump_snapshot()` å¾—åˆ°çš„åªæœ‰å½“å‰è¿›ç¨‹çš„æ˜¾å­˜å ç”¨æƒ…å†µã€‚

è¿™å¬ä¸Šå»æ²¡ä»€ä¹ˆæ„æ€ï¼Œä½†æ˜¯åœ¨ RL åœºæ™¯ä¸‹ï¼Œæƒ…å†µä¼šå¤§ä¸ºä¸åŒã€‚ä»¥ verl ä¸¾ä¾‹ï¼Œverl çš„ FSDP worker æ‰€åœ¨è¿›ç¨‹åˆå§‹åŒ–äº† SGLang Engineï¼Œè¿™æ · FSDP worker å’Œ SGLang Scheduler ä¸åœ¨ä¸€ä¸ªè¿›ç¨‹å†…ã€‚å¦‚æœæˆ‘ä»¬ä¸€ç›´åœ¨ FSDP worker ä¸Šé€šè¿‡ `torch.cuda.memory._dump_snapshot()` ç›‘æ§æ˜¾å­˜ï¼Œé‚£ä¹ˆæˆ‘ä»¬åªèƒ½ç›‘æ§åˆ° FSDP worker çš„æ˜¾å­˜å ç”¨æƒ…å†µï¼Œè€Œæ— æ³•ç›‘æ§åˆ° SGLang Scheduler çš„æ˜¾å­˜å ç”¨æƒ…å†µã€‚æ­£æ˜¯è¿™ä¸ªåŸå› ï¼Œè®©æˆ‘ä»¬åœ¨æ’æŸ¥ RL è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ˜¾å­˜æ³„éœ²é—®é¢˜æ—¶ï¼Œæ ¹æœ¬æ²¡æœ‰å¯¹ SGLang Scheduler çš„æ˜¾å­˜æ³„éœ²è¿›è¡Œç›‘æ§ï¼Œå¾ˆé•¿æ—¶é—´éƒ½æ²¡æœ‰è¿›å±•ã€‚


### torch.cuda.memory._dump_snapshot

ä»‹ç»å®Œäº† `torch.cuda.memory_summary`ï¼Œæˆ‘ä»¬å†æ¥çœ‹çœ‹ `torch.cuda.memory._dump_snapshot` çš„è¾“å‡ºã€‚è™½ç„¶å¬ä¸Šå» `memory_summary` çš„è¾“å‡ºæ›´åŠ å…¨å±€ï¼Œæ¯•ç«Ÿæ˜¯ç›´æ¥ç›‘æ§ rank ä¸Šæ‰€æœ‰çš„è¿›ç¨‹ï¼Œä½†æ˜¯å¤§å®¶ä¹Ÿçœ‹åˆ°äº†ï¼Œæˆ‘ä»¬æ— æ³•é€šè¿‡ `memory_summary` å¾—åˆ°ç»†è‡´çš„æ˜¾å­˜ç®¡ç†ä¿¡æ¯ã€‚æ¯”å¦‚ `memory_summary` å‘Šè¯‰æˆ‘ä»¬ reserved memory æ˜¯ 144GBï¼Œä½†æ˜¯å…·ä½“æ˜¯å“ªäº›è¿›ç¨‹å“ªäº› tensor å®é™…å ç”¨äº†å¤šå°‘ï¼Œæˆ‘ä»¬æ— æ³•å¾—çŸ¥ã€‚`torch.cuda.memory._dump_snapshot` æ­£æ˜¯ä¸ºè¿™ä¸€éœ€æ±‚è€Œè®¾è®¡çš„ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å¾—åˆ°å½“å‰è¿›ç¨‹åœ¨ç›‘è§†èŒƒå›´å†…çš„æ¯ä¸€ä¸ª tensor çš„åˆ›å»ºã€å ç”¨å’Œé”€æ¯ã€‚è®©æˆ‘ä»¬æ¥çœ‹çœ‹å…·ä½“ç”¨æ³•ï¼š

<details>
<summary>torch.cuda.memory._dump_snapshot çš„ç”¨æ³•</summary>

```python
def enable_memory_visualize(
    trace_alloc_max_entries: int = 200_000,
    stack_depth: int = 32,
    context: str = "all",
    stacks: str = "all",
    devices=None,
    record_context: bool = True,
):
    """
    Enables memory history recording for CUDA allocations. This function
    should be called before any large-scale CUDA allocations. For DDP or
    multi-process setups, it must be called on each rank.

    Args:
        trace_alloc_max_entries (int): Maximum number of allocation entries
            to record.
        stack_depth (int): The depth of the call stack to capture for each
            allocation. (Supported by some PyTorch versions).
        context (str): The type of memory events to record.
            'alloc': records only allocation events.
            'state': records memory state changes.
            'all': records both.
        stacks (str): The type of call stacks to record.
            'python': records Python stacks.
            'cpp': records C++ stacks (available in some versions).
            'all': records both.
        devices (Union[int, list[int], None]): The device for which to enable
            memory history. `None` enables it for the current default device.
        record_context (bool): Whether to record context information for
            allocations. Required by older PyTorch versions.
    """
    # Memory history recording is CUDA-specific functionality
    if not is_cuda_available:
        logger.warning("[memory_visualize] Memory history recording is only available on CUDA devices")
        return

    f = get_torch_device().memory._record_memory_history
    params = set(inspect.signature(f).parameters.keys())

    def _one_call(dev_kw=None):
        kwargs = {}
        if "context" in params:
            kwargs["context"] = context
        if "stacks" in params:
            kwargs["stacks"] = stacks
        if "max_entries" in params:
            kwargs["max_entries"] = trace_alloc_max_entries
        elif "trace_alloc_max_entries" in params:
            kwargs["trace_alloc_max_entries"] = trace_alloc_max_entries
        if "stack_depth" in params:
            kwargs["stack_depth"] = stack_depth
        if dev_kw is not None:
            if "device" in params:
                kwargs["device"] = dev_kw
            elif "devices" in params:
                kwargs["devices"] = dev_kw if isinstance(dev_kw, list) else [dev_kw]
        if "record_context" in params:
            kwargs["record_context"] = record_context

        try:
            f(**kwargs)
            return "native", kwargs
        except TypeError:
            try:
                if "trace_alloc_max_entries" in params and "record_context" in params:
                    f(enabled=True, trace_alloc_max_entries=trace_alloc_max_entries, record_context=True)
                    return "legacy", {
                        "enabled": True,
                        "trace_alloc_max_entries": trace_alloc_max_entries,
                        "record_context": True,
                    }
                else:
                    f(enabled=True)
                    return "legacy-min", {"enabled": True}
            except Exception:
                raise

    if devices is None or isinstance(devices, str | int | torch.device):
        mode, used = _one_call(devices if devices is not None else None)
    else:
        mode, used = "multi-device", {}
        for d in list(devices):
            _mode, _used = _one_call(d)
            used[f"dev{d}"] = _used

    device = get_torch_device()
    if device.is_available():
        device.reset_peak_memory_stats()
        device.synchronize()

    rank = int(os.environ.get("RANK", "0") or 0)
    logger.info(f"[memory_visualize][rank {rank}] recording enabled ({mode}); args={used}")


class MemorySnapshotSampler:
    """
    A utility class that dumps GPU memory snapshots.
    This is useful for monitoring memory usage over a long-running process.

    The dumped files can be visualized with https://docs.pytorch.org/memory_viz

    Args:
        out_dir (str): The directory where the snapshots will be saved.
        tag (str): A tag for the snapshot filenames.
    """

    def __init__(self, out_dir: str = "./mem_snapshots", tag: str = "periodic"):
        self.out_dir = out_dir
        self.tag = tag

    def dump_memory_snapshot(self, out_dir: str = "./mem_snapshots", tag: str = "snapshot", sub_dir: str = None):
        """
        Generates a memory snapshot and saves it as a pickle file in a specified directory.
        The files are organized by timestamp in subdirectories, with all ranks' files
        placed in the same timestamp subdirectory.

        Args:
            out_dir (str): The directory where the snapshot file will be saved.
                The directory is created if it does not exist.
            tag (str): A string tag to prepend to the filename for easier identification.
            sub_dir (str): A subdirectory to place the snapshot file in.
        """
        if sub_dir is None:
            timestamp = datetime.now().strftime("%Y%m%d-%H%M")
            out_path = Path(out_dir) / timestamp
        else:
            out_path = Path(out_dir) / sub_dir
        out_path.mkdir(parents=True, exist_ok=True)

        # get the GPU rank on the current process
        rank = os.environ.get("RANK", "0")
        pid = os.getpid()
        # todo(chenyang): check wether we need to sync all ranks before dump
        fname = f"{tag}_rank{rank}_pid{pid}.pickle"
        path = out_path / fname

        device = get_torch_device()
        if not device.is_available():
            logger.warning("[memory_visualize] is only available on CUDA devices.")
            return
        try:
            device.synchronize()
            # Memory snapshot is CUDA-specific functionality
            device.memory._dump_snapshot(str(path))
            logger.info(f"[memory_visualize] dumped: {path}")
        except Exception as e:
            logger.info(f"[memory_visualize][warn] dump failed: {e}")
```

</details>

ä»¥ä¸Šå‡½æ•°èŠ‚é€‰è‡ªæˆ‘ä»¬ç»™ verl äº¤çš„ PR [3099](https://github.com/volcengine/verl/pull/3099)ï¼Œçœ‹ç€ç±»éå¸¸å¤æ‚ï¼Œå…¶å®å¹²çš„äº‹æƒ…å¾ˆç®€å•ã€‚æˆ‘ä»¬å°† `torch.cuda.memory._dump_snapshot` æ¯”ä½œä¸€ä¸ªå½•åƒæœºï¼Œé€šè¿‡ `enable_memory_visualize` å‡½æ•°æ¥å¼€å¯å½•åƒï¼Œè€Œæ¯æ¬¡ `MemorySnapshotSampler.dump_memory_snapshot` åˆ™ç›¸å½“äºå°†å½•åƒæœºå·²ç»æ‹åˆ°çš„å†…å®¹ä¿å­˜åˆ°æœ¬åœ°ã€‚æ˜¾ç„¶ï¼Œæˆ‘ä»¬ç›‘æ§ memory çš„æ—¶é—´è¶Šé•¿ï¼Œä¿å­˜ä¸‹æ¥çš„ memory step å°±è¶Šå¤šï¼Œæ–‡ä»¶å¤§å°è¶Šå¤§ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬ä¼šåœ¨ `enable_memory_visualize` ä¸­è®¾ç½® `trace_alloc_max_entries, stack_depth` æ¥é™åˆ¶ä¿å­˜çš„ memory trace çš„æ¡æ•°å’Œæ·±åº¦ã€‚æ¯æ¬¡è°ƒç”¨ `MemorySnapshotSampler.dump_memory_snapshot` æ—¶ï¼Œä¼šä¿å­˜å½“å‰ç›‘æ§èŒƒå›´å†…çš„æ‰€æœ‰ tensor çš„åˆ›å»ºã€å ç”¨å’Œé”€æ¯ã€‚æ­¤å¤–ï¼Œå¦‚æœå¼€å¯ `enable_memory_visualize` çš„æ—¶é—´å¤ªæ™šäº†ï¼Œæœ‰äº› tensor å·²ç»åœ¨è¿™ä¹‹å‰å°±åˆ›å»ºäº†ï¼Œé‚£ä¹ˆè¿™äº› tensor çš„åˆ›å»ºã€å ç”¨å’Œé”€æ¯ä¿¡æ¯å°±æ— æ³•è¢«ç›‘æ§ã€‚

è¿™æ ·çœ‹æ¥ï¼Œ`torch.cuda.memory._dump_snapshot` çš„ç”¨æ³•ä¹Ÿæ˜¯éå¸¸æ¸…æ™°çš„ï¼Œå°±æ˜¯ç›‘æ§å½“å‰ rank çš„å½“å‰è¿›ç¨‹åœ¨ç›‘æ§èŒƒå›´å†…çš„æ‰€æœ‰ tensor çš„åˆ›å»ºã€å ç”¨å’Œé”€æ¯ã€‚æˆ‘ä»¬æœ€ç»ˆä¼šå¾—åˆ°è‹¥å¹²å¤šä¸ª pickle æ–‡ä»¶ï¼Œæ¥ç€ä¸Šä¼ åˆ° torch å®˜æ–¹çš„ [memory viz](https://pytorch.org/memory_viz) ç½‘ç«™ä¸Šï¼Œå°±å¯ä»¥çœ‹åˆ°éå¸¸ç›´è§‚çš„ memory ä½¿ç”¨æƒ…å†µã€‚


å¦‚æ­¤ä»¥æ¥ï¼Œæˆ‘ä»¬å¾—åˆ°ä¸€äº›éå¸¸å…·ä½“çš„ memory ä½¿ç”¨æƒ…å†µï¼Œè¿™é‡Œä¸¾å‡ºä¸¤ä¸ªæˆ‘æœ€å¸¸ç”¨çš„å¯è§†åŒ–ç»“æœï¼š

1. Active Memory Timeline

<img src="./pics/active-memory-timeline.png" alt="Active Memory Timeline" width="50%">

è¿™å¼ å›¾æœ‰éå¸¸éå¸¸å¤šç»†èŠ‚ï¼Œé¦–å…ˆæ˜¯æˆ‘ä»¬è§‚å¯Ÿæ•´ä½“çš„ memory æœ€é«˜ç‚¹ï¼Œå¤§è‡´å‘ç°æœ€é«˜ç‚¹åœ¨ 25GB å·¦å³ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬èƒ½æ˜æ˜¾è§‚å¯Ÿåˆ°åœ¨æˆ‘ä»¬çš„æ•´ä¸ª record é˜¶æ®µæœ‰éå¸¸å¤šçš„é˜¶æ®µï¼Œè¿™é‡Œæˆ‘ç»§ç»­æ”¾å¤§ä¸€å°éƒ¨åˆ†ï¼Œæ¥çœ‹çœ‹å…·ä½“çš„è¿™ä¸ª spikeï¼š


<img src="./pics/forward-1.png" alt="Active Memory Timeline" width="50%">

æˆ‘ä»¬è§‚å¯Ÿè¿™ä¸ª spikeï¼ŒåŒæ—¶åœ¨ä¸‹æ–¹çš„ stack å†…æŸ¥çœ‹è¿™å—æ˜¾å­˜çš„åˆ†é…æ—¶æœºï¼Œåˆ†é…è¿‡ç¨‹ï¼Œå’Œå…·ä½“å¤§å°ã€‚è¿™é‡Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿåˆ°ï¼Œæˆ‘å›¾ä¸­ç®­å¤´æŒ‡å‡ºçš„ spike å®é™…ä¸Šæ¥è‡ªäº verl FSDP çš„ forward è¿‡ç¨‹ã€‚æ›´å…·ä½“çš„ stack ç”±äºä¿å¯†é—®é¢˜ï¼Œä¸ä¾¿é€éœ²ã€‚

ä¸€ä¸ªéå¸¸æœ‰æ„æ€çš„äº‹æƒ…æ˜¯ï¼Œæˆ‘ä»¬å‘è§‰ï¼Œç›¸ä¼¼æˆ–è€…ä½œç”¨ç›¸åŒçš„æ˜¾å­˜å—ï¼Œåœ¨ä¸åŒçš„é˜¶æ®µå»æ‹æ‘„çš„ memory snapshot ä¼šè¡¨ç°çš„ç›¸å½“ä¸€è‡´ï¼Œæ¯”å¦‚ç›¸åŒçš„é¢œè‰²ã€ç›¸å¯¹ä½ç½®å’Œå¤§å°ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œæˆ‘ä»¬åœ¨ verl æ¯ä¸ª training step ç»“æŸçš„åœ°æ–¹è®°å½•ä¸€æ¬¡ memory snapshotï¼Œåœ¨ [`examples/grpo_trainer/run_qwen2_5_vl-7b-sglang.sh`](https://github.com/volcengine/verl/blob/main/examples/grpo_trainer/run_qwen2_5_vl-7b-sglang.sh) ä¸­ï¼Œæˆ‘ä»¬è§‚å¯Ÿ step 2 3 4 ç»“æŸæ—¶çš„ memory stackï¼Œå¾—åˆ°å¦‚ä¸‹ä¸‰å¼ å›¾ï¼š

<img src="./pics/step-2.png" alt="step-2" width="50%">
<img src="./pics/step-3.png" alt="step-3" width="50%">
<img src="./pics/step-4.png" alt="step-4" width="50%">

æˆ‘ä»¬æ³¨æ„è§‚å¯Ÿ step 2 çš„æ—¶å€™ï¼Œåœ¨ 7.2GB 7.6GB å’Œ 7.8GB ä¸‰ä¸ªä½ç½®ï¼Œéƒ½æœ‰è¿ç»­çš„å¤§çš„å†…å­˜å—ï¼Œå‡ä¸º 512MB å¤§å°ï¼ˆæŸ¥çœ‹ stackï¼Œå®é™…ä¸Šæ˜¯ optimizer stateï¼‰ã€‚æ¥ç€ï¼Œåˆ°äº† step 3 çš„æ—¶å€™ï¼Œ7.2GB ä½ç½®çš„ 512MB æ˜¾å­˜å—è¿˜åœ¨ä¸€æ¨¡ä¸€æ ·çš„ä½ç½®ï¼Œä½†æ˜¯åœ¨ step 2 çš„ 7.6GB çš„å†…å­˜å—å·²ç»ç§»åŠ¨åˆ°äº† 8.6GBï¼›åˆ°äº† step 4ï¼Œè¿™å— 512MB çš„æ˜¾å­˜å—å·²ç»ç§»åŠ¨åˆ°äº† 9.6GB ä»¥ä¸Šäº†ã€‚æŒ‰ç…§æˆ‘ä»¬çš„ç»éªŒï¼Œè¿™ä¸¤ä¸ªæ˜¾å­˜å—ä¸åç§»ï¼Œä¸­é—´çš„è¿™äº›éå¸¸é›¶ç¢çš„æ˜¾å­˜å—å°±æ˜¯æ³„éœ²çš„å†…å®¹ã€‚æˆ‘ä»¬å…·ä½“çœ‹ stackï¼š

<details>
<summary>æ˜¾å­˜ç¢ç‰‡çš„çš„ stack</summary>

```bash
/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl_fast.py:278:_preprocess
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl_fast.py:173:_preprocess_image_like_inputs
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/transformers/image_processing_utils_fast.py:659:preprocess
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl_fast.py:151:preprocess
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/transformers/image_processing_utils_fast.py:623:call
??:0:PyInit__datetime
/usr/local/lib/python3.10/dist-packages/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py:150:call
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/sglang/srt/multimodal/processors/base_processor.py:218:process_mm_data
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/sglang/srt/multimodal/processors/base_processor.py:540:_process_and_collect_mm_items
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/sglang/srt/multimodal/processors/base_processor.py:597:process_and_combine_mm_data
/usr/local/lib/python3.10/dist-packages/sglang/srt/multimodal/processors/qwen_vl.py:251:process_mm_data_async
/usr/local/lib/python3.10/dist-packages/sglang/srt/managers/tokenizer_manager.py:535:_tokenize_one_request
/usr/local/lib/python3.10/dist-packages/sglang/srt/managers/tokenizer_manager.py:832:_handle_batch_request
??:0:_PyUnicode_IsWhitespace
??:0:PyIter_Send
/usr/local/lib/python3.10/dist-packages/sglang/srt/managers/tokenizer_manager.py:486:generate_request

```

</details>

å¾ˆæ˜æ˜¾ï¼Œæˆ‘ä»¬å‘ç°äº†è¿™äº›ç¢ç‰‡çš„æ¥æºï¼Œå°±æ˜¯ qwen vl çš„ fast tokenizer åœ¨æ³„éœ²ã€‚

é€šè¿‡æˆ‘ä»¬å·²æœ‰çš„å™è¿°ï¼Œæƒ³å¿…å¤§å®¶ä¹Ÿæœ‰äº†ä¸€äº›ä½¿ç”¨ torch.cuda.memory._dump_snapshot çš„ç»éªŒï¼Œæˆ‘ä»¬ä¹Ÿæ ¹æ®ä»¥ä¸Šå·²æœ‰çš„ä¿¡æ¯ï¼Œå‡çº§äº† [sglang ç‰ˆæœ¬](https://github.com/volcengine/verl/pull/3183)ï¼Œé¿å…äº†åœ¨ image processor ä¸Šçš„æ˜¾å­˜æ³„éœ²ã€‚

2. Allocator State History

æˆ‘ä»¬ç»§ç»­çœ‹ç¬¬äºŒç§å¯è§†åŒ–æ–¹æ³•ï¼ŒAllocator State History å’Œ Active Memory Timeline ç•¥åŒä¸åŒï¼Œæˆ‘ä»¬èƒ½å¤Ÿæ›´å…·ä½“çœ‹åˆ°åœ¨æ¯ä¸ªè®°å½•çš„äº‹ä»¶ç»“æŸåï¼Œå½“å‰è¿›ç¨‹çš„æ˜¾å­˜æƒ…å†µã€‚å¦‚ä¸‹å›¾ï¼š

<img src="./pics/stack.png" alt="step-4" width="50%">

å…¶ä¸­ï¼Œäº”é¢œå…­è‰²çš„æŸ±å­æ˜¯å®é™…åˆ†é…çš„æ˜¾å­˜ï¼ŒæŒªåŠ¨åˆ°å…¶ä¸Šå¯ä»¥çœ‹åˆ°å…·ä½“çš„åˆ†é…æ—¶æœºå’Œè¡Œæ•°ï¼Œæ¯”å¦‚ï¼š

<details>
<summary>æˆ‘å…ˆå‰æåˆ°çš„ optimizer state</summary>

```bash
b7f1ce3742000_0 518.8MiB (543956992 bytes) allocation (stream 0)
CUDACachingAllocator.cpp:0:c10::cuda::CUDACachingAllocator::Native::DeviceCachingAllocator::malloc(signed char, unsigned long, CUstream_st*)
python_torch_functions_0.cpp:0:torch::autograd::THPVariable_zeros_like(_object*, _object*, _object*)
/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py:180:_init_group
/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:838:_fn
/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py:236:step
/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py:79:_use_grad
/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py:485:wrapper
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:124:wrapper
/usr/local/lib/python3.10/dist-packages/verl/workers/actor/dp_actor.py:301:_optimizer_step
/usr/local/lib/python3.10/dist-packages/verl/workers/actor/dp_actor.py:496:update_policy
/usr/local/lib/python3.10/dist-packages/verl/utils/profiler/performance.py:118:log
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/verl/utils/profiler/performance.py:105:f
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/verl/workers/fsdp_workers.py:733:update_actor
/usr/local/lib/python3.10/dist-packages/verl/utils/profiler/nvtx_profile.py:180:wrapper
/usr/local/lib/python3.10/dist-packages/verl/single_controller/base/decorator.py:514:inner
??:0:PyMethod_New
/usr/local/lib/python3.10/dist-packages/verl/single_controller/ray/base.py:720:func
/usr/local/lib/python3.10/dist-packages/ray/util/tracing/tracing_helper.py:463:_resume_span
/usr/local/lib/python3.10/dist-packages/ray/_private/function_manager.py:689:actor_method_executor
_raylet.cpp:0:__pyx_pw_3ray_7_raylet_12execute_task_3function_executor(_object*, _object*, _object*)
```

</details>

ç™½è‰²çš„å—æ˜¯ segmentï¼Œä¹Ÿå³æˆ‘ä»¬æœ€å¼€å§‹æåˆ°çš„å·²ç» reservered ä½†æ˜¯æ²¡æœ‰ allocated çš„æ˜¾å­˜ã€‚segment è¶Šå¤šè¶Šç¢ï¼Œåˆ™æ˜¾å­˜ç¢ç‰‡åŒ–è¶Šä¸¥é‡ï¼Œæ›´å®¹æ˜“ OOMã€‚

## ç©¶ç«Ÿæ˜¾å­˜æ³„éœ²åœ¨å“ªå„¿

**é¦–å…ˆï¼Œæˆ‘ä»¬ bump äº† SGLang ç‰ˆæœ¬åï¼Œæ— è®ºæ˜¯ VLM è¿˜æ˜¯ LLMï¼ŒSGLang å‡ä¸å­˜åœ¨æ³„éœ²é—®é¢˜ï¼Œè¯·å¤§å®¶æ”¾å¿ƒä½¿ç”¨ SGLang-verlï¼Œå¯ä»¥å‚è€ƒ[æˆ‘ä»¬çš„æŒ‡å—](https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial/blob/main/rlhf/verl/multi-turn/release_log/latest_sglang.md)æ¥å¿«é€Ÿå¯ç”¨ã€‚**

å…¶æ¬¡ï¼Œæˆ‘è¿˜æ˜¯æ¥åˆ†äº«ä¸‹å…·ä½“æ³„éœ²çš„åŸå› ï¼š

å…¶å®è¿˜æ˜¯åœ¨ Rollout è¿‡ç¨‹ä¸­ï¼Œimage processor æœ‰ä¸€å®šçš„ç¢ç‰‡åŒ–ï¼Œæˆ–è€…æ³„éœ²ï¼ŒåŠ ä¹‹æˆ‘åœ¨å…¬å¸é‡Œçš„è®­ç»ƒåœºæ™¯éå¸¸å¤æ‚ï¼Œæ‰€ä»¥å åŠ  FSDP çš„ç¢ç‰‡åŒ–ï¼Œå¶å°”ä¼šå‡ºç° OOM é—®é¢˜ã€‚è¿™é‡Œï¼Œå›åˆ°æˆ‘ä¸€å¼€å§‹ç»™å‡ºçš„ä»£ç ç‰‡æ®µï¼š

<details>
<summary>åœ¨ SGLang Scheduler ä¸Šçš„æ¯ç§’å›æ”¶æ˜¾å­˜ä»£ç </summary>

```python
    @DynamicGradMode()
    def event_loop_overlap(self):
        """A scheduler loop that overlaps the CPU processing and GPU computation."""
        self.result_queue = deque()
        while True:
            current_time = time.time()
            if (
                not hasattr(self, "_last_memory_log_time")
                or current_time - self._last_memory_log_time >= 1.0
            ):
                gc.collect()
                torch.cuda.empty_cache()
```

</details>

è¿™é‡Œï¼Œæ¯ä¸€ç§’é’Ÿè°ƒç”¨ä¸€æ¬¡ `gc.collect, torch.cuda.empty_cache` æ¥å›æ”¶æ˜¾å­˜æ˜¯æˆ‘æ‰‹åŠ¨åŠ çš„ã€‚æˆ‘ä»¬æ¥çœ‹çœ‹ä¸åŠ çš„æƒ…å†µï¼Œå…·ä½“çš„å®éªŒè®°å½•åœ¨ [PR 9071](https://github.com/sgl-project/sglang/pull/9071) ä¸­ã€‚

å½“æˆ‘å¯ç”¨äº†æ¯ 1s å›æ”¶ä¸€æ¬¡æ˜¾å­˜åï¼Œé€šè¿‡é«˜å¼ºåº¦æŒ‡ä»¤çš„æ–¹æ³•ï¼š

```bash
python -m sglang.bench_serving \
    --backend sglang-oai-chat \
    --dataset-name random-image \
    --num-prompts 500 \
    --random-image-num-images 3 \
    --random-image-resolution 720p \
    --random-input-len 512 \
    --random-output-len 512
```

æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªå¦‚ä¸‹çš„æ˜¾å­˜å ç”¨éšç€æ—¶é—´çš„å˜åŒ–æ›²çº¿ï¼š

<img src="./pics/with-gc.png" alt="Active Memory Timeline" width="50%">

æˆ‘ä»¬è§‚å¯Ÿåˆ°ï¼Œç”±äºåŒä¸€æ—¶é—´å‘é€äº† 500 æ¡è¯·æ±‚ï¼Œæ‰€ä»¥æ•´ä¸ª rank ä¸Šçš„æ˜¾å­˜é™¡ç„¶å¢åŠ äº† 30GBã€‚è¿™æ˜¯åˆç†çš„ï¼Œå› ä¸º SGLang çš„ mem static å‚æ•°å¹¶ä¸ä¼šæ§åˆ¶ VLM çš„ image processor çš„æ˜¾å­˜å ç”¨ï¼ŒVLM è®¾ç½®çš„ mem usage å°±æ˜¯è¦ä½äº LLMï¼›åŒæ—¶ï¼Œimage processor è‚¯å®šè¦æŠŠ image å¤„ç†ä¸º tensorï¼Œè‡ªç„¶æ˜¯è¦å æ®ä¸å°‘æ˜¾å­˜çš„ã€‚çœŸæ­£å€¼å¾—å…³æ³¨çš„æ˜¯ï¼Œåœ¨æ‰€æœ‰è¯·æ±‚å¤„ç†ç»“æŸåï¼Œæ— è®ºæ˜¯ reserved è¿˜æ˜¯ allocated çš„æ˜¾å­˜ï¼Œéƒ½å›åˆ°äº† 145GB å·¦å³ã€‚

> ä¸ºä»€ä¹ˆæ˜¯ 145GB å‘¢ï¼Œå› ä¸ºæˆ‘ç”¨äº† B200 lolï¼Œè¿™è¾ˆå­ç¬¬ä¸€æ¬¡æ‘¸åˆ° B å¡ï¼Œå¯æƒœå®‰è£…ä¹Ÿç¨å¾®éº»çƒ¦äº›ï¼Œç°åœ¨è¿˜æ²¡è¯•è¿‡èƒ½ä¸èƒ½åš RL ğŸ˜‚

æ€»ä¹‹ï¼Œå¯ä»¥è§‚å¯Ÿåˆ°ï¼Œæˆ‘æ¯ 1s å›æ”¶ä¸€æ¬¡æ˜¾å­˜çš„è¯ï¼Œç¡®å®æ˜¯ä¸å­˜åœ¨æ³„éœ²çš„ã€‚ä½†æ˜¯ï¼Œæˆ‘æŠŠå›æ”¶æ˜¾å­˜çš„éƒ¨åˆ†å»æ‰åï¼Œæƒ…å†µç«‹åˆ»ä¸åŒäº†ï¼š

<img src="./pics/without-gc.png" alt="Active Memory Timeline" width="50%">

å¾ˆä¸å¹¸ï¼Œæˆ‘ä»¬ allocated çš„æ˜¾å­˜å®Œæˆäº†å›æ”¶ï¼Œä½†æ˜¯ reserved çš„æ˜¾å­˜ä¸€ç›´åœ¨å¢é•¿ã€‚è¿™å°±æ˜¯æˆ‘æåˆ°çš„ï¼Œsegment è¶Šåˆ†è¶Šå¤šï¼Œè¶Šæ¥è¶Šç»†ï¼Œè™½ç„¶ block æ²¡æœ‰å¢é•¿ï¼Œä½†æ˜¯ ROllout é˜¶æ®µæ˜¾å­˜å·²ç»é«˜åº¦ç¢ç‰‡åŒ–äº†ï¼Œåœ¨æˆ‘ä»¬å…¬å¸å¤æ‚çš„ mutli-turn ä¸šåŠ¡ä¸­ï¼Œä¸€ä¸ª rollout request é‡Œé¢ï¼Œä¼šæœ‰å¤šå¼ å›¾ç‰‡ï¼Œæœ€åè¿™äº›ç¢ç‰‡è®© SGLang æ— æ³•å†åˆ†é…å¤§ç‰‡è¿ç»­æ˜¾å­˜ï¼Œä»è€Œåœ¨ rollout é˜¶æ®µ OOMã€‚

è¯´åˆ°æ­¤ï¼Œå¬ä¸Šå»é—®é¢˜å¾ˆä¸¥é‡ï¼Œä½†æ˜¯æˆ‘å’Œåšæ¨ç†å¼•æ“çš„åŒè¡Œäº¤æµè¿‡ï¼Œimage processor ä¸ç”±æ¨ç†å¼•æ“æŒæ§ï¼Œå­˜åœ¨è¿™æ ·çš„ç¢ç‰‡æˆ–è€…æ³„éœ²å€’ä¹Ÿæ˜¯æ­£å¸¸ï¼Œè€Œæˆ‘ä»¬åœ¨ Scheduler ä¸Šå®šæœŸå›æ”¶æ˜¾å­˜çš„åšæ³•ï¼Œæ˜¯ reasonable è€Œä¸”å¸¸è§çš„ã€‚å¯æƒœçš„æ˜¯ï¼Œæˆ‘åœ¨ä¸Šæ–¹æå‡ºçš„æ–¹æ¡ˆæ˜¯æ¯ 1s å›æ”¶ä¸€æ¬¡ï¼Œè¿™æ— ç–‘å¯¹æ€§èƒ½æœ‰å¾ˆå¤§æŸå¤±ã€‚å¦‚æœä½ çš„ RL è®­ç»ƒä¹Ÿé‡åˆ°äº†ç±»ä¼¼çš„ VLM æ˜¾å­˜æ³„éœ²é—®é¢˜ï¼Œæˆ‘è®¤ä¸ºæœ‰å‡ ç§è§£å†³åŠæ³•ï¼š

1. åŠ å…¥å®šæœŸçš„æ˜¾å­˜å›æ”¶æœºåˆ¶ï¼Œæ¯”å¦‚æ¯ 10s æˆ–è€…æ¯ 10 ä¸ª requests å›æ”¶ä¸€æ¬¡ï¼›
2. ç›´æ¥é™ä½ rollout engine çš„ mem staticï¼Œæ¯”å¦‚ä»æˆ‘ä»¬ä¸€èˆ¬è®¾ç½®çš„ 0.85 é™ä½åˆ° 0.65ï¼›

1 çš„åŸå› å·²ç»åœ¨æˆ‘ä¸Šæ–¹çš„å›¾ç¤ºè¯´æ˜æ¸…æ¥šäº†ï¼Œè€Œ 2 çš„åŸå› å€¼å¾—ä¸€æä¸€æ–¹é¢ï¼ŒSGLang æœ¬èº«ä¸ç®¡ç† image processor çš„æ˜¾å­˜ï¼Œæ‰€ä»¥ SGLang æ¨èçš„ mem static å‚æ•°å¯¹ VLM å°±æ˜¯æ¯”èµ· LLM ä½ã€‚LLM æˆ‘ä»¬ä¸€èˆ¬è®¾ç½®çš„ mem static æ˜¯ 0.85ï¼ŒVLM æ¨èå¯èƒ½å°±æ˜¯ 0.8 äº†ï¼›å¦ä¸€æ–¹é¢ï¼Œå¾ˆå¤šæ—¶å€™å¦‚æœæˆ‘ä»¬ rollout çš„æ—¶å€™ï¼Œä½¿ç”¨ç±»ä¼¼ verl è¿™ç§ SPMD ç­–ç•¥ï¼Œæ¯ä¸ª rollout worker çš„ requests/worker æ˜¯èƒ½å¤Ÿç®—å‡ºæ¥çš„ï¼ˆå…·ä½“æ¥è¯´ï¼Œæ˜¯ `train batch size * grpo group size / num workers`ï¼‰ï¼Œå¦‚æœç»è¿‡æˆ‘ä»¬çš„è®¡ç®—ï¼Œrequests/worker æœ¬èº«å°±ä¸é«˜ï¼Œä½äº 20ï¼Œé‚£ä¹ˆè®¾ç½®æ›´å¤§çš„ mem staticï¼Œæœ‰æ›´å¤§çš„ kv cache ç©ºé—´ï¼Œå¯¹æ¨ç†æ€§èƒ½çš„å½±å“ä¹Ÿä¸å¤§ã€‚å½“ç„¶ï¼Œå¯¹äº slime è¿™ç§æ›´åŠ è§£è€¦çš„è®¾è®¡ï¼Œæ¯ä¸ª rollout worker ä¸Šçš„ requests/worker æ˜¯ä¸ä¸€å®šçš„ï¼Œä½†æ˜¯ä¹Ÿå¤§å·®ä¸å·®ï¼Œè¿˜æ˜¯å¯ä»¥ä¼°ç®—åˆ°å¹³å‡æ¯ä¸ª worker å¤„ç†çš„ requests æ•°é‡ã€‚

å½“ç„¶ï¼Œåœ¨çº¿ä¸Šçš„ serving åœºæ™¯ä¸æ–­åœ° `gc.collect` å¯¹æ€§èƒ½å½±å“éå¸¸å¤§ï¼Œæ‰€ä»¥æˆ‘ä¸ªäººè§‰å¾—ç›®å‰åªèƒ½åœ¨ RL åœºæ™¯ä¸‹è¿™ä¹ˆæã€‚å…·ä½“çº¿ä¸Š serving æ€ä¹ˆåšï¼Œè¿˜å¾—è®¨è®ºã€‚

æœ€åï¼Œå…¶å®å¾ˆæ—©ä¹‹å‰æˆ‘å°±æ„è¯†åˆ°äº† rollout å¯èƒ½å­˜åœ¨ç¢ç‰‡ï¼Œæˆ‘ç”šè‡³ä¹Ÿå‚è€ƒäº† verl å›¢é˜Ÿæ‰€å†™çš„ `aggressive_empty_cache` å‡½æ•°ï¼Œç»™ SGLang æäº†è¿™ä¸ª [PR 3136](https://github.com/volcengine/verl/pull/3136)ã€‚

<details>
<summary>aggressive_empty_cache çš„å®ç°</summary>

```python
def aggressive_empty_cache(force_sync: bool = True, max_retries: int = 3) -> None:
    """
    More aggressive GPU memory cleanup function, tries to release PyTorch reserved
    but unallocated memory.

    Args:
        force_sync: Whether to force device synchronization
        max_retries: Maximum number of retries
    """
    device = get_torch_device()
    if not device.is_available():
        return

    for attempt in range(max_retries):
        # Record memory status before cleanup
        before_reserved = device.memory_reserved()
        before_allocated = device.memory_allocated()

        # Run garbage collection
        gc.collect()

        # Clear PyTorch cache
        device.empty_cache()

        # Force synchronization (optional)
        if force_sync:
            device.synchronize()

        # Record memory status after cleanup
        after_reserved = device.memory_reserved()
        after_allocated = device.memory_allocated()

        # Calculate freed memory
        reserved_freed = before_reserved - after_reserved
        allocated_freed = before_allocated - after_allocated

        logger.info(
            f"Memory cleanup attempt {attempt + 1}: Freed {reserved_freed / 1024**3:.2f} GB reserved, "
            f"{allocated_freed / 1024**3:.2f} GB allocated"
        )

        # Stop retrying if little memory was freed
        if reserved_freed < 1024**3:  # less than 1GB
            break
```

</details>

è¿™ä¸ªå‡½æ•°å…¶å®å’Œç›´æ¥è°ƒç”¨ `gc.collect, torch.cuda.empty_cache` åŒºåˆ«ä¸å¤§ï¼Œä¸è¿‡ä»–ä»¬åœ¨å›æ”¶çš„åŒæ—¶åšäº†ä¸€æ¬¡åŒæ­¥ï¼Œå¯ä»¥å›æ”¶çš„æ›´å½»åº•äº›ã€‚è¿™ä¸ªå‡½æ•°æ˜¯å¯¹çš„ï¼Œä½†æˆ‘çš„è°ƒç”¨æ—¶é—´é”™äº†ã€‚æ³¨æ„åˆ°ï¼Œæˆ‘åœ¨ PR 3136 ä¸­çš„è°ƒç”¨æ—¶æœºæ˜¯ï¼š

```python
  async def wake_up(self):
        aggressive_empty_cache(force_sync=True)

    @GPUMemoryLogger(role="FSDPSGLangShardingManager exit", logger=logger)
    async def sleep(self):
        aggressive_empty_cache(force_sync=True)
```

æˆ‘ä»¬éƒ½æ˜¯åœ¨ FSDP ä¸­ï¼Œè°ƒç”¨äº† SGLang çš„ `wake_up` å’Œ `sleep` å‡½æ•°çš„æ—¶å€™æ‰å›æ”¶æ˜¾å­˜ï¼Œè¿™æ˜¯æœ‰é—®é¢˜çš„ã€‚SGLang ä¸ä¼šå’Œ FSDP åŒè¿›ç¨‹ï¼Œè€Œä¸” wake up å’Œ sleep çš„æ—¶å€™å·²ç»æ›´æ¢äº†æ–°çš„ garbage allocatorï¼Œè‡ªç„¶å›æ”¶ä¸åˆ° rollout æ—¶å€™çš„æ˜¾å­˜ç¢ç‰‡ã€‚æƒ³æ˜ç™½è¿™ç‚¹åï¼Œæˆ‘ä»¬æŠŠæ€è·¯æ”¹æˆåœ¨ rollout ç»“æŸçš„æ—¶å€™å›æ”¶æ˜¾å­˜ï¼Œé—®é¢˜ä¸€ä¸‹å°±è§£å†³äº†ã€‚

